{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis of Vagrant Developers\n",
    "<a href=\"#TODO's\">TODO</a><br>\n",
    "<a href=\"#Imports\">Imports</a><br>\n",
    "<a href=\"#Functions\">Functions</a><br>\n",
    "<a href=\"#Analysis\">Analysis</a><br>\n",
    "<a href=\"#Linear-Regression\"><b>Analysis</b> - Linear-Regression</a><br>\n",
    "<a href=\"#Graph-Based-Analysis-using-Logistic-Regression,-Random-Forest-Classifer,-and-XGBoost-classifier\"><b>Analysis</b> - Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier</a><br>\n",
    "<a href=\"#Cross-Validation\"><b>Analysis</b> - Cross Validation</a><br>\n",
    "<a href=\"#Rebalancing-data\"><b>Analysis</b> - Data Rebalancing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO's\n",
    "\n",
    "<ul>\n",
    "<li>Implement a new dataframe to store the results from each section. (refer to last cell)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "import numpy\n",
    "import os\n",
    "import math\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve, plot_precision_recall_curve, auc, recall_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, LeaveOneOut, KFold, StratifiedKFold, RepeatedKFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import statsmodels.api as sm\n",
    "from ast import literal_eval\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(model, x, y):\n",
    "    '''\n",
    "    Plots the predictions made using a linear regression model \n",
    "    given the set of dependent variable(s) and the independent variable\n",
    "        model: Linear Regression Model\n",
    "        x: Dependent Variable(s)\n",
    "        y: Independent Variable\n",
    "    returns: Independent Variable Predictions\n",
    "    '''\n",
    "    y_pred = model.predict(x)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_pred, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# source: https://stackoverflow.com/questions/26319259/how-to-get-a-regression-summary-in-python-scikit-like-r-does\n",
    "def regression_results(y_true, y_pred):\n",
    "    '''\n",
    "    Analyzes the results from the linear regression model prediction using different metrics, such r^2\n",
    "    '''\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def Loo(model, x, y):\n",
    "    '''\n",
    "    Uses the LeaveOneOut cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    loo = LeaveOneOut() \n",
    "    highestscore = (0, \"\")\n",
    "    y_true, y_pred = list(), list()\n",
    "    \n",
    "    # Split the data\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        predictions = model.predict_proba(x_test)\n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        score = model.score(x_test, y_test) # NOTE: Removed the following due to errors: prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if score > highestscore[0]:\n",
    "            highestscore = (model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\")\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[1])\n",
    "    print(\"\\nModel Score: {}\\n\".format(highestscore[0]))\n",
    "    #acc = accuracy_score(y_true, y_pred)\n",
    "    #print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    \n",
    "def Loo_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the LeaveOneOut cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = LeaveOneOut()\n",
    "    # to see list of scoring methods, go to: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Rkf(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the RepeatedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    kf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42) \n",
    "    #kf.get_n_splits(x)\n",
    "    #print(kf)\n",
    "    highestscore = (0, 0, \"\", 0, 0, 0, 0)\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    precision = precision_score(highestscore[3], highestscore[4])\n",
    "    print(\"Precision: \", precision)\n",
    "    recall = recall_score(highestscore[3], highestscore[4])\n",
    "    print(\"Recall: \", recall)\n",
    "    f1 = f1_score(highestscore[3], highestscore[4])\n",
    "    print(\"F1: \", f1_score(highestscore[3], highestscore[4]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6], precision, recall, f1\n",
    "    \n",
    "def Rkf_short(model, x, y):    \n",
    "    '''\n",
    "    Uses the shortened version of the RepeatedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Skf(model, x, y, threshold = None):\n",
    "    '''\n",
    "    Uses the StratifiedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    highestscore = (0, 0, \"\", 0, 0, 0, 0)\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "            \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    precision = precision_score(highestscore[3], highestscore[4])\n",
    "    print(\"Precision: \", precision)\n",
    "    recall = recall_score(highestscore[3], highestscore[4])\n",
    "    print(\"Recall: \", recall)\n",
    "    f1 = f1_score(highestscore[3], highestscore[4])\n",
    "    print(\"F1: \", f1_score(highestscore[3], highestscore[4]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6], precision, recall, f1\n",
    "    \n",
    "def Skf_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the StratifiedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))    \n",
    "\n",
    "def Tss(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the TimeSeriesSplit cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    highestscore = (0, 0, \"\", 0, 0, 0, 0)\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    rcall = None\n",
    "    yhat = None\n",
    "    \n",
    "    for train_index, test_index in tscv.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    precision = precision_score(highestscore[3], highestscore[4])\n",
    "    print(\"Precision: \", precision)\n",
    "    recall = recall_score(highestscore[3], highestscore[4])\n",
    "    print(\"Recall: \", recall)\n",
    "    f1 = f1_score(highestscore[3], highestscore[4])\n",
    "    print(\"F1: \", f1_score(highestscore[3], highestscore[4]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6], precision, recall, f1\n",
    "\n",
    "def Tss_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the TimeSeriesSplit cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = TimeSeriesSplit(n_splits=10)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores))) \n",
    "    \n",
    "def Compare_Model_Scores(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    \n",
    "    print(\"Predictions for model 1: \")\n",
    "    print(prediction_probs1)\n",
    "    print(\"\\nPredictions for model 2: \")\n",
    "    print(prediction_probs2)\n",
    "    '''\n",
    "    \n",
    "    #recall1, recall2, precision1, precision2, thresholds_list = get_precision_recall(test_x1, test_x2, y_test, model1, model2)\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:, 1]) \n",
    "    #retrieve probability of being 1(in second column of probs_y)\n",
    "    \n",
    "    pr_auc1 = auc(recall1, precision1)\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    prec_1 = precision_score(y_test, predictions1)\n",
    "    print(\"Precision score for model 1: \", prec_1)\n",
    "    rec_1 = recall_score(y_test, predictions1)\n",
    "    print(\"Recall score for model 1: \", rec_1)\n",
    "    f1_1 = f1_score(y_test, predictions1)\n",
    "    print(\"F1 score for model 1: \", f1_1)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    \n",
    "    pr_auc2 = auc(recall2, precision2)\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    \n",
    "    prec_2 = precision_score(y_test, predictions2)\n",
    "    print(\"Precision score for model 2: \", prec_2)\n",
    "    rec_2 = recall_score(y_test, predictions2)\n",
    "    print(\"Recall score for model 2: \", rec_2)\n",
    "    f1_2 = f1_score(y_test, predictions2)\n",
    "    print(\"F1 score for model 2: \", f1_2)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2\n",
    "    \n",
    "def Compare_Model_Scores_Best_Threshold(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:,1])\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    \n",
    "    pr_auc1 = auc(recall1[ix1:], precision1[ix1:])\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    prec_1 = precision_score(y_test, predictions1)\n",
    "    print(\"Precision score for model 1: \", prec_1)\n",
    "    rec_1 = recall_score(y_test, predictions1)\n",
    "    print(\"Recall score for model 1: \", rec_1)\n",
    "    f1_1 = f1_score(y_test, predictions1)\n",
    "    print(\"F1 score for model 1: \", f1_1)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore2[np.isnan(fscore2)] = 0  \n",
    "    ix2 = np.argmax(fscore2)\n",
    "    \n",
    "    pr_auc2 = auc(recall2[ix2:], precision2[ix2:])\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    prec_2 = precision_score(y_test, predictions2)\n",
    "    print(\"Precision score for model 2: \", prec_2)\n",
    "    rec_2 = recall_score(y_test, predictions2)\n",
    "    print(\"Recall score for model 2: \", rec_2)\n",
    "    f1_2 = f1_score(y_test, predictions2)\n",
    "    print(\"F1 score for model 2: \", f1_2)\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2\n",
    "\n",
    "def plot_thresholds(model1, model2, test_x1, test_y1, test_x2, test_y2, prediction_probs1, prediction_probs2, title):\n",
    "    '''Predict test_y values and probabilities based on fitted logistic for both models''' \n",
    "\n",
    "    # recall1, recall2, precision1, precision2, threshold_list = get_precision_recall(test_x1, test_x2, test_y1, model1, model2)\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(test_y1, prediction_probs1[:, 1]) \n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(test_y2, prediction_probs2[:, 1])\n",
    "    \n",
    "    # convert to f1 score\n",
    "    # from: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    fscore2[np.isnan(fscore2)] = 0 \n",
    "    \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    ix2 = np.argmax(fscore2)\n",
    "    #print(f\"F score 1: {fscore1} with ix: {ix1}\")\n",
    "    #print(f\"F score 2: {fscore2} with ix: {ix2}\")\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 1' % (thresholds1[ix1], fscore1[ix1]))\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 2' % (thresholds2[ix2], fscore2[ix2]))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.title(f\"PRC for {title}\")\n",
    "    # use marker = \".\" to see each threshhold value\n",
    "    plt.plot(recall1[:-1], precision1[:-1], \"b\", label=f\"Model 1\\n-----------\\n • PRC-AUC score: {auc(recall1[ix1:], precision1[ix1:]):.2f}\\n • Best Threshold: {round(thresholds1[ix1], 2):.2f}\\n • Best F1-Score: {round(fscore1[ix1], 2):.2f}\\n\")\n",
    "    plt.plot(recall2[:-1], precision2[:-1], \"r--\", label=f\"Model 2\\n-----------\\n • PRC-AUC score: {auc(recall2[ix2:], precision2[ix2:]):.2f}\\n • Best Threshold: {round(thresholds2[ix2], 2):.2f}\\n • Best F1-Score: {round(fscore2[ix2], 2):.2f}\")\n",
    "    plt.scatter([recall1[ix1], recall2[ix2]], [precision1[ix1], precision2[ix2]], marker='o', color='black', label='Best threshold')\n",
    "    #plt.annotate('Model 1 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds1[ix1], fscore1[ix1]), (0.38, 0.35), fontsize=8)\n",
    "    #plt.annotate('Model 2 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds2[ix2], fscore2[ix2]), (0.38, 0.3), fontsize=8)\n",
    "    \n",
    "    x1 = np.array(recall1[ix1:], dtype=float)\n",
    "    x2 = np.array(recall2[ix2:], dtype=float)\n",
    "    y1 = np.array(precision1[ix1:], dtype=float)\n",
    "    y2 = np.array(precision2[ix2:], dtype=float)\n",
    "    y1_opp = np.array(precision1[ix2:], dtype=float)\n",
    "    \n",
    "    #plt.fill_between(x1, y1, color='b', alpha=0.5)\n",
    "    # where=y1_opp<=y2\n",
    "    #plt.fill_between(x2, y2, color='r', alpha=0.3)\n",
    "    \n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    plt.ylim([0,1])\n",
    "    plt.xlim([0,1])\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return thresholds1[ix1], thresholds2[ix2], fig\n",
    "    \n",
    "def simple_threshold_plot(classifier, x_test, y_test):\n",
    "    predictions = classifier.predict(x_test)\n",
    "    prc_val = average_precision_score(y_test, predictions)\n",
    "    disp = plot_precision_recall_curve(classifier, x_test, y_test)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(prc_val))\n",
    "    \n",
    "def get_precision_recall(test_x1, test_x2, test_y, model1, model2):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with each type of threshold\n",
    "    '''\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, 1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "        \n",
    "    return recall1, recall2, precision1, precision2, threshold_list\n",
    "\n",
    "def get_precision_recall_best_thresh(test_x1, test_x2, test_y, model1, model2, best_thresh1=None, best_thresh2=None):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with the best threshold\n",
    "    '''\n",
    "    limit1, limit2 = 1, 1\n",
    "    if best_thresh1 != None:\n",
    "        limit1 = best_thresh1\n",
    "    if best_thresh2 != None:\n",
    "        limit2 = best_thresh2\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, limit1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        \n",
    "    threshold_list = np.arange(0.001, limit2, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "    return recall1, recall2, precision1, precision2, threshold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name   PageRank    Betweenness  Closeness  Harmonic  \\\n",
      "0             Seth Vargo  24.098295  172342.464826   0.917656  0.955134   \n",
      "1     Mitchell Hashimoto  24.093374  263957.868091   0.879363  0.931406   \n",
      "2          Chris Roberts  21.082051  177846.949345   0.842297  0.906385   \n",
      "3               tfanning  19.974389   59072.500908   0.847842  0.910267   \n",
      "4             Brian Cain  19.631400  131598.446530   0.818503  0.889129   \n",
      "...                  ...        ...            ...        ...       ...   \n",
      "1155               winky   0.153670       0.000000   0.487179  0.492091   \n",
      "1156           Yufan Lou   0.153324       0.000000   0.459010  0.471096   \n",
      "1157       Aidan Feldman   0.152928       0.000000   0.488000  0.492954   \n",
      "1158        Steven Leung   0.152204       0.000000   0.498066  0.499569   \n",
      "1159             Murathe   0.150903       0.000000   0.487795  0.492522   \n",
      "\n",
      "        Degree  Number_of_Bugs  \n",
      "0     108731.0           233.0  \n",
      "1     786949.0           865.0  \n",
      "2     190286.0           113.0  \n",
      "3      11936.0             3.0  \n",
      "4     125936.0           151.0  \n",
      "...        ...             ...  \n",
      "1155       3.0             0.0  \n",
      "1156       6.0             0.0  \n",
      "1157       4.0             0.0  \n",
      "1158       3.0             0.0  \n",
      "1159       3.0             0.0  \n",
      "\n",
      "[1160 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make sure the data is from all dates\n",
    "df = pd.read_csv(\"../Neo4j_output/Centrality_Output.csv\")\n",
    "# Replace NaN with 0 to include developers who did not introduce any bugs\n",
    "df['Number_of_Bugs'] = df['Number_of_Bugs'].fillna(0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.248\n",
      "Model:                            OLS   Adj. R-squared:                  0.247\n",
      "Method:                 Least Squares   F-statistic:                     380.9\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):           1.47e-73\n",
      "Time:                        17:24:55   Log-Likelihood:                -5312.7\n",
      "No. Observations:                1160   AIC:                         1.063e+04\n",
      "Df Residuals:                    1158   BIC:                         1.064e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.4607      0.761     -5.859      0.000      -5.954      -2.967\n",
      "x1             6.3483      0.325     19.516      0.000       5.710       6.987\n",
      "==============================================================================\n",
      "Omnibus:                     2817.378   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         26060725.802\n",
      "Skew:                          23.606   Prob(JB):                         0.00\n",
      "Kurtosis:                     735.775   Cond. No.                         2.66\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = df['PageRank'].values.reshape(-1, 1)\n",
    "y = df['Number_of_Bugs'].values.reshape(-1, 1)\n",
    "model = linear_regressor.fit(x, y)\n",
    "y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.2475\n",
      "r2:  0.2475\n",
      "MAE:  4.8982\n",
      "MSE:  556.645\n",
      "RMSE:  23.5933\n"
     ]
    }
   ],
   "source": [
    "regression_results(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.711\n",
      "Model:                            OLS   Adj. R-squared:                  0.711\n",
      "Method:                 Least Squares   F-statistic:                     2846.\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):          3.09e-314\n",
      "Time:                        17:24:55   Log-Likelihood:                -4758.1\n",
      "No. Observations:                1160   AIC:                             9520.\n",
      "Df Residuals:                    1158   BIC:                             9530.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4835      0.432     -1.120      0.263      -1.331       0.364\n",
      "x1             0.0020   3.67e-05     53.348      0.000       0.002       0.002\n",
      "==============================================================================\n",
      "Omnibus:                     1638.934   Durbin-Watson:                   2.371\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          5700945.193\n",
      "Skew:                           6.834   Prob(JB):                         0.00\n",
      "Kurtosis:                     346.167   Cond. No.                     1.18e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.18e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = df['Betweenness'].values.reshape(-1, 1)\n",
    "y = df['Number_of_Bugs'].values.reshape(-1, 1)\n",
    "model = linear_regressor.fit(x, y)\n",
    "y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.7108\n",
      "r2:  0.7108\n",
      "MAE:  2.1069\n",
      "MSE:  213.94\n",
      "RMSE:  14.6267\n"
     ]
    }
   ],
   "source": [
    "regression_results(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.192\n",
      "Model:                            OLS   Adj. R-squared:                  0.191\n",
      "Method:                 Least Squares   F-statistic:                     274.3\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):           1.84e-55\n",
      "Time:                        17:24:55   Log-Likelihood:                -5354.3\n",
      "No. Observations:                1160   AIC:                         1.071e+04\n",
      "Df Residuals:                    1158   BIC:                         1.072e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -153.1468      9.375    -16.335      0.000    -171.541    -134.752\n",
      "x1           301.0905     18.179     16.563      0.000     265.424     336.757\n",
      "==============================================================================\n",
      "Omnibus:                     2883.859   Durbin-Watson:                   1.538\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         29133403.726\n",
      "Skew:                          25.023   Prob(JB):                         0.00\n",
      "Kurtosis:                     777.762   Cond. No.                         32.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = df['Closeness'].values.reshape(-1, 1)\n",
    "y = df['Number_of_Bugs'].values.reshape(-1, 1)\n",
    "model = linear_regressor.fit(x, y)\n",
    "y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.1915\n",
      "r2:  0.1915\n",
      "MAE:  5.8539\n",
      "MSE:  598.0523\n",
      "RMSE:  24.4551\n"
     ]
    }
   ],
   "source": [
    "regression_results(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.145\n",
      "Model:                            OLS   Adj. R-squared:                  0.144\n",
      "Method:                 Least Squares   F-statistic:                     196.1\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):           2.85e-41\n",
      "Time:                        17:24:56   Log-Likelihood:                -5386.9\n",
      "No. Observations:                1160   AIC:                         1.078e+04\n",
      "Df Residuals:                    1158   BIC:                         1.079e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -104.1860      7.597    -13.715      0.000    -119.091     -89.281\n",
      "x1           199.9453     14.279     14.002      0.000     171.929     227.962\n",
      "==============================================================================\n",
      "Omnibus:                     2930.119   Durbin-Watson:                   1.442\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         31682651.388\n",
      "Skew:                          26.042   Prob(JB):                         0.00\n",
      "Kurtosis:                     810.954   Cond. No.                         24.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = df['Harmonic'].values.reshape(-1, 1)\n",
    "y = df['Number_of_Bugs'].values.reshape(-1, 1)\n",
    "model = linear_regressor.fit(x, y)\n",
    "y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.1448\n",
      "r2:  0.1448\n",
      "MAE:  5.983\n",
      "MSE:  632.6194\n",
      "RMSE:  25.1519\n"
     ]
    }
   ],
   "source": [
    "regression_results(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.951\n",
      "Method:                 Least Squares   F-statistic:                 2.266e+04\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        17:24:56   Log-Likelihood:                -3724.0\n",
      "No. Observations:                1160   AIC:                             7452.\n",
      "Df Residuals:                    1158   BIC:                             7462.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1904      0.177      1.078      0.281      -0.156       0.537\n",
      "x1             0.0011   7.25e-06    150.516      0.000       0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1552.015   Durbin-Watson:                   1.468\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2192676.246\n",
      "Skew:                           6.386   Prob(JB):                         0.00\n",
      "Kurtosis:                     215.609   Cond. No.                     2.44e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.44e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = df['Degree'].values.reshape(-1, 1)\n",
    "y = df['Number_of_Bugs'].values.reshape(-1, 1)\n",
    "model = linear_regressor.fit(x, y)\n",
    "y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.9514\n",
      "r2:  0.9514\n",
      "MAE:  1.0246\n",
      "MSE:  35.9721\n",
      "RMSE:  5.9977\n"
     ]
    }
   ],
   "source": [
    "regression_results(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Number_of_Bugs   R-squared:                       0.952\n",
      "Model:                            OLS   Adj. R-squared:                  0.952\n",
      "Method:                 Least Squares   F-statistic:                     4607.\n",
      "Date:                Mon, 30 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        17:24:56   Log-Likelihood:                -3712.9\n",
      "No. Observations:                1160   AIC:                             7438.\n",
      "Df Residuals:                    1154   BIC:                             7468.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -9.3917      7.621     -1.232      0.218     -24.343       5.560\n",
      "PageRank       -0.6764      0.372     -1.817      0.069      -1.407       0.054\n",
      "Betweenness     0.0002   5.42e-05      3.276      0.001    7.12e-05       0.000\n",
      "Closeness     -11.4117     33.274     -0.343      0.732     -76.697      53.873\n",
      "Harmonic       30.1984     26.352      1.146      0.252     -21.505      81.901\n",
      "Degree          0.0010   1.63e-05     63.311      0.000       0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      937.699   Durbin-Watson:                   1.517\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2032167.639\n",
      "Skew:                           2.215   Prob(JB):                         0.00\n",
      "Kurtosis:                     208.001   Cond. No.                     6.27e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.27e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = df[['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']]\n",
    "y = df['Number_of_Bugs']\n",
    "#model = linear_regressor.fit(x, y)\n",
    "#y_pred = plot_prediction(model, x, y)\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    XGB_precision_1  XGB_precision_2  XGB_recall_1  XGB_recall_2  XGB_f1_1  \\\n",
      "0          1.000000         1.000000      0.734094      0.732637  0.846660   \n",
      "1          0.920280         0.993958      0.729144      0.729144  0.813637   \n",
      "2          1.000000         1.000000      0.608546      0.608593  0.756641   \n",
      "3          1.000000         1.000000      0.965854      0.965854  0.982630   \n",
      "4          0.548443         0.548443      1.000000      1.000000  0.708380   \n",
      "5          0.626999         0.813470      0.864605      0.777514  0.726877   \n",
      "6          0.995389         0.995389      1.000000      1.000000  0.997689   \n",
      "7          0.827153         0.827153      0.916948      0.916948  0.869739   \n",
      "8          0.767649         0.767649      0.974230      0.974230  0.858689   \n",
      "9          0.665342         0.889771      0.828984      0.830797  0.738203   \n",
      "10         0.670996         0.671033      0.793392      0.793525  0.727079   \n",
      "11         0.660867         0.660870      0.881457      0.881469  0.755387   \n",
      "12         0.688746         0.688746      0.901340      0.901340  0.780831   \n",
      "13         0.779650         0.779650      0.809675      0.809675  0.794379   \n",
      "\n",
      "    XGB_f1_2  XGB_PRC_AUC_1  XGB_PRC_AUC_2  LR_precision_1  LR_precision_2  \\\n",
      "0   0.845690       0.952647       0.955318        1.000000        1.000000   \n",
      "1   0.841202       0.844487       0.950370        0.550926        0.956197   \n",
      "2   0.756677       0.967942       0.967989        0.583942        1.000000   \n",
      "3   0.982630       0.965854       0.965854        1.000000        1.000000   \n",
      "4   0.708380       0.774222       0.774222        0.551351        0.548443   \n",
      "5   0.795086       0.726882       0.736078        0.540564        0.810559   \n",
      "6   0.997689       0.997695       0.997695        0.995270        0.995306   \n",
      "7   0.869739       0.901355       0.901355        0.832351        0.827153   \n",
      "8   0.858689       0.883658       0.883653        0.767649        0.767619   \n",
      "9   0.859273       0.810260       0.872267        0.825536        0.965092   \n",
      "10  0.727156       0.718221       0.718423        0.542074        0.674534   \n",
      "11  0.755393       0.753893       0.753868        0.000000        0.656959   \n",
      "12  0.780831       0.792898       0.792879        0.663067        0.686459   \n",
      "13  0.794379       0.816212       0.816216        0.797266        0.779650   \n",
      "\n",
      "    ...  LR_PRC_AUC_1  LR_PRC_AUC_2  RF_precision_1  RF_precision_2  \\\n",
      "0   ...      0.924717      0.953018        1.000000        1.000000   \n",
      "1   ...      0.776316      0.974990        0.631628        1.000000   \n",
      "2   ...      0.775000      0.966394        1.000000        1.000000   \n",
      "3   ...      0.981636      0.965854        1.000000        1.000000   \n",
      "4   ...      0.764474      0.774222        0.548443        0.548443   \n",
      "5   ...      0.778373      0.822846        0.813470        0.626994   \n",
      "6   ...      0.997635      0.997695        0.995389        0.995389   \n",
      "7   ...      0.901250      0.901363        0.827153        0.827153   \n",
      "8   ...      0.865748      0.883294        0.767649        0.767649   \n",
      "9   ...      0.889553      0.909132        0.858473        0.809087   \n",
      "10  ...      0.763933      0.771983        0.671033        0.671033   \n",
      "11  ...      0.753665      0.774019        0.660885        0.660873   \n",
      "12  ...      0.775302      0.807716        0.688746        0.688746   \n",
      "13  ...      0.788379      0.816196        0.777438        0.779650   \n",
      "\n",
      "    RF_recall_1  RF_recall_2   RF_f1_1   RF_f1_2  RF_PRC_AUC_1  RF_PRC_AUC_2  \n",
      "0      0.732637     0.732637  0.845690  0.845690      0.945936      0.953861  \n",
      "1      0.752414     0.729302  0.686750  0.843464      0.864633      0.965807  \n",
      "2      0.608710     0.608663  0.756768  0.756732      0.968059      0.968059  \n",
      "3      0.965854     0.965854  0.982630  0.982630      0.965854      0.965854  \n",
      "4      1.000000     1.000000  0.708380  0.708380      0.774222      0.774222  \n",
      "5      0.777514     0.864753  0.795086  0.726926      0.732680      0.726891  \n",
      "6      1.000000     1.000000  0.997689  0.997689      0.997695      0.997695  \n",
      "7      0.916948     0.916948  0.869739  0.869739      0.901355      0.901344  \n",
      "8      0.974230     0.974230  0.858689  0.858689      0.883611      0.883514  \n",
      "9      0.830797     0.830797  0.844408  0.819798      0.852482      0.859970  \n",
      "10     0.793525     0.793525  0.727156  0.727156      0.718239      0.718325  \n",
      "11     0.881529     0.881481  0.755425  0.755400      0.753954      0.753907  \n",
      "12     0.901340     0.901340  0.780831  0.780831      0.791408      0.792865  \n",
      "13     0.809019     0.809675  0.792914  0.794379      0.816082      0.816214  \n",
      "\n",
      "[14 rows x 24 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of all of the unique commits (i.e. links) between developers and the corresponding folders\n",
    "\n",
    "start = 0\n",
    "\n",
    "if os.path.exists('out2.csv'):\n",
    "    final_result_df = pd.read_csv('out2.csv', index_col=0)\n",
    "    print(final_result_df)\n",
    "    for index, row in final_result_df.iterrows():\n",
    "        print()\n",
    "        if math.isnan(row['XGB_precision_1']):\n",
    "            break\n",
    "        start += 1\n",
    "else:\n",
    "    final_result_df = pd.DataFrame({'XGB_precision_1':[None]*14, \n",
    "                                'XGB_precision_2':[None]*14,\n",
    "                                'XGB_recall_1':[None]*14, \n",
    "                                'XGB_recall_2':[None]*14,\n",
    "                                'XGB_f1_1':[None]*14, \n",
    "                                'XGB_f1_2':[None]*14,\n",
    "                                'XGB_PRC_AUC_1':[None]*14,\n",
    "                                'XGB_PRC_AUC_2':[None]*14,\n",
    "                                'LR_precision_1':[None]*14, \n",
    "                                'LR_precision_2':[None]*14, \n",
    "                                'LR_recall_1':[None]*14, \n",
    "                                'LR_recall_2':[None]*14, \n",
    "                                'LR_f1_1':[None]*14, \n",
    "                                'LR_f1_2':[None]*14, \n",
    "                                'LR_PRC_AUC_1':[None]*14, \n",
    "                                'LR_PRC_AUC_2':[None]*14,\n",
    "                                'RF_precision_1':[None]*14, \n",
    "                                'RF_precision_2':[None]*14,\n",
    "                                'RF_recall_1':[None]*14, \n",
    "                                'RF_recall_2':[None]*14,\n",
    "                                'RF_f1_1':[None]*14, \n",
    "                                'RF_f1_2':[None]*14,\n",
    "                                'RF_PRC_AUC_1':[None]*14, \n",
    "                                'RF_PRC_AUC_2':[None]*14})\n",
    "\n",
    "rankings = {'XGB':[], 'Logistic_Regression':[], 'Random_Forest':[]}\n",
    "\n",
    "files = ['ActiveMQ', 'Ant', 'Camel', 'Derby', 'Geronimo', 'Hadoop', 'HBase', 'Ivy', 'JCR', 'JMeter', 'LOG4J2', 'Lucene', 'Mahout', 'OpenJPA']\n",
    "\n",
    "for file_index in range(start, len(files)):\n",
    "    graph_df = pd.read_csv(f\"../Neo4j_output/Jit_Reliability_Output/{files[file_index]}.csv\")\n",
    "    print(graph_df.loc[graph_df['Bug'] == \"INTRODUCED_NEW_BUG\"])\n",
    "    new_columns = {}\n",
    "\n",
    "    # Generate binary classification for our dataframe based on if a developer \n",
    "    # introduced a bug or not with the corresponding commit\n",
    "    for index in graph_df.index:\n",
    "        if graph_df.loc[index, \"Bug\"] != \"INTRODUCED_NEW_BUG\":\n",
    "            graph_df.loc[index, \"Bug\"] = 0\n",
    "        else:\n",
    "            graph_df.loc[index, \"Bug\"] = 1\n",
    "\n",
    "        # separate each node2vec embedding into it's own unique label\n",
    "        embeddings = literal_eval(graph_df.loc[index, 'n2vEmbedding'])\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            if f\"emb_{i}\" not in new_columns:\n",
    "                new_columns[f\"emb_{i}\"] = []\n",
    "                new_columns[f\"emb_{i}\"].append(embedding)\n",
    "            else:\n",
    "                new_columns[f\"emb_{i}\"].append(embedding)\n",
    "\n",
    "    # delete the n2vEmbedding label, as the list has now been separated into their own unique labels \n",
    "    del graph_df['n2vEmbedding']\n",
    "    temp_df = pd.DataFrame.from_dict(new_columns)\n",
    "    graph_df = graph_df.join(temp_df)\n",
    "    \n",
    "    x = graph_df[\"Name\"]\n",
    "    y = graph_df[\"Bug\"].astype('int')\n",
    "\n",
    "    lr_model1 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    lr_model2 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    rf_model1 = RandomForestClassifier(n_estimators=120)\n",
    "    rf_model2 = RandomForestClassifier(n_estimators=120)\n",
    "    xgb_model1 = XGBClassifier(verbosity = 0)\n",
    "    xgb_model2 = XGBClassifier(verbosity = 0)\n",
    "\n",
    "    '''\n",
    "    train_test_split params\n",
    "    -----------------------\n",
    "    graph_df: Graph dataset\n",
    "    test_size: float value between 0.0 and 1.0 representing the precentage of data to be put into the test dataset\n",
    "    random_state = used to create reproducible, or deterministic results.\n",
    "    '''\n",
    "    try:\n",
    "        train, test = train_test_split(graph_df, test_size=0.30, random_state = 5)\n",
    "    except:\n",
    "        continue\n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "\n",
    "    # Labels used for model 1\n",
    "    labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "\n",
    "    # Labels used for model 2\n",
    "    labels2 = set(list(graph_df.columns))\n",
    "    labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "    x1_train = train[labels1]\n",
    "    x2_train = train[labels2]\n",
    "    y_train = train[\"Bug\"]\n",
    "    x1_test = test[labels1]\n",
    "    x2_test = test[labels2]\n",
    "    y_test = test[\"Bug\"]\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    lr_model1.fit(x1_train, y_train)\n",
    "    lr_model2.fit(x2_train, y_train)\n",
    "    rf_model1.fit(x1_train, y_train)\n",
    "    rf_model2.fit(x2_train, y_train)\n",
    "    xgb_model1.fit(x1_train, y_train)\n",
    "    xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "    lr_predictions1 = lr_model1.predict(x1_test)\n",
    "    lr_predictions2 = lr_model2.predict(x2_test)\n",
    "    lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "    lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "    rf_predictions1 = rf_model1.predict(x1_test)\n",
    "    rf_predictions2 = rf_model2.predict(x2_test)\n",
    "    rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "    rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "    xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "    xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "    xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "    xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "    results_data = [[None for j in range(15)] for i in range(72)]\n",
    "\n",
    "    # Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "    print(\"Original_Logistic_Regression model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[0][0] = \"Original_Logistic_Regression\"\n",
    "    results_data[0][1] = lr_model1.score(x1_test, y_test)\n",
    "    results_data[0][2] = lr_model2.score(x2_test, y_test)\n",
    "    results_data[0][3] = acc1\n",
    "    results_data[0][4] = acc2\n",
    "    results_data[0][5] = prc_val1\n",
    "    results_data[0][6] = prc_val2\n",
    "    results_data[0][7] = pr_auc1\n",
    "    results_data[0][8] = pr_auc2\n",
    "    results_data[0][9] = prec_1\n",
    "    results_data[0][10] = prec_2\n",
    "    results_data[0][11] = rec_1\n",
    "    results_data[0][12] = rec_2\n",
    "    results_data[0][13] = f1_1\n",
    "    results_data[0][14] = f1_2\n",
    "\n",
    "    print(\"Original_Random_Forrest model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[1][0] = \"Original_Random_Forrest\"\n",
    "    results_data[1][1] = rf_model1.score(x1_test, y_test)\n",
    "    results_data[1][2] = rf_model2.score(x2_test, y_test)\n",
    "    results_data[1][3] = acc1\n",
    "    results_data[1][4] = acc2\n",
    "    results_data[1][5] = prc_val1\n",
    "    results_data[1][6] = prc_val2\n",
    "    results_data[1][7] = pr_auc1\n",
    "    results_data[1][8] = pr_auc2\n",
    "    results_data[1][9] = prec_1\n",
    "    results_data[1][10] = prec_2\n",
    "    results_data[1][11] = rec_1\n",
    "    results_data[1][12] = rec_2\n",
    "    results_data[1][13] = f1_1\n",
    "    results_data[1][14] = f1_2\n",
    "\n",
    "    print(\"Original_XGB model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[2][0] = \"Original_XGB_Classifier\"\n",
    "    results_data[2][1] = xgb_model1.score(x1_test, y_test)\n",
    "    results_data[2][2] = xgb_model2.score(x2_test, y_test)\n",
    "    results_data[2][3] = acc1\n",
    "    results_data[2][4] = acc2\n",
    "    results_data[2][5] = prc_val1\n",
    "    results_data[2][6] = prc_val2\n",
    "    results_data[2][7] = pr_auc1\n",
    "    results_data[2][8] = pr_auc2\n",
    "    results_data[2][9] = prec_1\n",
    "    results_data[2][10] = prec_2\n",
    "    results_data[2][11] = rec_1\n",
    "    results_data[2][12] = rec_2\n",
    "    results_data[2][13] = f1_1\n",
    "    results_data[2][14] = f1_2\n",
    "\n",
    "    lr_best_threshold1, lr_best_threshold2, lr_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y_test, x2_test, y_test, lr_prediction_probs1, lr_prediction_probs2, \"original dataset Logistic Regression\")\n",
    "    rf_best_threshold1, rf_best_threshold2, rf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y_test, x2_test, y_test, rf_prediction_probs1, rf_prediction_probs2, \"original dataset Random Forrest\")\n",
    "    xgb_best_threshold1, xgb_best_threshold2, xgb_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y_test, x2_test, y_test, xgb_prediction_probs1, xgb_prediction_probs2, \"original dataset XGBoost\")\n",
    "\n",
    "    lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "    lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "    print(\"Original_Logistic_Regression_Best_Threshold model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "\n",
    "    results_data[3][0] = \"Original_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[3][1] = lr_model1.score(x1_test, y_test)\n",
    "    results_data[3][2] = lr_model2.score(x2_test, y_test)\n",
    "    results_data[3][3] = acc1\n",
    "    results_data[3][4] = acc2\n",
    "    results_data[3][5] = prc_val1\n",
    "    results_data[3][6] = prc_val2\n",
    "    results_data[3][7] = pr_auc1\n",
    "    results_data[3][8] = pr_auc2\n",
    "    results_data[3][9] = prec_1\n",
    "    results_data[3][10] = prec_2\n",
    "    results_data[3][11] = rec_1\n",
    "    results_data[3][12] = rec_2\n",
    "    results_data[3][13] = f1_1\n",
    "    results_data[3][14] = f1_2\n",
    "\n",
    "    rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "    rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "    print(\"Original_Random_Forrest_Best_Threshold model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    \n",
    "    results_data[4][0] = \"Original_Random_Forrest_Best_Threshold\"\n",
    "    results_data[4][1] = rf_model1.score(x1_test, y_test)\n",
    "    results_data[4][2] = rf_model2.score(x2_test, y_test)\n",
    "    results_data[4][3] = acc1\n",
    "    results_data[4][4] = acc2\n",
    "    results_data[4][5] = prc_val1\n",
    "    results_data[4][6] = prc_val2\n",
    "    results_data[4][7] = pr_auc1\n",
    "    results_data[4][8] = pr_auc2\n",
    "    results_data[4][9] = prec_1\n",
    "    results_data[4][10] = prec_2\n",
    "    results_data[4][11] = rec_1\n",
    "    results_data[4][12] = rec_2\n",
    "    results_data[4][13] = f1_1\n",
    "    results_data[4][14] = f1_2\n",
    "\n",
    "    xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "    xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "    print(\"Original_XGBoost_Classifier_Best_Threshold model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    \n",
    "    results_data[5][0] = \"Original_XGBoost_Classifier_Best_Threshold\"\n",
    "    results_data[5][1] = xgb_model1.score(x1_test, y_test)\n",
    "    results_data[5][2] = xgb_model2.score(x2_test, y_test)\n",
    "    results_data[5][3] = acc1\n",
    "    results_data[5][4] = acc2\n",
    "    results_data[5][5] = prc_val1\n",
    "    results_data[5][6] = prc_val2\n",
    "    results_data[5][7] = pr_auc1\n",
    "    results_data[5][8] = pr_auc2\n",
    "    results_data[5][9] = prec_1\n",
    "    results_data[5][10] = prec_2\n",
    "    results_data[5][11] = rec_1\n",
    "    results_data[5][12] = rec_2\n",
    "    results_data[5][13] = f1_1\n",
    "    results_data[5][14] = f1_2\n",
    "\n",
    "    x1 = graph_df[labels1]\n",
    "    x2 = graph_df[labels2]\n",
    "    y = graph_df['Bug'].astype('int')\n",
    "\n",
    "    print(\"Original_XGBoost_Classifier_Best_Threshold model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, x1, y)\n",
    "    \n",
    "    results_data[6][0] = \"Original_Logistic_Regression_rkf\"\n",
    "    results_data[6][1] = model_score\n",
    "    results_data[6][3] = acc\n",
    "    results_data[6][5] = prc_val\n",
    "    results_data[6][7] = pr_auc\n",
    "    results_data[6][9] = precision\n",
    "    results_data[6][11] = recall\n",
    "    results_data[6][13] = f1\n",
    "    print(\"---------------------\")\n",
    "    print(\"With best threshold\")\n",
    "    \n",
    "    print(\"Original_Logistic_Regression_rkf_Best_Threshold model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, x1, y, lr_best_threshold1)\n",
    "    results_data[7][0] = \"Original_Logistic_Regression_rkf_Best_Threshold\"\n",
    "    results_data[7][1] = model_score\n",
    "    results_data[7][3] = acc\n",
    "    results_data[7][5] = prc_val\n",
    "    results_data[7][7] = pr_auc\n",
    "    results_data[7][9] = precision\n",
    "    results_data[7][11] = recall\n",
    "    results_data[7][13] = f1\n",
    "\n",
    "    # Rkf_short(lr_model1, x1, y)\n",
    "    print(\"Original_Random_Forrest_rkf model 1\")\n",
    "    model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1, precision, recall, f1 = Rkf(rf_model1, x1, y)\n",
    "    results_data[8][0] = \"Original_Random_Forrest_rkf\"\n",
    "    results_data[8][1] = model_score\n",
    "    results_data[8][3] = acc\n",
    "    results_data[8][5] = prc_val\n",
    "    results_data[8][7] = pr_auc\n",
    "    results_data[8][9] = precision\n",
    "    results_data[8][11] = recall\n",
    "    results_data[8][13] = f1\n",
    "\n",
    "    print(\"Original_XGB_Classifier_rkf model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1, precision, recall, f1 = Rkf(xgb_model1, x1, y)\n",
    "    results_data[9][0] = \"Original_XGB_Classifier_rkf\"\n",
    "    results_data[9][1] = model_score\n",
    "    results_data[9][3] = acc\n",
    "    results_data[9][5] = prc_val\n",
    "    results_data[9][7] = pr_auc\n",
    "    results_data[9][9] = precision\n",
    "    results_data[9][11] = recall\n",
    "    results_data[9][13] = f1\n",
    "\n",
    "    print(\"Original_Logistic_Regression_skf model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1, precision, recall, f1 = Skf(lr_model1, x1, y)\n",
    "    results_data[10][0] = \"Original_Logistic_Regression_skf\"\n",
    "    results_data[10][1] = model_score\n",
    "    results_data[10][3] = acc\n",
    "    results_data[10][5] = prc_val\n",
    "    results_data[10][7] = pr_auc\n",
    "    results_data[10][9] = precision\n",
    "    results_data[10][11] = recall\n",
    "    results_data[10][13] = f1\n",
    "\n",
    "    print(\"Original_Logistic_Regression_skf_Best_Threshold model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_skf_best_prediction_probs1, precision, recall, f1 = Skf(lr_model1, x1, y, lr_best_threshold1)\n",
    "    results_data[11][0] = \"Original_Logistic_Regression_skf_Best_Threshold\"\n",
    "    results_data[11][1] = model_score\n",
    "    results_data[11][3] = acc\n",
    "    results_data[11][5] = prc_val\n",
    "    results_data[11][7] = pr_auc\n",
    "    results_data[11][9] = precision\n",
    "    results_data[11][11] = recall\n",
    "    results_data[11][13] = f1\n",
    "\n",
    "    print(\"Original_Random_Forrest_skf model 1\")\n",
    "    # Skf_short(lr_model1, x1, y)\n",
    "    model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1, precision, recall, f1 = Skf(rf_model1, x1, y)\n",
    "    results_data[12][0] = \"Original_Random_Forrest_skf\"\n",
    "    results_data[12][1] = model_score\n",
    "    results_data[12][3] = acc\n",
    "    results_data[12][5] = prc_val\n",
    "    results_data[12][7] = pr_auc\n",
    "    results_data[12][9] = precision\n",
    "    results_data[12][11] = recall\n",
    "    results_data[12][13] = f1\n",
    "\n",
    "    print(\"Original_XGB_Classifier_skf model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1, precision, recall, f1 = Skf(xgb_model1, x1, y)\n",
    "    results_data[13][0] = \"Original_XGB_Classifier_skf\"\n",
    "    results_data[13][1] = model_score\n",
    "    results_data[13][3] = acc\n",
    "    results_data[13][5] = prc_val\n",
    "    results_data[13][7] = pr_auc\n",
    "    results_data[13][9] = precision\n",
    "    results_data[13][11] = recall\n",
    "    results_data[13][13] = f1\n",
    "\n",
    "    print(\"Original_Logistic_Regression_tss model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1, precision, recall, f1 = Tss(lr_model1, x1, y)\n",
    "    results_data[14][0] = \"Original_Logistic_Regression_tss\"\n",
    "    results_data[14][1] = model_score\n",
    "    results_data[14][3] = acc\n",
    "    results_data[14][5] = prc_val\n",
    "    results_data[14][7] = pr_auc\n",
    "    results_data[14][9] = precision\n",
    "    results_data[14][11] = recall\n",
    "    results_data[14][13] = f1\n",
    "\n",
    "    print(\"Original_Logistic_Regression_tss_Best_Threshold model 1\")\n",
    "    model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1, precision, recall, f1 = Tss(lr_model1, x1, y, lr_best_threshold1)\n",
    "    results_data[15][0] = \"Original_Logistic_Regression_tss_Best_Threshold\"\n",
    "    results_data[15][1] = model_score\n",
    "    results_data[15][3] = acc\n",
    "    results_data[15][5] = prc_val\n",
    "    results_data[15][7] = pr_auc\n",
    "    results_data[15][9] = precision\n",
    "    results_data[15][11] = recall\n",
    "    results_data[15][13] = f1\n",
    "\n",
    "    # Skf_short(lr_model1, x1, y)\n",
    "    print(\"Original_Random_Forrest_tss model 1\")\n",
    "    model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1, precision, recall, f1 = Tss(rf_model1, x1, y)\n",
    "    results_data[16][0] = \"Original_Random_Forrest_tss\"\n",
    "    results_data[16][1] = model_score\n",
    "    results_data[16][3] = acc\n",
    "    results_data[16][5] = prc_val\n",
    "    results_data[16][7] = pr_auc\n",
    "    results_data[16][9] = precision\n",
    "    results_data[16][11] = recall\n",
    "    results_data[16][13] = f1\n",
    "\n",
    "    print(\"Original_XGB_Classifier_tss model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1, precision, recall, f1 = Tss(xgb_model1, x1, y)\n",
    "    results_data[17][0] = \"Original_XGB_Classifier_tss\"\n",
    "    results_data[17][1] = model_score\n",
    "    results_data[17][3] = acc\n",
    "    results_data[17][5] = prc_val\n",
    "    results_data[17][7] = pr_auc\n",
    "    results_data[17][9] = precision\n",
    "    results_data[17][11] = recall\n",
    "    results_data[17][13] = f1\n",
    "\n",
    "    # ---- Data for Model 2 ----\n",
    "    print(\"Row 6 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, x2, y)\n",
    "    results_data[6][2] = model_score\n",
    "    results_data[6][4] = acc\n",
    "    results_data[6][6] = prc_val\n",
    "    results_data[6][8] = pr_auc\n",
    "    results_data[6][10] = precision\n",
    "    results_data[6][12] = recall\n",
    "    results_data[6][14] = f1\n",
    "\n",
    "    print(\"Row 7 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, x2, y, lr_best_threshold2)\n",
    "    results_data[7][2] = model_score\n",
    "    results_data[7][4] = acc\n",
    "    results_data[7][6] = prc_val\n",
    "    results_data[7][8] = pr_auc\n",
    "    results_data[7][10] = precision\n",
    "    results_data[7][12] = recall\n",
    "    results_data[7][14] = f1\n",
    "\n",
    "    # Rkf_short(lr_model2, x2, y)\n",
    "\n",
    "    print(\"Row 8 model 2\")\n",
    "    model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2, precision, recall, f1 = Rkf(rf_model2, x2, y)\n",
    "    results_data[8][2] = model_score\n",
    "    results_data[8][4] = acc\n",
    "    results_data[8][6] = prc_val\n",
    "    results_data[8][8] = pr_auc\n",
    "    results_data[8][10] = precision\n",
    "    results_data[8][12] = recall\n",
    "    results_data[8][14] = f1\n",
    "\n",
    "    print(\"Row 9 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2, precision, recall, f1 = Rkf(xgb_model2, x2, y)\n",
    "    results_data[9][2] = model_score\n",
    "    results_data[9][4] = acc\n",
    "    results_data[9][6] = prc_val\n",
    "    results_data[9][8] = pr_auc\n",
    "    results_data[9][10] = precision\n",
    "    results_data[9][12] = recall\n",
    "    results_data[9][14] = f1\n",
    "\n",
    "    print(\"Row 10 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2, precision, recall, f1 = Skf(lr_model2, x2, y)\n",
    "    results_data[10][2] = model_score\n",
    "    results_data[10][4] = acc\n",
    "    results_data[10][6] = prc_val\n",
    "    results_data[10][8] = pr_auc\n",
    "    results_data[10][10] = precision\n",
    "    results_data[10][12] = recall\n",
    "    results_data[10][14] = f1\n",
    "\n",
    "    print(\"Row 11 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2, precision, recall, f1 = Skf(lr_model2, x2, y, lr_best_threshold2)\n",
    "    results_data[11][2] = model_score\n",
    "    results_data[11][4] = acc\n",
    "    results_data[11][6] = prc_val\n",
    "    results_data[11][8] = pr_auc\n",
    "    results_data[11][10] = precision\n",
    "    results_data[11][12] = recall\n",
    "    results_data[11][14] = f1\n",
    "\n",
    "    print(\"Row 12 model 2\")\n",
    "    # Skf_short(lr_model2, x2, y)\n",
    "    model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2, precision, recall, f1 = Skf(rf_model2, x2, y)\n",
    "    results_data[12][2] = model_score\n",
    "    results_data[12][4] = acc\n",
    "    results_data[12][6] = prc_val\n",
    "    results_data[12][8] = pr_auc\n",
    "    results_data[12][10] = precision\n",
    "    results_data[12][12] = recall\n",
    "    results_data[12][14] = f1\n",
    "\n",
    "    print(\"Row 13 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2, precision, recall, f1 = Skf(xgb_model2, x2, y)\n",
    "    results_data[13][2] = model_score\n",
    "    results_data[13][4] = acc\n",
    "    results_data[13][6] = prc_val\n",
    "    results_data[13][8] = pr_auc\n",
    "    results_data[13][10] = precision\n",
    "    results_data[13][12] = recall\n",
    "    results_data[13][14] = f1\n",
    "\n",
    "    print(\"Row 14 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2, precision, recall, f1 = Tss(lr_model2, x2, y)\n",
    "    results_data[14][2] = model_score\n",
    "    results_data[14][4] = acc\n",
    "    results_data[14][6] = prc_val\n",
    "    results_data[14][8] = pr_auc\n",
    "    results_data[14][10] = precision\n",
    "    results_data[14][12] = recall\n",
    "    results_data[14][14] = f1\n",
    "\n",
    "    print(\"Row 15 model 2\")\n",
    "    model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2, precision, recall, f1 = Tss(lr_model2, x2, y, lr_best_threshold2)\n",
    "    results_data[15][2] = model_score\n",
    "    results_data[15][4] = acc\n",
    "    results_data[15][6] = prc_val\n",
    "    results_data[15][8] = pr_auc\n",
    "    results_data[15][10] = precision\n",
    "    results_data[15][12] = recall\n",
    "    results_data[15][14] = f1\n",
    "\n",
    "    print(\"Row 16 model 2\")\n",
    "    # Skf_short(lr_model2, x2, y)\n",
    "    model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2, precision, recall, f1 = Tss(rf_model2, x2, y)\n",
    "    results_data[16][2] = model_score\n",
    "    results_data[16][4] = acc\n",
    "    results_data[16][6] = prc_val\n",
    "    results_data[16][8] = pr_auc\n",
    "    results_data[16][10] = precision\n",
    "    results_data[16][12] = recall\n",
    "    results_data[16][14] = f1\n",
    "\n",
    "    print(\"Row 17 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2, precision, recall, f1 = Tss(xgb_model2, x2, y)\n",
    "    results_data[17][2] = model_score\n",
    "    results_data[17][4] = acc\n",
    "    results_data[17][6] = prc_val\n",
    "    results_data[17][8] = pr_auc\n",
    "    results_data[17][10] = precision\n",
    "    results_data[17][12] = recall\n",
    "    results_data[17][14] = f1\n",
    "\n",
    "    lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"original dataset Logistic Regression Rkf\")\n",
    "    rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"original dataset Random Forrest Rkf\")\n",
    "    xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"original dataset XGBoost Rkf\")\n",
    "\n",
    "    lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"original dataset Logistic Regression Skf\")\n",
    "    rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"original dataset Random Forrest Skf\")\n",
    "    xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"original dataset XGBoost Skf\")\n",
    "\n",
    "    lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"original dataset Logistic Regression Tss\")\n",
    "    rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"original dataset Random Forrest Tss\")\n",
    "    xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"original dataset XGBoost Tss\")\n",
    "\n",
    "    # Perform undersampling\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    \n",
    "    bug_df = graph_df.loc[graph_df['Bug'] == 1]\n",
    "    non_bug_df = graph_df.loc[graph_df['Bug'] == 0]\n",
    "    normalized_under_df = pd.concat([bug_df, non_bug_df])\n",
    "    normalized_under_df = normalized_under_df.reset_index()\n",
    "    print(normalized_under_df['Bug'].value_counts())\n",
    "\n",
    "    usx1 = normalized_under_df[labels1]\n",
    "    usx2 = normalized_under_df[labels2]\n",
    "    usy = normalized_under_df[\"Bug\"].astype('int')\n",
    "    usy = usy.sample(frac=1).reset_index(drop=True) # shuffle dataset\n",
    "    usy1 = usy\n",
    "    usy2 = usy\n",
    "    \n",
    "    usx1, usy1 = rus.fit_resample(usx1, usy1)\n",
    "    usx2, usy2 = rus.fit_resample(usx2, usy2)\n",
    "\n",
    "    train, test = train_test_split(normalized_under_df, test_size=0.30, random_state = 5)\n",
    "\n",
    "    labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "    labels2 = set(list(normalized_under_df.columns))\n",
    "    labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "    x1_train = train[labels1]\n",
    "    x2_train = train[labels2]\n",
    "    y_train = train[\"Bug\"].astype('int')\n",
    "    x1_test = test[labels1]\n",
    "    x2_test = test[labels2]\n",
    "    y_test = test[\"Bug\"].astype('int')\n",
    "\n",
    "    lr_model1.fit(x1_train, y_train)\n",
    "    lr_model2.fit(x2_train, y_train)\n",
    "    rf_model1.fit(x1_train, y_train)\n",
    "    rf_model2.fit(x2_train, y_train)\n",
    "    xgb_model1.fit(x1_train, y_train)\n",
    "    xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "    lr_predictions1 = lr_model1.predict(x1_test)\n",
    "    lr_predictions2 = lr_model2.predict(x2_test)\n",
    "    lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "    lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "    rf_predictions1 = rf_model1.predict(x1_test)\n",
    "    rf_predictions2 = rf_model2.predict(x2_test)\n",
    "    rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "    rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "    xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "    xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "    xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "    xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "    # Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "    results_data[18][0] = \"Undersampled_Logistic_Regression\"\n",
    "    results_data[18][1] = lr_model1.score(x1_test, y_test)\n",
    "    results_data[18][2] = lr_model2.score(x2_test, y_test)\n",
    "\n",
    "    results_data[19][0] = \"Undersampled_Random_Forrest\"\n",
    "    results_data[19][1] = rf_model1.score(x1_test, y_test)\n",
    "    results_data[19][2] = rf_model2.score(x2_test, y_test)\n",
    "\n",
    "    results_data[20][0] = \"Undersampled_XGB_Classifier\"\n",
    "    results_data[20][1] = xgb_model1.score(x1_test, y_test)\n",
    "    results_data[20][2] = xgb_model2.score(x2_test, y_test)\n",
    "\n",
    "    print(\"Row 18 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[18][3] = acc1\n",
    "    results_data[18][4] = acc2\n",
    "    results_data[18][5] = prc_val1\n",
    "    results_data[18][6] = prc_val2\n",
    "    results_data[18][7] = pr_auc1\n",
    "    results_data[18][8] = pr_auc2\n",
    "    results_data[18][9] = prec_1\n",
    "    results_data[18][10] = prec_2\n",
    "    results_data[18][11] = rec_1\n",
    "    results_data[18][12] = rec_2\n",
    "    results_data[18][13] = f1_1\n",
    "    results_data[18][14] = f1_2\n",
    "\n",
    "    print(\"Row 19 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[19][3] = acc1\n",
    "    results_data[19][4] = acc2\n",
    "    results_data[19][5] = prc_val1\n",
    "    results_data[19][6] = prc_val2\n",
    "    results_data[19][7] = pr_auc1\n",
    "    results_data[19][8] = pr_auc2\n",
    "    results_data[19][9] = prec_1\n",
    "    results_data[19][10] = prec_2\n",
    "    results_data[19][11] = rec_1\n",
    "    results_data[19][12] = rec_2\n",
    "    results_data[19][13] = f1_1\n",
    "    results_data[19][14] = f1_2\n",
    "\n",
    "    print(\"Row 20 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[20][3] = acc1\n",
    "    results_data[20][4] = acc2\n",
    "    results_data[20][5] = prc_val1\n",
    "    results_data[20][6] = prc_val2\n",
    "    results_data[20][7] = pr_auc1\n",
    "    results_data[20][8] = pr_auc2\n",
    "    results_data[20][9] = prec_1\n",
    "    results_data[20][10] = prec_2\n",
    "    results_data[20][11] = rec_1\n",
    "    results_data[20][12] = rec_2\n",
    "    results_data[20][13] = f1_1\n",
    "    results_data[20][14] = f1_2\n",
    "\n",
    "    lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "    lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[21][0] = \"Undersampled_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[21][1] = lr_model1.score(x1_test, y_test)\n",
    "    results_data[21][2] = lr_model2.score(x2_test, y_test)\n",
    "    results_data[21][3] = acc1\n",
    "    results_data[21][4] = acc2\n",
    "    results_data[21][5] = prc_val1\n",
    "    results_data[21][6] = prc_val2\n",
    "    results_data[21][7] = pr_auc1\n",
    "    results_data[21][8] = pr_auc2\n",
    "    results_data[21][9] = prec_1\n",
    "    results_data[21][10] = prec_2\n",
    "    results_data[21][11] = rec_1\n",
    "    results_data[21][12] = rec_2\n",
    "    results_data[21][13] = f1_1\n",
    "    results_data[21][14] = f1_2\n",
    "\n",
    "    rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "    rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[22][0] = \"Undersampled_Random_Forrest_Best_Threshold\"\n",
    "    results_data[22][1] = rf_model1.score(x1_test, y_test)\n",
    "    results_data[22][2] = rf_model2.score(x2_test, y_test)\n",
    "    results_data[22][3] = acc1\n",
    "    results_data[22][4] = acc2\n",
    "    results_data[22][5] = prc_val1\n",
    "    results_data[22][6] = prc_val2\n",
    "    results_data[22][7] = pr_auc1\n",
    "    results_data[22][8] = pr_auc2\n",
    "    results_data[22][9] = prec_1\n",
    "    results_data[22][10] = prec_2\n",
    "    results_data[22][11] = rec_1\n",
    "    results_data[22][12] = rec_2\n",
    "    results_data[22][13] = f1_1\n",
    "    results_data[22][14] = f1_2\n",
    "\n",
    "    xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "    xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "    print(\"Row 23 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[23][0] = \"Undersampled_XGB_Classifier_Best_Threshold\"\n",
    "    results_data[23][1] = xgb_model1.score(x1_test, y_test)\n",
    "    results_data[23][2] = xgb_model2.score(x2_test, y_test)\n",
    "    results_data[23][3] = acc1\n",
    "    results_data[23][4] = acc2\n",
    "    results_data[23][5] = prc_val1\n",
    "    results_data[23][6] = prc_val2\n",
    "    results_data[23][7] = pr_auc1\n",
    "    results_data[23][8] = pr_auc2\n",
    "    results_data[23][9] = prec_1\n",
    "    results_data[23][10] = prec_2\n",
    "    results_data[23][11] = rec_1\n",
    "    results_data[23][12] = rec_2\n",
    "    results_data[23][13] = f1_1\n",
    "    results_data[23][14] = f1_2\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, usx1, usy1)\n",
    "    results_data[24][0] = \"Undersampled_Logistic_Regression_rkf\"\n",
    "    results_data[24][1] = model_score\n",
    "    results_data[24][3] = acc\n",
    "    results_data[24][5] = prc_val\n",
    "    results_data[24][7] = pr_auc\n",
    "    results_data[24][9] = precision\n",
    "    results_data[24][11] = recall\n",
    "    results_data[24][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, usx1, usy1, lr_best_threshold1)\n",
    "    results_data[25][0] = \"Undersampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "    results_data[25][1] = model_score\n",
    "    results_data[25][3] = acc\n",
    "    results_data[25][5] = prc_val\n",
    "    results_data[25][7] = pr_auc\n",
    "    results_data[25][9] = precision\n",
    "    results_data[25][11] = recall\n",
    "    results_data[25][13] = f1\n",
    "\n",
    "    #Rkf_short(lr_model1, usx1, usy)\n",
    "    model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1, precision, recall, f1 = Rkf(rf_model1, usx1, usy1)\n",
    "    results_data[26][0] = \"Undersampled_Random_Forrest_rkf\"\n",
    "    results_data[26][1] = model_score\n",
    "    results_data[26][3] = acc\n",
    "    results_data[26][5] = prc_val\n",
    "    results_data[26][7] = pr_auc\n",
    "    results_data[26][9] = precision\n",
    "    results_data[26][11] = recall\n",
    "    results_data[26][13] = f1\n",
    "\n",
    "    print(\"Row 27 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1, precision, recall, f1 = Rkf(xgb_model1, usx1, usy1)\n",
    "    results_data[27][0] = \"Undersampled_XGB_Classifier_rkf\"\n",
    "    results_data[27][1] = model_score\n",
    "    results_data[27][3] = acc\n",
    "    results_data[27][5] = prc_val\n",
    "    results_data[27][7] = pr_auc\n",
    "    results_data[27][9] = precision\n",
    "    results_data[27][11] = recall\n",
    "    results_data[27][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1, precision, recall, f1 = Skf(lr_model1, usx1, usy1)\n",
    "    results_data[28][0] = \"Undersampled_Logistic_Regression_skf\"\n",
    "    results_data[28][1] = model_score\n",
    "    results_data[28][3] = acc\n",
    "    results_data[28][5] = prc_val\n",
    "    results_data[28][7] = pr_auc\n",
    "    results_data[28][9] = precision\n",
    "    results_data[28][11] = recall\n",
    "    results_data[28][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1, precision, recall, f1 = Skf(lr_model1, usx1, usy1, lr_best_threshold1)\n",
    "    results_data[29][0] = \"Undersampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "    results_data[29][1] = model_score\n",
    "    results_data[29][3] = acc\n",
    "    results_data[29][5] = prc_val\n",
    "    results_data[29][7] = pr_auc\n",
    "    results_data[29][9] = precision\n",
    "    results_data[29][11] = recall\n",
    "    results_data[29][13] = f1\n",
    "\n",
    "    # Skf_short(lr_model1, usx1, usy)\n",
    "\n",
    "    model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1, precision, recall, f1 = Skf(rf_model1, usx1, usy1)\n",
    "    results_data[30][0] = \"Undersampled_Random_Forrest_skf\"\n",
    "    results_data[30][1] = model_score\n",
    "    results_data[30][3] = acc\n",
    "    results_data[30][5] = prc_val\n",
    "    results_data[30][7] = pr_auc\n",
    "    results_data[30][9] = precision\n",
    "    results_data[30][11] = recall\n",
    "    results_data[30][13] = f1\n",
    "\n",
    "    print(\"Row 31 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1, precision, recall, f1 = Skf(xgb_model1, usx1, usy1)\n",
    "    results_data[31][0] = \"Undersampled_XGB_Classifier_skf\"\n",
    "    results_data[31][1] = model_score\n",
    "    results_data[31][3] = acc\n",
    "    results_data[31][5] = prc_val\n",
    "    results_data[31][7] = pr_auc\n",
    "    results_data[31][9] = precision\n",
    "    results_data[31][11] = recall\n",
    "    results_data[31][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1, precision, recall, f1 = Tss(lr_model1, usx1, usy1)\n",
    "    results_data[32][0] = \"Undersampled_Logistic_Regression_tss\"\n",
    "    results_data[32][1] = model_score\n",
    "    results_data[32][3] = acc\n",
    "    results_data[32][5] = prc_val\n",
    "    results_data[32][7] = pr_auc\n",
    "    results_data[32][9] = precision\n",
    "    results_data[32][11] = recall\n",
    "    results_data[32][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1, precision, recall, f1 = Tss(lr_model1, usx1, usy1, lr_best_threshold1)\n",
    "    results_data[33][0] = \"Undersampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "    results_data[33][1] = model_score\n",
    "    results_data[33][3] = acc\n",
    "    results_data[33][5] = prc_val\n",
    "    results_data[33][7] = pr_auc\n",
    "    results_data[33][9] = precision\n",
    "    results_data[33][11] = recall\n",
    "    results_data[33][13] = f1\n",
    "\n",
    "    # Skf_short(lr_model1, usx1, usy)\n",
    "    model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1, precision, recall, f1 = Tss(rf_model1, usx1, usy1)\n",
    "    results_data[34][0] = \"Undersampled_Random_Forrest_tss\"\n",
    "    results_data[34][1] = model_score\n",
    "    results_data[34][3] = acc\n",
    "    results_data[34][5] = prc_val\n",
    "    results_data[34][7] = pr_auc\n",
    "    results_data[34][9] = precision\n",
    "    results_data[34][11] = recall\n",
    "    results_data[34][13] = f1\n",
    "\n",
    "    print(\"Row 35 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1, precision, recall, f1 = Tss(xgb_model1, usx1, usy1)\n",
    "    results_data[35][0] = \"Undersampled_XGB_Classifier_tss\"\n",
    "    results_data[35][1] = model_score\n",
    "    results_data[35][3] = acc\n",
    "    results_data[35][5] = prc_val\n",
    "    results_data[35][7] = pr_auc\n",
    "    results_data[35][9] = precision\n",
    "    results_data[35][11] = recall\n",
    "    results_data[35][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, usx2, usy2)\n",
    "    results_data[24][2] = model_score\n",
    "    results_data[24][4] = acc\n",
    "    results_data[24][6] = prc_val\n",
    "    results_data[24][8] = pr_auc\n",
    "    results_data[24][10] = precision\n",
    "    results_data[24][12] = recall\n",
    "    results_data[24][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, usx2, usy2, lr_best_threshold2)\n",
    "    results_data[25][2] = model_score\n",
    "    results_data[25][4] = acc\n",
    "    results_data[25][6] = prc_val\n",
    "    results_data[25][8] = pr_auc\n",
    "    results_data[25][10] = precision\n",
    "    results_data[25][12] = recall\n",
    "    results_data[25][14] = f1\n",
    "\n",
    "    # Rkf_short(lr_model2, usx2, usy)\n",
    "    model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2, precision, recall, f1 = Rkf(rf_model2, usx2, usy2)\n",
    "    results_data[26][2] = model_score\n",
    "    results_data[26][4] = acc\n",
    "    results_data[26][6] = prc_val\n",
    "    results_data[26][8] = pr_auc\n",
    "    results_data[26][10] = precision\n",
    "    results_data[26][12] = recall\n",
    "    results_data[26][14] = f1\n",
    "\n",
    "    print(\"Row 27 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2, precision, recall, f1 = Rkf(xgb_model2, usx2, usy2)\n",
    "    results_data[27][2] = model_score\n",
    "    results_data[27][4] = acc\n",
    "    results_data[27][6] = prc_val\n",
    "    results_data[27][8] = pr_auc\n",
    "    results_data[27][10] = precision\n",
    "    results_data[27][12] = recall\n",
    "    results_data[27][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2, precision, recall, f1 = Skf(lr_model2, usx2, usy2)\n",
    "    results_data[28][2] = model_score\n",
    "    results_data[28][4] = acc\n",
    "    results_data[28][6] = prc_val\n",
    "    results_data[28][8] = pr_auc\n",
    "    results_data[28][10] = precision\n",
    "    results_data[28][12] = recall\n",
    "    results_data[28][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2, precision, recall, f1 = Skf(lr_model2, usx2, usy2, lr_best_threshold2)\n",
    "    results_data[29][2] = model_score\n",
    "    results_data[29][4] = acc\n",
    "    results_data[29][6] = prc_val\n",
    "    results_data[29][8] = pr_auc\n",
    "    results_data[29][10] = precision\n",
    "    results_data[29][12] = recall\n",
    "    results_data[29][14] = f1\n",
    "\n",
    "    # Skf_short(lr_model2, usx2, usy)\n",
    "    model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2, precision, recall, f1 = Skf(rf_model2, usx2, usy2)\n",
    "    results_data[30][2] = model_score\n",
    "    results_data[30][4] = acc\n",
    "    results_data[30][6] = prc_val\n",
    "    results_data[30][8] = pr_auc\n",
    "    results_data[30][10] = precision\n",
    "    results_data[30][12] = recall\n",
    "    results_data[30][14] = f1\n",
    "\n",
    "    print(\"Row 31 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2, precision, recall, f1 = Skf(xgb_model2, usx2, usy2)\n",
    "    results_data[31][2] = model_score\n",
    "    results_data[31][4] = acc\n",
    "    results_data[31][6] = prc_val\n",
    "    results_data[31][8] = pr_auc\n",
    "    results_data[31][10] = precision\n",
    "    results_data[31][12] = recall\n",
    "    results_data[31][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2, precision, recall, f1 = Tss(lr_model2, usx2, usy)\n",
    "    results_data[32][2] = model_score\n",
    "    results_data[32][4] = acc\n",
    "    results_data[32][6] = prc_val\n",
    "    results_data[32][8] = pr_auc\n",
    "    results_data[32][10] = precision\n",
    "    results_data[32][12] = recall\n",
    "    results_data[32][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2, precision, recall, f1 = Tss(lr_model2, usx2, usy2, lr_best_threshold2)\n",
    "    results_data[33][2] = model_score\n",
    "    results_data[33][4] = acc\n",
    "    results_data[33][6] = prc_val\n",
    "    results_data[33][8] = pr_auc\n",
    "    results_data[33][10] = precision\n",
    "    results_data[33][12] = recall\n",
    "    results_data[33][14] = f1\n",
    "\n",
    "    # Skf_short(lr_model2, usx2, usy)\n",
    "    model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2, precision, recall, f1 = Tss(rf_model2, usx2, usy2)\n",
    "    results_data[34][2] = model_score\n",
    "    results_data[34][4] = acc\n",
    "    results_data[34][6] = prc_val\n",
    "    results_data[34][8] = pr_auc\n",
    "    results_data[34][10] = precision\n",
    "    results_data[34][12] = recall\n",
    "    results_data[34][14] = f1\n",
    "\n",
    "    print(\"Row 35 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2, precision, recall, f1 = Tss(xgb_model2, usx2, usy2)\n",
    "    results_data[35][2] = model_score\n",
    "    results_data[35][4] = acc\n",
    "    results_data[35][6] = prc_val\n",
    "    results_data[35][8] = pr_auc\n",
    "    results_data[35][10] = precision\n",
    "    results_data[35][12] = recall\n",
    "    results_data[35][14] = f1\n",
    "\n",
    "    # Oversampling\n",
    "    x1 = graph_df[labels1]\n",
    "    x2 = graph_df[labels2]\n",
    "    y = graph_df[\"Bug\"].astype('int')\n",
    "    # For oversampling we will use SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    # Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
    "    sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "\n",
    "    # Fit the model to generate the data for Model 1.\n",
    "    oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "    # Fit the model to generate the data for Model 2.\n",
    "    oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "    osx1 = oversampled_X1\n",
    "    osx2 = oversampled_X2\n",
    "    osy1 = oversampled_Y1\n",
    "    osy2 = oversampled_Y2\n",
    "\n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(osx1, osy1, test_size=0.3, random_state = 5)\n",
    "    #x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(osx2, osy2, test_size=0.3, random_state = 5)\n",
    "    #x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "    lr_model1.fit(x1_train, y1_train)\n",
    "    lr_model2.fit(x2_train, y2_train)\n",
    "    rf_model1.fit(x1_train, y1_train)\n",
    "    rf_model2.fit(x2_train, y2_train)\n",
    "    xgb_model1.fit(x1_train, y1_train)\n",
    "    xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "    lr_predictions1 = lr_model1.predict(x1_test)\n",
    "    lr_predictions2 = lr_model2.predict(x2_test)\n",
    "    lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "    lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "    rf_predictions1 = rf_model1.predict(x1_test)\n",
    "    rf_predictions2 = rf_model2.predict(x2_test)\n",
    "    rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "    rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "    xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "    xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "    xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "    xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "    # Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "    results_data[36][0] = \"Oversampled_Logistic_Regression\"\n",
    "    results_data[36][1] = lr_model1.score(x1_test, y1_test)\n",
    "    results_data[36][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "    results_data[37][0] = \"Oversampled_Random_Forrest\"\n",
    "    results_data[37][1] = rf_model1.score(x1_test, y1_test)\n",
    "    results_data[37][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "    results_data[38][0] = \"Oversampled_XGB_Classifier\"\n",
    "    results_data[38][1] = xgb_model1.score(x1_test, y1_test)\n",
    "    results_data[38][2] = xgb_model2.score(x2_test, y2_test)\n",
    "\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[36][3] = acc1\n",
    "    results_data[36][4] = acc2\n",
    "    results_data[36][5] = prc_val1\n",
    "    results_data[36][6] = prc_val2\n",
    "    results_data[36][7] = pr_auc1\n",
    "    results_data[36][8] = pr_auc2\n",
    "    results_data[36][9] = prec_1\n",
    "    results_data[36][10] = prec_2\n",
    "    results_data[36][11] = rec_1\n",
    "    results_data[36][12] = rec_2\n",
    "    results_data[36][13] = f1_1\n",
    "    results_data[36][14] = f1_2\n",
    "\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[37][3] = acc1\n",
    "    results_data[37][4] = acc2\n",
    "    results_data[37][5] = prc_val1\n",
    "    results_data[37][6] = prc_val2\n",
    "    results_data[37][7] = pr_auc1\n",
    "    results_data[37][8] = pr_auc2\n",
    "    results_data[37][9] = prec_1\n",
    "    results_data[37][10] = prec_2\n",
    "    results_data[37][11] = rec_1\n",
    "    results_data[37][12] = rec_2\n",
    "    results_data[37][13] = f1_1\n",
    "    results_data[37][14] = f1_2\n",
    "\n",
    "    print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "    print(\"Row 38 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[38][3] = acc1\n",
    "    results_data[38][4] = acc2\n",
    "    results_data[38][5] = prc_val1\n",
    "    results_data[38][6] = prc_val2\n",
    "    results_data[38][7] = pr_auc1\n",
    "    results_data[38][8] = pr_auc2\n",
    "    results_data[38][9] = prec_1\n",
    "    results_data[38][10] = prec_2\n",
    "    results_data[38][11] = rec_1\n",
    "    results_data[38][12] = rec_2\n",
    "    results_data[38][13] = f1_1\n",
    "    results_data[38][14] = f1_2\n",
    "\n",
    "    lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "    lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[39][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[39][1] = lr_model1.score(x1_test, y1_test)\n",
    "    results_data[39][2] = lr_model2.score(x2_test, y2_test)\n",
    "    results_data[39][3] = acc1\n",
    "    results_data[39][4] = acc2\n",
    "    results_data[39][5] = prc_val1\n",
    "    results_data[39][6] = prc_val2\n",
    "    results_data[39][7] = pr_auc1\n",
    "    results_data[39][8] = pr_auc2\n",
    "    results_data[39][9] = prec_1\n",
    "    results_data[39][10] = prec_2\n",
    "    results_data[39][11] = rec_1\n",
    "    results_data[39][12] = rec_2\n",
    "    results_data[39][13] = f1_1\n",
    "    results_data[39][14] = f1_2\n",
    "\n",
    "    rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "    rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[40][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[40][1] = rf_model1.score(x1_test, y1_test)\n",
    "    results_data[40][2] = rf_model2.score(x2_test, y2_test)\n",
    "    results_data[40][3] = acc1\n",
    "    results_data[40][4] = acc2\n",
    "    results_data[40][5] = prc_val1\n",
    "    results_data[40][6] = prc_val2\n",
    "    results_data[40][7] = pr_auc1\n",
    "    results_data[40][8] = pr_auc2\n",
    "    results_data[40][9] = prec_1\n",
    "    results_data[40][10] = prec_2\n",
    "    results_data[40][11] = rec_1\n",
    "    results_data[40][12] = rec_2\n",
    "    results_data[40][13] = f1_1\n",
    "    results_data[40][14] = f1_2\n",
    "\n",
    "    xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "    xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[41][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[41][1] = xgb_model1.score(x1_test, y1_test)\n",
    "    results_data[41][2] = xgb_model2.score(x2_test, y2_test)\n",
    "    results_data[41][3] = acc1\n",
    "    results_data[41][4] = acc2\n",
    "    results_data[41][5] = prc_val1\n",
    "    results_data[41][6] = prc_val2\n",
    "    results_data[41][7] = pr_auc1\n",
    "    results_data[41][8] = pr_auc2\n",
    "    results_data[41][9] = prec_1\n",
    "    results_data[41][10] = prec_2\n",
    "    results_data[41][11] = rec_1\n",
    "    results_data[41][12] = rec_2\n",
    "    results_data[41][13] = f1_1\n",
    "    results_data[41][14] = f1_2\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, osx1, osy1)\n",
    "    results_data[42][0] = \"Oversampled_Logistic_Regression_rkf\"\n",
    "    results_data[42][1] = model_score\n",
    "    results_data[42][3] = acc\n",
    "    results_data[42][5] = prc_val\n",
    "    results_data[42][7] = pr_auc\n",
    "    results_data[42][9] = precision\n",
    "    results_data[42][11] = recall\n",
    "    results_data[42][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "    results_data[43][0] = \"Oversampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "    results_data[43][1] = model_score\n",
    "    results_data[43][3] = acc\n",
    "    results_data[43][5] = prc_val\n",
    "    results_data[43][7] = pr_auc\n",
    "    results_data[43][9] = precision\n",
    "    results_data[43][11] = recall\n",
    "    results_data[43][13] = f1\n",
    "\n",
    "    # Rkf_short(lr_model1, osx1, osy1)\n",
    "    model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1, precision, recall, f1 = Rkf(rf_model1, osx1, osy1)\n",
    "    results_data[44][0] = \"Oversampled_Random_Forrest_rkf\"\n",
    "    results_data[44][1] = model_score\n",
    "    results_data[44][3] = acc\n",
    "    results_data[44][5] = prc_val\n",
    "    results_data[44][7] = pr_auc\n",
    "    results_data[44][9] = precision\n",
    "    results_data[44][11] = recall\n",
    "    results_data[44][13] = f1\n",
    "\n",
    "    print(\"Row 45 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1, precision, recall, f1 = Rkf(xgb_model1, osx1, osy1)\n",
    "    results_data[45][0] = \"Oversampled_XGB_Classifier_rkf\"\n",
    "    results_data[45][1] = model_score\n",
    "    results_data[45][3] = acc\n",
    "    results_data[45][5] = prc_val\n",
    "    results_data[45][7] = pr_auc\n",
    "    results_data[45][9] = precision\n",
    "    results_data[45][11] = recall\n",
    "    results_data[45][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1, precision, recall, f1 = Skf(lr_model1, osx1, osy1)\n",
    "    results_data[46][0] = \"Oversampled_Logistic_Regression_skf\"\n",
    "    results_data[46][1] = model_score\n",
    "    results_data[46][3] = acc\n",
    "    results_data[46][5] = prc_val\n",
    "    results_data[46][7] = pr_auc\n",
    "    results_data[46][9] = precision\n",
    "    results_data[46][11] = recall\n",
    "    results_data[46][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1, precision, recall, f1 = Skf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "    results_data[47][0] = \"Oversampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "    results_data[47][1] = model_score\n",
    "    results_data[47][3] = acc\n",
    "    results_data[47][5] = prc_val\n",
    "    results_data[47][7] = pr_auc\n",
    "    results_data[47][9] = precision\n",
    "    results_data[47][11] = recall\n",
    "    results_data[47][13] = f1\n",
    "\n",
    "    # Skf_short(lr_model1, osx1, osy1)\n",
    "    model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1, precision, recall, f1 = Skf(rf_model1, osx1, osy1)\n",
    "    results_data[48][0] = \"Oversampled_Random_Forrest_skf\"\n",
    "    results_data[48][1] = model_score\n",
    "    results_data[48][3] = acc\n",
    "    results_data[48][5] = prc_val\n",
    "    results_data[48][7] = pr_auc\n",
    "    results_data[48][9] = precision\n",
    "    results_data[48][11] = recall\n",
    "    results_data[48][13] = f1\n",
    "\n",
    "    print(\"Row 49 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1, precision, recall, f1 = Skf(xgb_model1, osx1, osy1)\n",
    "    results_data[49][0] = \"Oversampled_XGB_Classifier_skf\"\n",
    "    results_data[49][1] = model_score\n",
    "    results_data[49][3] = acc\n",
    "    results_data[49][5] = prc_val\n",
    "    results_data[49][7] = pr_auc\n",
    "    results_data[49][9] = precision\n",
    "    results_data[49][11] = recall\n",
    "    results_data[49][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1, precision, recall, f1 = Tss(lr_model1, osx1, osy1)\n",
    "    results_data[50][0] = \"Oversampled_Logistic_Regression_tss\"\n",
    "    results_data[50][1] = model_score\n",
    "    results_data[50][3] = acc\n",
    "    results_data[50][5] = prc_val\n",
    "    results_data[50][7] = pr_auc\n",
    "    results_data[50][9] = precision\n",
    "    results_data[50][11] = recall\n",
    "    results_data[50][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1, precision, recall, f1 = Tss(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "    results_data[51][0] = \"Oversampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "    results_data[51][1] = model_score\n",
    "    results_data[51][3] = acc\n",
    "    results_data[51][5] = prc_val\n",
    "    results_data[51][7] = pr_auc\n",
    "    results_data[51][9] = precision\n",
    "    results_data[51][11] = recall\n",
    "    results_data[51][13] = f1\n",
    "\n",
    "    # Tss_short(lr_model1, osx1, osy1)\n",
    "    model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1, precision, recall, f1 = Tss(rf_model1, osx1, osy1)\n",
    "    results_data[52][0] = \"Oversampled_Random_Forrest_tss\"\n",
    "    results_data[52][1] = model_score\n",
    "    results_data[52][3] = acc\n",
    "    results_data[52][5] = prc_val\n",
    "    results_data[52][7] = pr_auc\n",
    "    results_data[52][9] = precision\n",
    "    results_data[52][11] = recall\n",
    "    results_data[52][13] = f1\n",
    "\n",
    "    print(\"Row 53 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1, precision, recall, f1 = Tss(xgb_model1, osx1, osy1)\n",
    "    results_data[53][0] = \"Oversampled_XGB_Classifier_tss\"\n",
    "    results_data[53][1] = model_score\n",
    "    results_data[53][3] = acc\n",
    "    results_data[53][5] = prc_val\n",
    "    results_data[53][7] = pr_auc\n",
    "    results_data[53][9] = precision\n",
    "    results_data[53][11] = recall\n",
    "    results_data[53][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, osx2, osy2)\n",
    "    results_data[42][2] = model_score\n",
    "    results_data[42][4] = acc\n",
    "    results_data[42][6] = prc_val\n",
    "    results_data[42][8] = pr_auc\n",
    "    results_data[42][10] = precision\n",
    "    results_data[42][12] = recall\n",
    "    results_data[42][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "    results_data[43][2] = model_score\n",
    "    results_data[43][4] = acc\n",
    "    results_data[43][6] = prc_val\n",
    "    results_data[43][8] = pr_auc\n",
    "    results_data[43][10] = precision\n",
    "    results_data[43][12] = recall\n",
    "    results_data[43][14] = f1\n",
    "\n",
    "    # Rkf_short(lr_model2, osx2, osy2)\n",
    "    model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2, precision, recall, f1 = Rkf(rf_model2, osx2, osy2)\n",
    "    results_data[44][2] = model_score\n",
    "    results_data[44][4] = acc\n",
    "    results_data[44][6] = prc_val\n",
    "    results_data[44][8] = pr_auc\n",
    "    results_data[44][10] = precision\n",
    "    results_data[44][12] = recall\n",
    "    results_data[44][14] = f1\n",
    "\n",
    "    print(\"Row 45 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2, precision, recall, f1 = Rkf(xgb_model2, osx2, osy2)\n",
    "    results_data[45][2] = model_score\n",
    "    results_data[45][4] = acc\n",
    "    results_data[45][6] = prc_val\n",
    "    results_data[45][8] = pr_auc\n",
    "    results_data[45][10] = precision\n",
    "    results_data[45][12] = recall\n",
    "    results_data[45][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2, precision, recall, f1 = Skf(lr_model2, osx2, osy2)\n",
    "    results_data[46][2] = model_score\n",
    "    results_data[46][4] = acc\n",
    "    results_data[46][6] = prc_val\n",
    "    results_data[46][8] = pr_auc\n",
    "    results_data[46][10] = precision\n",
    "    results_data[46][12] = recall\n",
    "    results_data[46][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2, precision, recall, f1 = Skf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "    results_data[47][2] = model_score\n",
    "    results_data[47][4] = acc\n",
    "    results_data[47][6] = prc_val\n",
    "    results_data[47][8] = pr_auc\n",
    "    results_data[47][10] = precision\n",
    "    results_data[47][12] = recall\n",
    "    results_data[47][14] = f1\n",
    "\n",
    "    # Skf_short(lr_model2, osx2, osy2)\n",
    "    model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2, precision, recall, f1 = Skf(rf_model2, osx2, osy2)\n",
    "    results_data[48][2] = model_score\n",
    "    results_data[48][4] = acc\n",
    "    results_data[48][6] = prc_val\n",
    "    results_data[48][8] = pr_auc\n",
    "    results_data[48][10] = precision\n",
    "    results_data[48][12] = recall\n",
    "    results_data[48][14] = f1\n",
    "\n",
    "    print(\"Row 49 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2, precision, recall, f1 = Skf(xgb_model1, osx1, osy1)\n",
    "    results_data[49][2] = model_score\n",
    "    results_data[49][4] = acc\n",
    "    results_data[49][6] = prc_val\n",
    "    results_data[49][8] = pr_auc\n",
    "    results_data[49][10] = precision\n",
    "    results_data[49][12] = recall\n",
    "    results_data[49][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2, precision, recall, f1 = Tss(lr_model2, osx2, osy2)\n",
    "    results_data[50][2] = model_score\n",
    "    results_data[50][4] = acc\n",
    "    results_data[50][6] = prc_val\n",
    "    results_data[50][8] = pr_auc\n",
    "    results_data[50][10] = precision\n",
    "    results_data[50][12] = recall\n",
    "    results_data[50][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2, precision, recall, f1 = Tss(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "    results_data[51][2] = model_score\n",
    "    results_data[51][4] = acc\n",
    "    results_data[51][6] = prc_val\n",
    "    results_data[51][8] = pr_auc\n",
    "    results_data[51][10] = precision\n",
    "    results_data[51][12] = recall\n",
    "    results_data[51][14] = f1\n",
    "\n",
    "    # Tss_short(lr_model2, osx2, osy2)\n",
    "    model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2, precision, recall, f1 = Tss(rf_model2, osx2, osy2)\n",
    "    results_data[52][2] = model_score\n",
    "    results_data[52][4] = acc\n",
    "    results_data[52][6] = prc_val\n",
    "    results_data[52][8] = pr_auc\n",
    "    results_data[52][10] = precision\n",
    "    results_data[52][12] = recall\n",
    "    results_data[52][14] = f1\n",
    "\n",
    "    print(\"Row 53 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2, precision, recall, f1 = Tss(xgb_model2, osx2, osy2)\n",
    "    results_data[53][2] = model_score\n",
    "    results_data[53][4] = acc\n",
    "    results_data[53][6] = prc_val\n",
    "    results_data[53][8] = pr_auc\n",
    "    results_data[53][10] = precision\n",
    "    results_data[53][12] = recall\n",
    "    results_data[53][14] = f1\n",
    "\n",
    "    # OSUS\n",
    "    x1 = graph_df[labels1]\n",
    "    x2 = graph_df[labels2]\n",
    "    y = graph_df[\"Bug\"].astype('int')\n",
    "\n",
    "    sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "\n",
    "    # Fit the model to generate the data for Model 1.\n",
    "    oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "    # Fit the model to generate the data for Model 2.\n",
    "    oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "    osx1 = oversampled_X1\n",
    "    osx2 = oversampled_X2\n",
    "    osy1 = oversampled_Y1\n",
    "    osy2 = oversampled_Y2\n",
    "\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "    balanced_x1, balanced_y1, = rus.fit_resample(osx1, osy1)\n",
    "    balanced_x2, balanced_y2, = rus.fit_resample(osx2, osy2)\n",
    "    \n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(balanced_x1, balanced_y1, test_size=0.3, random_state = 5)\n",
    "    #x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(balanced_x2, balanced_y2, test_size=0.3, random_state = 5)\n",
    "    #x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "    lr_model1.fit(x1_train, y1_train)\n",
    "    lr_model2.fit(x2_train, y2_train)\n",
    "    rf_model1.fit(x1_train, y1_train)\n",
    "    rf_model2.fit(x2_train, y2_train)\n",
    "    xgb_model1.fit(x1_train, y1_train)\n",
    "    xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "    lr_predictions1 = lr_model1.predict(x1_test)\n",
    "    lr_predictions2 = lr_model2.predict(x2_test)\n",
    "    lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "    lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "    rf_predictions1 = rf_model1.predict(x1_test)\n",
    "    rf_predictions2 = rf_model2.predict(x2_test)\n",
    "    rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "    rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "    xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "    xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "    xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "    xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "    # Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "    results_data[54][0] = \"OSUS_Combination_Logistic_Regression\"\n",
    "    results_data[54][1] = lr_model1.score(x1_test, y1_test)\n",
    "    results_data[54][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "    results_data[55][0] = \"OSUS_Combination_Random_Forrest\"\n",
    "    results_data[55][1] = rf_model1.score(x1_test, y1_test)\n",
    "    results_data[55][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "    results_data[56][0] = \"OSUS_Combination_XGB_Classifier\"\n",
    "    results_data[56][1] = xgb_model1.score(x1_test, y1_test)\n",
    "    results_data[56][2] = xgb_model2.score(x2_test, y2_test)\n",
    "\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[54][3] = acc1\n",
    "    results_data[54][4] = acc2\n",
    "    results_data[54][5] = prc_val1\n",
    "    results_data[54][6] = prc_val2\n",
    "    results_data[54][7] = pr_auc1\n",
    "    results_data[54][8] = pr_auc2\n",
    "    results_data[54][9] = prec_1\n",
    "    results_data[54][10] = prec_2\n",
    "    results_data[54][11] = rec_1\n",
    "    results_data[54][12] = rec_2\n",
    "    results_data[54][13] = f1_1\n",
    "    results_data[54][14] = f1_2\n",
    "\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[55][3] = acc1\n",
    "    results_data[55][4] = acc2\n",
    "    results_data[55][5] = prc_val1\n",
    "    results_data[55][6] = prc_val2\n",
    "    results_data[55][7] = pr_auc1\n",
    "    results_data[55][8] = pr_auc2\n",
    "    results_data[55][9] = prec_1\n",
    "    results_data[55][10] = prec_2\n",
    "    results_data[55][11] = rec_1\n",
    "    results_data[55][12] = rec_2\n",
    "    results_data[55][13] = f1_1\n",
    "    results_data[55][14] = f1_2\n",
    "\n",
    "    print(\"Row 56 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[56][3] = acc1\n",
    "    results_data[56][4] = acc2\n",
    "    results_data[56][5] = prc_val1\n",
    "    results_data[56][6] = prc_val2\n",
    "    results_data[56][7] = pr_auc1\n",
    "    results_data[56][8] = pr_auc2\n",
    "    results_data[56][9] = prec_1\n",
    "    results_data[56][10] = prec_2\n",
    "    results_data[56][11] = rec_1\n",
    "    results_data[56][12] = rec_2\n",
    "    results_data[56][13] = f1_1\n",
    "    results_data[56][14] = f1_2\n",
    "\n",
    "    lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "    lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "    results_data[57][0] = \"OSUS_Logistic_Regression_Best_Threshold\"\n",
    "    results_data[57][1] = lr_model1.score(x1_test, y1_test)\n",
    "    results_data[57][2] = lr_model2.score(x2_test, y2_test)\n",
    "    results_data[57][3] = acc1\n",
    "    results_data[57][4] = acc2\n",
    "    results_data[57][5] = prc_val1\n",
    "    results_data[57][6] = prc_val2\n",
    "    results_data[57][7] = pr_auc1\n",
    "    results_data[57][8] = pr_auc2\n",
    "    results_data[57][9] = prec_1\n",
    "    results_data[57][10] = prec_2\n",
    "    results_data[57][11] = rec_1\n",
    "    results_data[57][12] = rec_2\n",
    "    results_data[57][13] = f1_1\n",
    "    results_data[57][14] = f1_2\n",
    "\n",
    "    rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "    rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "    results_data[58][0] = \"OSUS_Random_Forrest_Best_Threshold\"\n",
    "    results_data[58][1] = rf_model1.score(x1_test, y1_test)\n",
    "    results_data[58][2] = rf_model2.score(x2_test, y2_test)\n",
    "    results_data[58][3] = acc1\n",
    "    results_data[58][4] = acc2\n",
    "    results_data[58][5] = prc_val1\n",
    "    results_data[58][6] = prc_val2\n",
    "    results_data[58][7] = pr_auc1\n",
    "    results_data[58][8] = pr_auc2\n",
    "    results_data[58][9] = prec_1\n",
    "    results_data[58][10] = prec_2\n",
    "    results_data[58][11] = rec_1\n",
    "    results_data[58][12] = rec_2\n",
    "    results_data[58][13] = f1_1\n",
    "    results_data[58][14] = f1_2\n",
    "\n",
    "    xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "    xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "    print(\"Row 59 model 1\")\n",
    "    acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2, prec_1, prec_2, rec_1, rec_2, f1_1, f1_2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "    results_data[59][0] = \"OSUS_XGBoost_Classifier_Best_Threshold\"\n",
    "    results_data[59][1] = xgb_model1.score(x1_test, y1_test)\n",
    "    results_data[59][2] = xgb_model2.score(x2_test, y2_test)\n",
    "    results_data[59][3] = acc1\n",
    "    results_data[59][4] = acc2\n",
    "    results_data[59][5] = prc_val1\n",
    "    results_data[59][6] = prc_val2\n",
    "    results_data[59][7] = pr_auc1\n",
    "    results_data[59][8] = pr_auc2\n",
    "    results_data[59][9] = prec_1\n",
    "    results_data[59][10] = prec_2\n",
    "    results_data[59][11] = rec_1\n",
    "    results_data[59][12] = rec_2\n",
    "    results_data[59][13] = f1_1\n",
    "    results_data[59][14] = f1_2\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, balanced_x1, balanced_y1)\n",
    "    results_data[60][0] = \"OSUS_Combination_Logistic_Regression_rkf\"\n",
    "    results_data[60][1] = model_score\n",
    "    results_data[60][3] = acc\n",
    "    results_data[60][5] = prc_val\n",
    "    results_data[60][7] = pr_auc\n",
    "    results_data[60][9] = precision\n",
    "    results_data[60][11] = recall\n",
    "    results_data[60][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1, precision, recall, f1 = Rkf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "    results_data[61][0] = \"OSUS_Combination_Logistic_Regression_rkf_Best_Threshold\"\n",
    "    results_data[61][1] = model_score\n",
    "    results_data[61][3] = acc\n",
    "    results_data[61][5] = prc_val\n",
    "    results_data[61][7] = pr_auc\n",
    "    results_data[61][9] = precision\n",
    "    results_data[61][11] = recall\n",
    "    results_data[61][13] = f1\n",
    "\n",
    "    # Rkf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "    model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1, precision, recall, f1 = Rkf(rf_model1, balanced_x1, balanced_y1)\n",
    "    results_data[62][0] = \"OSUS_Combination_Random_Forrest_rkf\"\n",
    "    results_data[62][1] = model_score\n",
    "    results_data[62][3] = acc\n",
    "    results_data[62][5] = prc_val\n",
    "    results_data[62][7] = pr_auc\n",
    "    results_data[62][9] = precision\n",
    "    results_data[62][11] = recall\n",
    "    results_data[62][13] = f1\n",
    "\n",
    "    print(\"Row 63 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1, precision, recall, f1 = Rkf(xgb_model1, balanced_x1, balanced_y1)\n",
    "    results_data[63][0] = \"OSUS_Combination_XGB_Classifier_rkf\"\n",
    "    results_data[63][1] = model_score\n",
    "    results_data[63][3] = acc\n",
    "    results_data[63][5] = prc_val\n",
    "    results_data[63][7] = pr_auc\n",
    "    results_data[63][9] = precision\n",
    "    results_data[63][11] = recall\n",
    "    results_data[63][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1, precision, recall, f1 = Skf(lr_model1, balanced_x1, balanced_y1)\n",
    "    results_data[64][0] = \"OSUS_Combination_Logistic_Regression_skf\"\n",
    "    results_data[64][1] = model_score\n",
    "    results_data[64][3] = acc\n",
    "    results_data[64][5] = prc_val\n",
    "    results_data[64][7] = pr_auc\n",
    "    results_data[64][9] = precision\n",
    "    results_data[64][11] = recall\n",
    "    results_data[64][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1, precision, recall, f1 = Skf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "    results_data[65][0] = \"OSUS_Combination_Logistic_Regression_skf_Best_Threshold\"\n",
    "    results_data[65][1] = model_score\n",
    "    results_data[65][3] = acc\n",
    "    results_data[65][5] = prc_val\n",
    "    results_data[65][7] = pr_auc\n",
    "    results_data[65][9] = precision\n",
    "    results_data[65][11] = recall\n",
    "    results_data[65][13] = f1\n",
    "\n",
    "    # Skf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "    model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1, precision, recall, f1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "    results_data[66][0] = \"OSUS_Combination_Random_Forrest_skf\"\n",
    "    results_data[66][1] = model_score\n",
    "    results_data[66][3] = acc\n",
    "    results_data[66][5] = prc_val\n",
    "    results_data[66][7] = pr_auc\n",
    "    results_data[66][9] = precision\n",
    "    results_data[66][11] = recall\n",
    "    results_data[66][13] = f1\n",
    "\n",
    "    print(\"Row 67 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1, precision, recall, f1 = Skf(xgb_model1, balanced_x1, balanced_y1)\n",
    "    results_data[67][0] = \"OSUS_Combination_XGB_Classifier_skf\"\n",
    "    results_data[67][1] = model_score\n",
    "    results_data[67][3] = acc\n",
    "    results_data[67][5] = prc_val\n",
    "    results_data[67][7] = pr_auc\n",
    "    results_data[67][9] = precision\n",
    "    results_data[67][11] = recall\n",
    "    results_data[67][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1, precision, recall, f1 = Tss(lr_model1, balanced_x1, balanced_y1)\n",
    "    results_data[68][0] = \"OSUS_Combination_Logistic_Regression_tss\"\n",
    "    results_data[68][1] = model_score\n",
    "    results_data[68][3] = acc\n",
    "    results_data[68][5] = prc_val\n",
    "    results_data[68][7] = pr_auc\n",
    "    results_data[68][9] = precision\n",
    "    results_data[68][11] = recall\n",
    "    results_data[68][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1, precision, recall, f1 = Tss(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "    results_data[69][0] = \"OSUS_Combination_Logistic_Regression_tss_Best_Threshold\"\n",
    "    results_data[69][1] = model_score\n",
    "    results_data[69][3] = acc\n",
    "    results_data[69][5] = prc_val\n",
    "    results_data[69][7] = pr_auc\n",
    "    results_data[69][9] = precision\n",
    "    results_data[69][11] = recall\n",
    "    results_data[69][13] = f1\n",
    "\n",
    "    # Tss_short(lr_model1, balanced_x1, balanced_y1)\n",
    "    model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1, precision, recall, f1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "    results_data[70][0] = \"OSUS_Combination_Random_Forrest_tss\"\n",
    "    results_data[70][1] = model_score\n",
    "    results_data[70][3] = acc\n",
    "    results_data[70][5] = prc_val\n",
    "    results_data[70][7] = pr_auc\n",
    "    results_data[70][9] = precision\n",
    "    results_data[70][11] = recall\n",
    "    results_data[70][13] = f1\n",
    "\n",
    "    print(\"Row 71 model 1\")\n",
    "    model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1, precision, recall, f1 = Tss(xgb_model1, balanced_x1, balanced_y1)\n",
    "    results_data[71][0] = \"OSUS_Combination_XGB_Classifier_tss\"\n",
    "    results_data[71][1] = model_score\n",
    "    results_data[71][3] = acc\n",
    "    results_data[71][5] = prc_val\n",
    "    results_data[71][7] = pr_auc\n",
    "    results_data[71][9] = precision\n",
    "    results_data[71][11] = recall\n",
    "    results_data[71][13] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, balanced_x2, balanced_y2)\n",
    "    results_data[60][2] = model_score\n",
    "    results_data[60][4] = acc\n",
    "    results_data[60][6] = prc_val\n",
    "    results_data[60][8] = pr_auc\n",
    "    results_data[60][10] = precision\n",
    "    results_data[60][12] = recall\n",
    "    results_data[60][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2, precision, recall, f1 = Rkf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "    results_data[61][2] = model_score\n",
    "    results_data[61][4] = acc\n",
    "    results_data[61][6] = prc_val\n",
    "    results_data[61][8] = pr_auc\n",
    "    results_data[61][10] = precision\n",
    "    results_data[61][12] = recall\n",
    "    results_data[61][14] = f1\n",
    "\n",
    "    # Rkf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "    model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2, precision, recall, f1 = Rkf(rf_model2, balanced_x2, balanced_y2)\n",
    "    results_data[62][2] = model_score\n",
    "    results_data[62][4] = acc\n",
    "    results_data[62][6] = prc_val\n",
    "    results_data[62][8] = pr_auc\n",
    "    results_data[62][10] = precision\n",
    "    results_data[62][12] = recall\n",
    "    results_data[62][14] = f1\n",
    "\n",
    "    print(\"Row 63 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2, precision, recall, f1 = Rkf(xgb_model2, balanced_x2, balanced_y2)\n",
    "    results_data[63][2] = model_score\n",
    "    results_data[63][4] = acc\n",
    "    results_data[63][6] = prc_val\n",
    "    results_data[63][8] = pr_auc\n",
    "    results_data[63][10] = precision\n",
    "    results_data[63][12] = recall\n",
    "    results_data[63][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2, precision, recall, f1 = Skf(lr_model2, balanced_x2, balanced_y2)\n",
    "    results_data[64][2] = model_score\n",
    "    results_data[64][4] = acc\n",
    "    results_data[64][6] = prc_val\n",
    "    results_data[64][8] = pr_auc\n",
    "    results_data[64][10] = precision\n",
    "    results_data[64][12] = recall\n",
    "    results_data[64][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2, precision, recall, f1 = Skf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "    results_data[65][2] = model_score\n",
    "    results_data[65][4] = acc\n",
    "    results_data[65][6] = prc_val\n",
    "    results_data[65][8] = pr_auc\n",
    "    results_data[65][10] = precision\n",
    "    results_data[65][12] = recall\n",
    "    results_data[65][14] = f1\n",
    "\n",
    "    # Skf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "    model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2, precision, recall, f1 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "    results_data[66][2] = model_score\n",
    "    results_data[66][4] = acc\n",
    "    results_data[66][6] = prc_val\n",
    "    results_data[66][8] = pr_auc\n",
    "    results_data[66][10] = precision\n",
    "    results_data[66][12] = recall\n",
    "    results_data[66][14] = f1\n",
    "\n",
    "    print(\"Row 67 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2, precision, recall, f1 = Skf(xgb_model2, balanced_x2, balanced_y2)\n",
    "    results_data[67][2] = model_score\n",
    "    results_data[67][4] = acc\n",
    "    results_data[67][6] = prc_val\n",
    "    results_data[67][8] = pr_auc\n",
    "    results_data[67][10] = precision\n",
    "    results_data[67][12] = recall\n",
    "    results_data[67][14] = f1\n",
    "\n",
    "    model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2, precision, recall, f1 = Tss(lr_model2, balanced_x2, balanced_y2)\n",
    "    results_data[68][2] = model_score\n",
    "    results_data[68][4] = acc\n",
    "    results_data[68][6] = prc_val\n",
    "    results_data[68][8] = pr_auc\n",
    "    results_data[68][10] = precision\n",
    "    results_data[68][12] = recall\n",
    "    results_data[68][14] = f1\n",
    "    print(\"---------------------\")\n",
    "    print(\"With best threshold\")\n",
    "    model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2, precision, recall, f1 = Tss(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "    results_data[69][2] = model_score\n",
    "    results_data[69][4] = acc\n",
    "    results_data[69][6] = prc_val\n",
    "    results_data[69][8] = pr_auc\n",
    "    results_data[69][10] = precision\n",
    "    results_data[69][12] = recall\n",
    "    results_data[69][14] = f1\n",
    "\n",
    "    # Tss_short(lr_model2, balanced_x2, balanced_y2)\n",
    "    model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2, precision, recall, f1 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "    results_data[70][2] = model_score\n",
    "    results_data[70][4] = acc\n",
    "    results_data[70][6] = prc_val\n",
    "    results_data[70][8] = pr_auc\n",
    "    results_data[70][10] = precision\n",
    "    results_data[70][12] = recall\n",
    "    results_data[70][14] = f1\n",
    "\n",
    "    print(\"Row 71 model 2\")\n",
    "    model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2, precision, recall, f1 = Tss(xgb_model2, balanced_x2, balanced_y2)\n",
    "    results_data[71][2] = model_score\n",
    "    results_data[71][4] = acc\n",
    "    results_data[71][6] = prc_val\n",
    "    results_data[71][8] = pr_auc\n",
    "    results_data[71][10] = precision\n",
    "    results_data[71][12] = recall\n",
    "    results_data[71][14] = f1\n",
    "\n",
    "    results_df = pd.DataFrame(results_data, columns = ['Test', 'Model1 score', 'Model2 score', 'Model1 accuracy', 'Model2 accuracy', 'Model1 avg. PR score', 'Model2 avg. PR score', 'Model1 PRC-AUC Score', 'Model2 PRC-AUC Score', 'Model1 Precision Score', 'Model2 Precision Score', 'Model1 Recall Score', 'Model2 Recall Score', 'Model1 F1 Score', 'Model2 F1 Score'])\n",
    "    model1_results_df = results_df[['Test', 'Model1 score', 'Model1 accuracy', 'Model1 avg. PR score', 'Model1 PRC-AUC Score', 'Model1 Precision Score', 'Model1 Recall Score', 'Model1 F1 Score']]\n",
    "    model2_results_df = results_df[['Test', 'Model2 score', 'Model2 accuracy', 'Model2 avg. PR score', 'Model2 PRC-AUC Score', 'Model2 Precision Score', 'Model2 Recall Score', 'Model2 F1 Score']]\n",
    "\n",
    "    print(results_df)\n",
    "\n",
    "    model1_results_df = model1_results_df[~model1_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model1 PRC-AUC Score', 'Model1 score'], ascending=False)\n",
    "    model2_results_df = model2_results_df[~model2_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model2 PRC-AUC Score'], ascending=False)\n",
    "\n",
    "    print(model1_results_df)\n",
    "    print(model2_results_df)\n",
    "    \n",
    "    found_lr = False\n",
    "    found_xgb = False\n",
    "    found_rf = False\n",
    "    \n",
    "    for index, row in model1_results_df.iterrows():\n",
    "        if found_lr == True and found_xgb == True and found_rf == True:\n",
    "            break\n",
    "        if 'Logistic_Regression' in row['Test'] and found_lr == False and row['Model1 PRC-AUC Score'] != 1.0:\n",
    "            found_lr = True\n",
    "            final_result_df.loc[file_index, 'LR_precision_1'] = row['Model1 Precision Score']\n",
    "            final_result_df.loc[file_index, 'LR_recall_1'] = row['Model1 Recall Score']\n",
    "            final_result_df.loc[file_index, 'LR_f1_1'] = row['Model1 F1 Score']\n",
    "            final_result_df.loc[file_index, 'LR_PRC_AUC_1'] = row['Model1 PRC-AUC Score']\n",
    "        elif 'Random_Forrest' in row['Test'] and found_rf == False and row['Model1 PRC-AUC Score'] != 1.0:\n",
    "            found_rf = True\n",
    "            final_result_df.loc[file_index, 'RF_precision_1'] = row['Model1 Precision Score']\n",
    "            final_result_df.loc[file_index, 'RF_recall_1'] = row['Model1 Recall Score']\n",
    "            final_result_df.loc[file_index, 'RF_f1_1'] = row['Model1 F1 Score']\n",
    "            final_result_df.loc[file_index, 'RF_PRC_AUC_1'] = row['Model1 PRC-AUC Score']\n",
    "        elif 'XGB' in row['Test'] and found_xgb == False and row['Model1 PRC-AUC Score'] != 1.0:\n",
    "            found_xgb = True\n",
    "            final_result_df.loc[file_index, 'XGB_precision_1'] = row['Model1 Precision Score']\n",
    "            final_result_df.loc[file_index, 'XGB_recall_1'] = row['Model1 Recall Score']\n",
    "            final_result_df.loc[file_index, 'XGB_f1_1'] = row['Model1 F1 Score']\n",
    "            final_result_df.loc[file_index, 'XGB_PRC_AUC_1'] = row['Model1 PRC-AUC Score']\n",
    "      \n",
    "    found_lr = False\n",
    "    found_xgb = False\n",
    "    found_rf = False\n",
    "    \n",
    "    for index, row in model2_results_df.iterrows():\n",
    "        if found_lr == True and found_xgb == True and found_rf == True:\n",
    "            break\n",
    "        if 'Logistic_Regression' in row['Test'] and found_lr == False and row['Model2 PRC-AUC Score'] != 1.0:\n",
    "            found_lr = True\n",
    "            final_result_df.loc[file_index, 'LR_precision_2'] = row['Model2 Precision Score']\n",
    "            final_result_df.loc[file_index, 'LR_recall_2'] = row['Model2 Recall Score']\n",
    "            final_result_df.loc[file_index, 'LR_f1_2'] = row['Model2 F1 Score']\n",
    "            final_result_df.loc[file_index, 'LR_PRC_AUC_2'] = row['Model2 PRC-AUC Score']\n",
    "        elif 'Random_Forrest' in row['Test'] and found_rf == False and row['Model2 PRC-AUC Score'] != 1.0:\n",
    "            found_rf = True\n",
    "            final_result_df.loc[file_index, 'RF_precision_2'] = row['Model2 Precision Score']\n",
    "            final_result_df.loc[file_index, 'RF_recall_2'] = row['Model2 Recall Score']\n",
    "            final_result_df.loc[file_index, 'RF_f1_2'] = row['Model2 F1 Score']\n",
    "            final_result_df.loc[file_index, 'RF_PRC_AUC_2'] = row['Model2 PRC-AUC Score']\n",
    "        elif 'XGB' in row['Test'] and found_xgb == False and row['Model2 PRC-AUC Score'] != 1.0:\n",
    "            found_xgb = True\n",
    "            final_result_df.loc[file_index, 'XGB_precision_2'] = row['Model2 Precision Score']\n",
    "            final_result_df.loc[file_index, 'XGB_recall_2'] = row['Model2 Recall Score']\n",
    "            final_result_df.loc[file_index, 'XGB_f1_2'] = row['Model2 F1 Score']\n",
    "            final_result_df.loc[file_index, 'XGB_PRC_AUC_2'] = row['Model2 PRC-AUC Score']\n",
    "    \n",
    "    final_result_df.to_csv('out2.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_precision_1</th>\n",
       "      <th>XGB_precision_2</th>\n",
       "      <th>XGB_recall_1</th>\n",
       "      <th>XGB_recall_2</th>\n",
       "      <th>XGB_f1_1</th>\n",
       "      <th>XGB_f1_2</th>\n",
       "      <th>XGB_PRC_AUC_1</th>\n",
       "      <th>XGB_PRC_AUC_2</th>\n",
       "      <th>LR_precision_1</th>\n",
       "      <th>LR_precision_2</th>\n",
       "      <th>...</th>\n",
       "      <th>LR_PRC_AUC_1</th>\n",
       "      <th>LR_PRC_AUC_2</th>\n",
       "      <th>RF_precision_1</th>\n",
       "      <th>RF_precision_2</th>\n",
       "      <th>RF_recall_1</th>\n",
       "      <th>RF_recall_2</th>\n",
       "      <th>RF_f1_1</th>\n",
       "      <th>RF_f1_2</th>\n",
       "      <th>RF_PRC_AUC_1</th>\n",
       "      <th>RF_PRC_AUC_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734094</td>\n",
       "      <td>0.732637</td>\n",
       "      <td>0.846660</td>\n",
       "      <td>0.845690</td>\n",
       "      <td>0.952647</td>\n",
       "      <td>0.955318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924717</td>\n",
       "      <td>0.953018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732637</td>\n",
       "      <td>0.732637</td>\n",
       "      <td>0.845690</td>\n",
       "      <td>0.845690</td>\n",
       "      <td>0.945936</td>\n",
       "      <td>0.953861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.920280</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.813637</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.844487</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>0.550926</td>\n",
       "      <td>0.956197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.974990</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752414</td>\n",
       "      <td>0.729302</td>\n",
       "      <td>0.686750</td>\n",
       "      <td>0.843464</td>\n",
       "      <td>0.864633</td>\n",
       "      <td>0.965807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608546</td>\n",
       "      <td>0.608593</td>\n",
       "      <td>0.756641</td>\n",
       "      <td>0.756677</td>\n",
       "      <td>0.967942</td>\n",
       "      <td>0.967989</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.966394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608710</td>\n",
       "      <td>0.608663</td>\n",
       "      <td>0.756768</td>\n",
       "      <td>0.756732</td>\n",
       "      <td>0.968059</td>\n",
       "      <td>0.968059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981636</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548443</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.551351</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.774222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.626999</td>\n",
       "      <td>0.813470</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.777514</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.795086</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.736078</td>\n",
       "      <td>0.540564</td>\n",
       "      <td>0.810559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778373</td>\n",
       "      <td>0.822846</td>\n",
       "      <td>0.813470</td>\n",
       "      <td>0.626994</td>\n",
       "      <td>0.777514</td>\n",
       "      <td>0.864753</td>\n",
       "      <td>0.795086</td>\n",
       "      <td>0.726926</td>\n",
       "      <td>0.732680</td>\n",
       "      <td>0.726891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.997695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.901355</td>\n",
       "      <td>0.901355</td>\n",
       "      <td>0.832351</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.901363</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.901355</td>\n",
       "      <td>0.901344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.883658</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.767619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865748</td>\n",
       "      <td>0.883294</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.883611</td>\n",
       "      <td>0.883514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.665342</td>\n",
       "      <td>0.889771</td>\n",
       "      <td>0.828984</td>\n",
       "      <td>0.830797</td>\n",
       "      <td>0.738203</td>\n",
       "      <td>0.859273</td>\n",
       "      <td>0.810260</td>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>0.965092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889553</td>\n",
       "      <td>0.909132</td>\n",
       "      <td>0.858473</td>\n",
       "      <td>0.809087</td>\n",
       "      <td>0.830797</td>\n",
       "      <td>0.830797</td>\n",
       "      <td>0.844408</td>\n",
       "      <td>0.819798</td>\n",
       "      <td>0.852482</td>\n",
       "      <td>0.859970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.670996</td>\n",
       "      <td>0.671033</td>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.793525</td>\n",
       "      <td>0.727079</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.718221</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>0.542074</td>\n",
       "      <td>0.674534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763933</td>\n",
       "      <td>0.771983</td>\n",
       "      <td>0.671033</td>\n",
       "      <td>0.671033</td>\n",
       "      <td>0.793525</td>\n",
       "      <td>0.793525</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.718239</td>\n",
       "      <td>0.718325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.660867</td>\n",
       "      <td>0.660870</td>\n",
       "      <td>0.881457</td>\n",
       "      <td>0.881469</td>\n",
       "      <td>0.755387</td>\n",
       "      <td>0.755393</td>\n",
       "      <td>0.753893</td>\n",
       "      <td>0.753868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753665</td>\n",
       "      <td>0.774019</td>\n",
       "      <td>0.660885</td>\n",
       "      <td>0.660873</td>\n",
       "      <td>0.881529</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.755425</td>\n",
       "      <td>0.755400</td>\n",
       "      <td>0.753954</td>\n",
       "      <td>0.753907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.792898</td>\n",
       "      <td>0.792879</td>\n",
       "      <td>0.663067</td>\n",
       "      <td>0.686459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775302</td>\n",
       "      <td>0.807716</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.791408</td>\n",
       "      <td>0.792865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.816212</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.797266</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788379</td>\n",
       "      <td>0.816196</td>\n",
       "      <td>0.777438</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.809019</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>0.792914</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.816082</td>\n",
       "      <td>0.816214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGB_precision_1  XGB_precision_2  XGB_recall_1  XGB_recall_2  XGB_f1_1  \\\n",
       "0          1.000000         1.000000      0.734094      0.732637  0.846660   \n",
       "1          0.920280         0.993958      0.729144      0.729144  0.813637   \n",
       "2          1.000000         1.000000      0.608546      0.608593  0.756641   \n",
       "3          1.000000         1.000000      0.965854      0.965854  0.982630   \n",
       "4          0.548443         0.548443      1.000000      1.000000  0.708380   \n",
       "5          0.626999         0.813470      0.864605      0.777514  0.726877   \n",
       "6          0.995389         0.995389      1.000000      1.000000  0.997689   \n",
       "7          0.827153         0.827153      0.916948      0.916948  0.869739   \n",
       "8          0.767649         0.767649      0.974230      0.974230  0.858689   \n",
       "9          0.665342         0.889771      0.828984      0.830797  0.738203   \n",
       "10         0.670996         0.671033      0.793392      0.793525  0.727079   \n",
       "11         0.660867         0.660870      0.881457      0.881469  0.755387   \n",
       "12         0.688746         0.688746      0.901340      0.901340  0.780831   \n",
       "13         0.779650         0.779650      0.809675      0.809675  0.794379   \n",
       "\n",
       "    XGB_f1_2  XGB_PRC_AUC_1  XGB_PRC_AUC_2  LR_precision_1  LR_precision_2  \\\n",
       "0   0.845690       0.952647       0.955318        1.000000        1.000000   \n",
       "1   0.841202       0.844487       0.950370        0.550926        0.956197   \n",
       "2   0.756677       0.967942       0.967989        0.583942        1.000000   \n",
       "3   0.982630       0.965854       0.965854        1.000000        1.000000   \n",
       "4   0.708380       0.774222       0.774222        0.551351        0.548443   \n",
       "5   0.795086       0.726882       0.736078        0.540564        0.810559   \n",
       "6   0.997689       0.997695       0.997695        0.995270        0.995306   \n",
       "7   0.869739       0.901355       0.901355        0.832351        0.827153   \n",
       "8   0.858689       0.883658       0.883653        0.767649        0.767619   \n",
       "9   0.859273       0.810260       0.872267        0.825536        0.965092   \n",
       "10  0.727156       0.718221       0.718423        0.542074        0.674534   \n",
       "11  0.755393       0.753893       0.753868        0.000000        0.656959   \n",
       "12  0.780831       0.792898       0.792879        0.663067        0.686459   \n",
       "13  0.794379       0.816212       0.816216        0.797266        0.779650   \n",
       "\n",
       "    ...  LR_PRC_AUC_1  LR_PRC_AUC_2  RF_precision_1  RF_precision_2  \\\n",
       "0   ...      0.924717      0.953018        1.000000        1.000000   \n",
       "1   ...      0.776316      0.974990        0.631628        1.000000   \n",
       "2   ...      0.775000      0.966394        1.000000        1.000000   \n",
       "3   ...      0.981636      0.965854        1.000000        1.000000   \n",
       "4   ...      0.764474      0.774222        0.548443        0.548443   \n",
       "5   ...      0.778373      0.822846        0.813470        0.626994   \n",
       "6   ...      0.997635      0.997695        0.995389        0.995389   \n",
       "7   ...      0.901250      0.901363        0.827153        0.827153   \n",
       "8   ...      0.865748      0.883294        0.767649        0.767649   \n",
       "9   ...      0.889553      0.909132        0.858473        0.809087   \n",
       "10  ...      0.763933      0.771983        0.671033        0.671033   \n",
       "11  ...      0.753665      0.774019        0.660885        0.660873   \n",
       "12  ...      0.775302      0.807716        0.688746        0.688746   \n",
       "13  ...      0.788379      0.816196        0.777438        0.779650   \n",
       "\n",
       "    RF_recall_1  RF_recall_2   RF_f1_1   RF_f1_2  RF_PRC_AUC_1  RF_PRC_AUC_2  \n",
       "0      0.732637     0.732637  0.845690  0.845690      0.945936      0.953861  \n",
       "1      0.752414     0.729302  0.686750  0.843464      0.864633      0.965807  \n",
       "2      0.608710     0.608663  0.756768  0.756732      0.968059      0.968059  \n",
       "3      0.965854     0.965854  0.982630  0.982630      0.965854      0.965854  \n",
       "4      1.000000     1.000000  0.708380  0.708380      0.774222      0.774222  \n",
       "5      0.777514     0.864753  0.795086  0.726926      0.732680      0.726891  \n",
       "6      1.000000     1.000000  0.997689  0.997689      0.997695      0.997695  \n",
       "7      0.916948     0.916948  0.869739  0.869739      0.901355      0.901344  \n",
       "8      0.974230     0.974230  0.858689  0.858689      0.883611      0.883514  \n",
       "9      0.830797     0.830797  0.844408  0.819798      0.852482      0.859970  \n",
       "10     0.793525     0.793525  0.727156  0.727156      0.718239      0.718325  \n",
       "11     0.881529     0.881481  0.755425  0.755400      0.753954      0.753907  \n",
       "12     0.901340     0.901340  0.780831  0.780831      0.791408      0.792865  \n",
       "13     0.809019     0.809675  0.792914  0.794379      0.816082      0.816214  \n",
       "\n",
       "[14 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "Name: XGB_precision_rank1, dtype: int64\n",
      "[('XGB_precision_rank1', 1.0), ('LR_precision_rank1', 1.0), ('RF_precision_rank1', 1.0)]\n",
      "[('XGB_precision_rank1', 0.9202797202797204), ('RF_precision_rank1', 0.6316279069767442), ('LR_precision_rank1', 0.5509259259259259)]\n",
      "[('XGB_precision_rank1', 1.0), ('RF_precision_rank1', 1.0), ('LR_precision_rank1', 0.583941605839416)]\n",
      "[('XGB_precision_rank1', 1.0), ('LR_precision_rank1', 1.0), ('RF_precision_rank1', 1.0)]\n",
      "[('LR_precision_rank1', 0.5513513513513514), ('XGB_precision_rank1', 0.5484434561626429), ('RF_precision_rank1', 0.5484434561626429)]\n",
      "[('RF_precision_rank1', 0.813469894475481), ('XGB_precision_rank1', 0.6269986050005365), ('LR_precision_rank1', 0.5405643738977073)]\n",
      "[('XGB_precision_rank1', 0.9953890006706908), ('RF_precision_rank1', 0.9953890006706908), ('LR_precision_rank1', 0.9952702418211674)]\n",
      "[('LR_precision_rank1', 0.8323512640182474), ('XGB_precision_rank1', 0.8271534512264689), ('RF_precision_rank1', 0.8271534512264689)]\n",
      "[('XGB_precision_rank1', 0.767648837812149), ('LR_precision_rank1', 0.767648837812149), ('RF_precision_rank1', 0.767648837812149)]\n",
      "[('RF_precision_rank1', 0.8584729981378026), ('LR_precision_rank1', 0.8255360623781677), ('XGB_precision_rank1', 0.6653420685211041)]\n",
      "[('RF_precision_rank1', 0.6710326606329754), ('XGB_precision_rank1', 0.670995670995671), ('LR_precision_rank1', 0.5420743639921722)]\n",
      "[('RF_precision_rank1', 0.6608851244425262), ('XGB_precision_rank1', 0.6608668285226149), ('LR_precision_rank1', 0.0)]\n",
      "[('XGB_precision_rank1', 0.6887458310711239), ('RF_precision_rank1', 0.6887458310711239), ('LR_precision_rank1', 0.6630668051228799)]\n",
      "[('LR_precision_rank1', 0.7972659587452704), ('XGB_precision_rank1', 0.7796495195025438), ('RF_precision_rank1', 0.777438334464811)]\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     2\n",
      "5     2\n",
      "6     1\n",
      "7     2\n",
      "8     1\n",
      "9     3\n",
      "10    2\n",
      "11    2\n",
      "12    1\n",
      "13    2\n",
      "Name: XGB_precision_rank1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rank_column = [0]*14\n",
    "final_result_df['XGB_precision_rank1'] = rank_column\n",
    "final_result_df['XGB_recall_rank1'] = rank_column\n",
    "final_result_df['XGB_f1_rank1'] = rank_column\n",
    "final_result_df['XGB_PRC_AUC_rank1'] = rank_column\n",
    "final_result_df['LR_precision_rank1'] = rank_column\n",
    "final_result_df['LR_recall_rank1'] = rank_column\n",
    "final_result_df['LR_f1_rank1'] = rank_column\n",
    "final_result_df['LR_PRC_AUC_rank1'] = rank_column\n",
    "final_result_df['RF_precision_rank1'] = rank_column\n",
    "final_result_df['RF_recall_rank1'] = rank_column\n",
    "final_result_df['RF_f1_rank1'] = rank_column\n",
    "final_result_df['RF_PRC_AUC_rank1'] = rank_column\n",
    "\n",
    "final_result_df['XGB_precision_rank2'] = rank_column\n",
    "final_result_df['XGB_recall_rank2'] = rank_column\n",
    "final_result_df['XGB_f1_rank2'] = rank_column\n",
    "final_result_df['XGB_PRC_AUC_rank2'] = rank_column\n",
    "final_result_df['LR_precision_rank2'] = rank_column\n",
    "final_result_df['LR_recall_rank2'] = rank_column\n",
    "final_result_df['LR_f1_rank2'] = rank_column\n",
    "final_result_df['LR_PRC_AUC_rank2'] = rank_column\n",
    "final_result_df['RF_precision_rank2'] = rank_column\n",
    "final_result_df['RF_recall_rank2'] = rank_column\n",
    "final_result_df['RF_f1_rank2'] = rank_column\n",
    "final_result_df['RF_PRC_AUC_rank2'] = rank_column\n",
    "\n",
    "print(final_result_df['XGB_precision_rank1'])\n",
    "for index, row in final_result_df.iterrows():\n",
    "    precision_items = [('XGB_precision_rank1', row['XGB_precision_1']), ('LR_precision_rank1', row['LR_precision_1']), ('RF_precision_rank1', row['RF_precision_1'])]\n",
    "    recall_items = [('XGB_recall_rank1', row['XGB_recall_1']), ('LR_recall_rank1', row['LR_recall_1']), ('RF_recall_rank1', row['RF_recall_1'])]\n",
    "    f1_items = [('XGB_f1_rank1', row['XGB_f1_1']), ('LR_f1_rank1', row['LR_f1_1']), ('RF_f1_rank1', row['RF_f1_1'])]\n",
    "    prc_items = [('XGB_PRC_AUC_rank1', row['XGB_PRC_AUC_1']), ('LR_PRC_AUC_rank1', row['LR_PRC_AUC_1']), ('RF_PRC_AUC_rank1', row['RF_PRC_AUC_1'])]\n",
    "    \n",
    "    sorted_result = sorted(precision_items, key=lambda tup: tup[1], reverse=True)\n",
    "    print(sorted_result)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "     \n",
    "    sorted_result = sorted(recall_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "        \n",
    "    sorted_result = sorted(f1_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "        \n",
    "    sorted_result = sorted(prc_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "    \n",
    "    precision_items = [('XGB_precision_rank2', row['XGB_precision_2']), ('LR_precision_rank2', row['LR_precision_2']), ('RF_precision_rank2', row['RF_precision_2'])]\n",
    "    recall_items = [('XGB_recall_rank2', row['XGB_recall_2']), ('LR_recall_rank2', row['LR_recall_2']), ('RF_recall_rank2', row['RF_recall_2'])]\n",
    "    f1_items = [('XGB_f1_rank2', row['XGB_f1_2']), ('LR_f1_rank2', row['LR_f1_2']), ('RF_f1_rank2', row['RF_f1_2'])]\n",
    "    prc_items = [('XGB_PRC_AUC_rank2', row['XGB_PRC_AUC_2']), ('LR_PRC_AUC_rank2', row['LR_PRC_AUC_2']), ('RF_PRC_AUC_rank2', row['RF_PRC_AUC_2'])]\n",
    "    \n",
    "    sorted_result = sorted(precision_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "        \n",
    "    sorted_result = sorted(recall_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "        \n",
    "    sorted_result = sorted(f1_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "        \n",
    "    sorted_result = sorted(prc_items, key=lambda tup: tup[1], reverse=True)\n",
    "    rank = 1\n",
    "    for column, _ in sorted_result:\n",
    "        final_result_df.loc[index, column] = rank\n",
    "        rank += 1\n",
    "print(final_result_df['XGB_precision_rank1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB_precision_1</th>\n",
       "      <th>XGB_precision_2</th>\n",
       "      <th>XGB_recall_1</th>\n",
       "      <th>XGB_recall_2</th>\n",
       "      <th>XGB_f1_1</th>\n",
       "      <th>XGB_f1_2</th>\n",
       "      <th>XGB_PRC_AUC_1</th>\n",
       "      <th>XGB_PRC_AUC_2</th>\n",
       "      <th>LR_precision_1</th>\n",
       "      <th>LR_precision_2</th>\n",
       "      <th>...</th>\n",
       "      <th>XGB_f1_rank2</th>\n",
       "      <th>XGB_PRC_AUC_rank2</th>\n",
       "      <th>LR_precision_rank2</th>\n",
       "      <th>LR_recall_rank2</th>\n",
       "      <th>LR_f1_rank2</th>\n",
       "      <th>LR_PRC_AUC_rank2</th>\n",
       "      <th>RF_precision_rank2</th>\n",
       "      <th>RF_recall_rank2</th>\n",
       "      <th>RF_f1_rank2</th>\n",
       "      <th>RF_PRC_AUC_rank2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734094</td>\n",
       "      <td>0.732637</td>\n",
       "      <td>0.846660</td>\n",
       "      <td>0.845690</td>\n",
       "      <td>0.952647</td>\n",
       "      <td>0.955318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.920280</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.813637</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.844487</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>0.550926</td>\n",
       "      <td>0.956197</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608546</td>\n",
       "      <td>0.608593</td>\n",
       "      <td>0.756641</td>\n",
       "      <td>0.756677</td>\n",
       "      <td>0.967942</td>\n",
       "      <td>0.967989</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.548443</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.708380</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.774222</td>\n",
       "      <td>0.551351</td>\n",
       "      <td>0.548443</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.626999</td>\n",
       "      <td>0.813470</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.777514</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>0.795086</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.736078</td>\n",
       "      <td>0.540564</td>\n",
       "      <td>0.810559</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.995270</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.916948</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.901355</td>\n",
       "      <td>0.901355</td>\n",
       "      <td>0.832351</td>\n",
       "      <td>0.827153</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.858689</td>\n",
       "      <td>0.883658</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.767649</td>\n",
       "      <td>0.767619</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.665342</td>\n",
       "      <td>0.889771</td>\n",
       "      <td>0.828984</td>\n",
       "      <td>0.830797</td>\n",
       "      <td>0.738203</td>\n",
       "      <td>0.859273</td>\n",
       "      <td>0.810260</td>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>0.965092</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.670996</td>\n",
       "      <td>0.671033</td>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.793525</td>\n",
       "      <td>0.727079</td>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.718221</td>\n",
       "      <td>0.718423</td>\n",
       "      <td>0.542074</td>\n",
       "      <td>0.674534</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.660867</td>\n",
       "      <td>0.660870</td>\n",
       "      <td>0.881457</td>\n",
       "      <td>0.881469</td>\n",
       "      <td>0.755387</td>\n",
       "      <td>0.755393</td>\n",
       "      <td>0.753893</td>\n",
       "      <td>0.753868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656959</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.780831</td>\n",
       "      <td>0.792898</td>\n",
       "      <td>0.792879</td>\n",
       "      <td>0.663067</td>\n",
       "      <td>0.686459</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.794379</td>\n",
       "      <td>0.816212</td>\n",
       "      <td>0.816216</td>\n",
       "      <td>0.797266</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGB_precision_1  XGB_precision_2  XGB_recall_1  XGB_recall_2  XGB_f1_1  \\\n",
       "0          1.000000         1.000000      0.734094      0.732637  0.846660   \n",
       "1          0.920280         0.993958      0.729144      0.729144  0.813637   \n",
       "2          1.000000         1.000000      0.608546      0.608593  0.756641   \n",
       "3          1.000000         1.000000      0.965854      0.965854  0.982630   \n",
       "4          0.548443         0.548443      1.000000      1.000000  0.708380   \n",
       "5          0.626999         0.813470      0.864605      0.777514  0.726877   \n",
       "6          0.995389         0.995389      1.000000      1.000000  0.997689   \n",
       "7          0.827153         0.827153      0.916948      0.916948  0.869739   \n",
       "8          0.767649         0.767649      0.974230      0.974230  0.858689   \n",
       "9          0.665342         0.889771      0.828984      0.830797  0.738203   \n",
       "10         0.670996         0.671033      0.793392      0.793525  0.727079   \n",
       "11         0.660867         0.660870      0.881457      0.881469  0.755387   \n",
       "12         0.688746         0.688746      0.901340      0.901340  0.780831   \n",
       "13         0.779650         0.779650      0.809675      0.809675  0.794379   \n",
       "\n",
       "    XGB_f1_2  XGB_PRC_AUC_1  XGB_PRC_AUC_2  LR_precision_1  LR_precision_2  \\\n",
       "0   0.845690       0.952647       0.955318        1.000000        1.000000   \n",
       "1   0.841202       0.844487       0.950370        0.550926        0.956197   \n",
       "2   0.756677       0.967942       0.967989        0.583942        1.000000   \n",
       "3   0.982630       0.965854       0.965854        1.000000        1.000000   \n",
       "4   0.708380       0.774222       0.774222        0.551351        0.548443   \n",
       "5   0.795086       0.726882       0.736078        0.540564        0.810559   \n",
       "6   0.997689       0.997695       0.997695        0.995270        0.995306   \n",
       "7   0.869739       0.901355       0.901355        0.832351        0.827153   \n",
       "8   0.858689       0.883658       0.883653        0.767649        0.767619   \n",
       "9   0.859273       0.810260       0.872267        0.825536        0.965092   \n",
       "10  0.727156       0.718221       0.718423        0.542074        0.674534   \n",
       "11  0.755393       0.753893       0.753868        0.000000        0.656959   \n",
       "12  0.780831       0.792898       0.792879        0.663067        0.686459   \n",
       "13  0.794379       0.816212       0.816216        0.797266        0.779650   \n",
       "\n",
       "    ...  XGB_f1_rank2  XGB_PRC_AUC_rank2  LR_precision_rank2  LR_recall_rank2  \\\n",
       "0   ...             1                  1                   2                2   \n",
       "1   ...             2                  3                   3                3   \n",
       "2   ...             2                  2                   2                3   \n",
       "3   ...             1                  1                   2                2   \n",
       "4   ...             1                  1                   2                2   \n",
       "5   ...             1                  2                   2                3   \n",
       "6   ...             1                  1                   3                2   \n",
       "7   ...             1                  2                   2                2   \n",
       "8   ...             1                  1                   3                3   \n",
       "9   ...             2                  2                   1                3   \n",
       "10  ...             1                  2                   1                3   \n",
       "11  ...             2                  3                   3                1   \n",
       "12  ...             2                  2                   3                1   \n",
       "13  ...             1                  1                   2                2   \n",
       "\n",
       "    LR_f1_rank2  LR_PRC_AUC_rank2  RF_precision_rank2  RF_recall_rank2  \\\n",
       "0             2                 3                   3                3   \n",
       "1             3                 1                   1                1   \n",
       "2             3                 3                   3                1   \n",
       "3             2                 2                   3                3   \n",
       "4             2                 2                   3                3   \n",
       "5             2                 1                   3                1   \n",
       "6             3                 2                   2                3   \n",
       "7             2                 1                   3                3   \n",
       "8             3                 3                   2                2   \n",
       "9             1                 1                   3                2   \n",
       "10            3                 1                   3                2   \n",
       "11            3                 1                   1                2   \n",
       "12            1                 1                   2                3   \n",
       "13            2                 3                   3                3   \n",
       "\n",
       "    RF_f1_rank2  RF_PRC_AUC_rank2  \n",
       "0             3                 2  \n",
       "1             1                 2  \n",
       "2             1                 1  \n",
       "3             3                 3  \n",
       "4             3                 3  \n",
       "5             3                 3  \n",
       "6             2                 3  \n",
       "7             3                 3  \n",
       "8             2                 2  \n",
       "9             3                 3  \n",
       "10            2                 3  \n",
       "11            1                 2  \n",
       "12            3                 3  \n",
       "13            3                 2  \n",
       "\n",
       "[14 rows x 48 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_precision_1        0.796537\n",
      "XGB_precision_2        0.831152\n",
      "XGB_recall_1           0.857733\n",
      "XGB_recall_2           0.851552\n",
      "XGB_f1_1               0.811202\n",
      "XGB_f1_2               0.826630\n",
      "XGB_PRC_AUC_1          0.850445\n",
      "XGB_PRC_AUC_2          0.863299\n",
      "LR_precision_1         0.689285\n",
      "LR_precision_2         0.833426\n",
      "LR_recall_1            0.693540\n",
      "LR_recall_2            0.849996\n",
      "LR_f1_1                0.676498\n",
      "LR_f1_2                0.826877\n",
      "LR_PRC_AUC_1           0.838284\n",
      "LR_PRC_AUC_2           0.879909\n",
      "RF_precision_1         0.802879\n",
      "RF_precision_2         0.812501\n",
      "RF_recall_1            0.853180\n",
      "RF_recall_2            0.857800\n",
      "RF_f1_1                0.814440\n",
      "RF_f1_2                0.819107\n",
      "RF_PRC_AUC_1           0.854729\n",
      "RF_PRC_AUC_2           0.862752\n",
      "XGB_precision_rank1    1.571429\n",
      "XGB_recall_rank1       1.642857\n",
      "XGB_f1_rank1           1.571429\n",
      "XGB_PRC_AUC_rank1      1.714286\n",
      "LR_precision_rank1     2.285714\n",
      "LR_recall_rank1        2.285714\n",
      "LR_f1_rank1            2.500000\n",
      "LR_PRC_AUC_rank1       2.428571\n",
      "RF_precision_rank1     2.142857\n",
      "RF_recall_rank1        2.071429\n",
      "RF_f1_rank1            1.928571\n",
      "RF_PRC_AUC_rank1       1.857143\n",
      "XGB_precision_rank2    1.285714\n",
      "XGB_recall_rank2       1.428571\n",
      "XGB_f1_rank2           1.357143\n",
      "XGB_PRC_AUC_rank2      1.714286\n",
      "LR_precision_rank2     2.214286\n",
      "LR_recall_rank2        2.285714\n",
      "LR_f1_rank2            2.285714\n",
      "LR_PRC_AUC_rank2       1.785714\n",
      "RF_precision_rank2     2.500000\n",
      "RF_recall_rank2        2.285714\n",
      "RF_f1_rank2            2.357143\n",
      "RF_PRC_AUC_rank2       2.500000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_mean = final_result_df.mean()\n",
    "print(results_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean.to_csv('70_30_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Unnamed: 0         0\n",
      "0       XGB_precision_1  0.796537\n",
      "1       XGB_precision_2  0.831152\n",
      "2          XGB_recall_1  0.857733\n",
      "3          XGB_recall_2  0.851552\n",
      "4              XGB_f1_1  0.811202\n",
      "5              XGB_f1_2  0.826630\n",
      "6         XGB_PRC_AUC_1  0.850445\n",
      "7         XGB_PRC_AUC_2  0.863299\n",
      "8        LR_precision_1  0.689285\n",
      "9        LR_precision_2  0.833426\n",
      "10          LR_recall_1  0.693540\n",
      "11          LR_recall_2  0.849996\n",
      "12              LR_f1_1  0.676498\n",
      "13              LR_f1_2  0.826877\n",
      "14         LR_PRC_AUC_1  0.838284\n",
      "15         LR_PRC_AUC_2  0.879909\n",
      "16       RF_precision_1  0.802879\n",
      "17       RF_precision_2  0.812501\n",
      "18          RF_recall_1  0.853180\n",
      "19          RF_recall_2  0.857800\n",
      "20              RF_f1_1  0.814440\n",
      "21              RF_f1_2  0.819107\n",
      "22         RF_PRC_AUC_1  0.854729\n",
      "23         RF_PRC_AUC_2  0.862752\n",
      "24  XGB_precision_rank1  1.571429\n",
      "25     XGB_recall_rank1  1.642857\n",
      "26         XGB_f1_rank1  1.571429\n",
      "27    XGB_PRC_AUC_rank1  1.714286\n",
      "28   LR_precision_rank1  2.285714\n",
      "29      LR_recall_rank1  2.285714\n",
      "30          LR_f1_rank1  2.500000\n",
      "31     LR_PRC_AUC_rank1  2.428571\n",
      "32   RF_precision_rank1  2.142857\n",
      "33      RF_recall_rank1  2.071429\n",
      "34          RF_f1_rank1  1.928571\n",
      "35     RF_PRC_AUC_rank1  1.857143\n",
      "36  XGB_precision_rank2  1.285714\n",
      "37     XGB_recall_rank2  1.428571\n",
      "38         XGB_f1_rank2  1.357143\n",
      "39    XGB_PRC_AUC_rank2  1.714286\n",
      "40   LR_precision_rank2  2.214286\n",
      "41      LR_recall_rank2  2.285714\n",
      "42          LR_f1_rank2  2.285714\n",
      "43     LR_PRC_AUC_rank2  1.785714\n",
      "44   RF_precision_rank2  2.500000\n",
      "45      RF_recall_rank2  2.285714\n",
      "46          RF_f1_rank2  2.357143\n",
      "47     RF_PRC_AUC_rank2  2.500000\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('70_30_results.csv')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
