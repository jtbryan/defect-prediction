{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis of Vagrant Developers\n",
    "<a href=\"#TODO's\">TODO</a><br>\n",
    "<a href=\"#Imports\">Imports</a><br>\n",
    "<a href=\"#Functions\">Functions</a><br>\n",
    "<a href=\"#Analysis\">Analysis</a><br>\n",
    "<a href=\"#Graph-Based-Analysis-using-Logistic-Regression,-Random-Forest-Classifer,-and-XGBoost-classifier\"><b>Analysis</b> - Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier</a><br>\n",
    "<a href=\"#Cross-Validation\"><b>Analysis</b> - Cross Validation</a><br>\n",
    "<a href=\"#Rebalancing-data\"><b>Analysis</b> - Data Rebalancing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO's\n",
    "\n",
    "<ul>\n",
    "<li>Implement a new dataframe to store the results from each section. (refer to last cell)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "import numpy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve, plot_precision_recall_curve, auc, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, LeaveOneOut, KFold, StratifiedKFold, RepeatedKFold, TimeSeriesSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import statsmodels.api as sm\n",
    "from ast import literal_eval\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(model, x, y):\n",
    "    '''\n",
    "    Plots the predictions made using a linear regression model \n",
    "    given the set of dependent variable(s) and the independent variable\n",
    "        model: Linear Regression Model\n",
    "        x: Dependent Variable(s)\n",
    "        y: Independent Variable\n",
    "    returns: Independent Variable Predictions\n",
    "    '''\n",
    "    y_pred = model.predict(x)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_pred, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# source: https://stackoverflow.com/questions/26319259/how-to-get-a-regression-summary-in-python-scikit-like-r-does\n",
    "def regression_results(y_true, y_pred):\n",
    "    '''\n",
    "    Analyzes the results from the linear regression model prediction using different metrics, such r^2\n",
    "    '''\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def Loo(model, x, y):\n",
    "    '''\n",
    "    Uses the LeaveOneOut cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    loo = LeaveOneOut() \n",
    "    highestscore = (0, \"\")\n",
    "    y_true, y_pred = list(), list()\n",
    "    \n",
    "    # Split the data\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        predictions = model.predict_proba(x_test)\n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        score = model.score(x_test, y_test) # NOTE: Removed the following due to errors: prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if score > highestscore[0]:\n",
    "            highestscore = (model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\")\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[1])\n",
    "    print(\"\\nModel Score: {}\\n\".format(highestscore[0]))\n",
    "    #acc = accuracy_score(y_true, y_pred)\n",
    "    #print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    \n",
    "def Loo_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the LeaveOneOut cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = LeaveOneOut()\n",
    "    # to see list of scoring methods, go to: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Rkf(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the RepeatedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    kf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42) \n",
    "    #kf.get_n_splits(x)\n",
    "    #print(kf)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"Average Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "\n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "    \n",
    "def Rkf_short(model, x, y):    \n",
    "    '''\n",
    "    Uses the shortened version of the RepeatedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Skf(model, x, y, threshold = None):\n",
    "    '''\n",
    "    Uses the StratifiedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "            \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "    \n",
    "def Skf_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the StratifiedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))    \n",
    "\n",
    "def Tss(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the TimeSeriesSplit cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    rcall = None\n",
    "    yhat = None\n",
    "    \n",
    "    for train_index, test_index in tscv.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "\n",
    "def Tss_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the TimeSeriesSplit cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = TimeSeriesSplit(n_splits=10)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores))) \n",
    "    \n",
    "def Compare_Model_Scores(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    \n",
    "    print(\"Predictions for model 1: \")\n",
    "    print(prediction_probs1)\n",
    "    print(\"\\nPredictions for model 2: \")\n",
    "    print(prediction_probs2)\n",
    "    '''\n",
    "    \n",
    "    #recall1, recall2, precision1, precision2, thresholds_list = get_precision_recall(test_x1, test_x2, y_test, model1, model2)\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:, 1]) \n",
    "    #retrieve probability of being 1(in second column of probs_y)\n",
    "    \n",
    "    pr_auc1 = auc(recall1, precision1)\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    \n",
    "    pr_auc2 = auc(recall2, precision2)\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2\n",
    "    \n",
    "def Compare_Model_Scores_Best_Threshold(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:,1])\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    \n",
    "    pr_auc1 = auc(recall1[ix1:], precision1[ix1:])\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore2[np.isnan(fscore2)] = 0  \n",
    "    ix2 = np.argmax(fscore2)\n",
    "    \n",
    "    pr_auc2 = auc(recall2[ix2:], precision2[ix2:])\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2\n",
    "\n",
    "def plot_thresholds(model1, model2, test_x1, test_y1, test_x2, test_y2, prediction_probs1, prediction_probs2, title):\n",
    "    '''Predict test_y values and probabilities based on fitted logistic for both models''' \n",
    "\n",
    "    # recall1, recall2, precision1, precision2, threshold_list = get_precision_recall(test_x1, test_x2, test_y1, model1, model2)\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(test_y1, prediction_probs1[:, 1]) \n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(test_y2, prediction_probs2[:, 1])\n",
    "    \n",
    "    # convert to f1 score\n",
    "    # from: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    fscore2[np.isnan(fscore2)] = 0 \n",
    "    \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    ix2 = np.argmax(fscore2)\n",
    "    #print(f\"F score 1: {fscore1} with ix: {ix1}\")\n",
    "    #print(f\"F score 2: {fscore2} with ix: {ix2}\")\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 1' % (thresholds1[ix1], fscore1[ix1]))\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 2' % (thresholds2[ix2], fscore2[ix2]))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.title(f\"PRC for {title}\")\n",
    "    # use marker = \".\" to see each threshhold value\n",
    "    plt.plot(recall1[:-1], precision1[:-1], \"b\", label=f\"Model 1\\n-----------\\n • PRC-AUC score: {auc(recall1[ix1:], precision1[ix1:]):.2f}\\n • Best Threshold: {round(thresholds1[ix1], 2):.2f}\\n • Best F1-Score: {round(fscore1[ix1], 2):.2f}\\n\")\n",
    "    plt.plot(recall2[:-1], precision2[:-1], \"r--\", label=f\"Model 2\\n-----------\\n • PRC-AUC score: {auc(recall2[ix2:], precision2[ix2:]):.2f}\\n • Best Threshold: {round(thresholds2[ix2], 2):.2f}\\n • Best F1-Score: {round(fscore2[ix2], 2):.2f}\")\n",
    "    plt.scatter([recall1[ix1], recall2[ix2]], [precision1[ix1], precision2[ix2]], marker='o', color='black', label='Best threshold')\n",
    "    #plt.annotate('Model 1 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds1[ix1], fscore1[ix1]), (0.38, 0.35), fontsize=8)\n",
    "    #plt.annotate('Model 2 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds2[ix2], fscore2[ix2]), (0.38, 0.3), fontsize=8)\n",
    "    \n",
    "    x1 = np.array(recall1[ix1:], dtype=float)\n",
    "    x2 = np.array(recall2[ix2:], dtype=float)\n",
    "    y1 = np.array(precision1[ix1:], dtype=float)\n",
    "    y2 = np.array(precision2[ix2:], dtype=float)\n",
    "    y1_opp = np.array(precision1[ix2:], dtype=float)\n",
    "    \n",
    "    #plt.fill_between(x1, y1, color='b', alpha=0.5)\n",
    "    # where=y1_opp<=y2\n",
    "    #plt.fill_between(x2, y2, color='r', alpha=0.3)\n",
    "    \n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    plt.ylim([0,1])\n",
    "    plt.xlim([0,1])\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return thresholds1[ix1], thresholds2[ix2], fig\n",
    "    \n",
    "def simple_threshold_plot(classifier, x_test, y_test):\n",
    "    predictions = classifier.predict(x_test)\n",
    "    prc_val = average_precision_score(y_test, predictions)\n",
    "    disp = plot_precision_recall_curve(classifier, x_test, y_test)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(prc_val))\n",
    "    \n",
    "def get_precision_recall(test_x1, test_x2, test_y, model1, model2):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with each type of threshold\n",
    "    '''\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, 1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "        \n",
    "    return recall1, recall2, precision1, precision2, threshold_list\n",
    "\n",
    "def get_precision_recall_best_thresh(test_x1, test_x2, test_y, model1, model2, best_thresh1=None, best_thresh2=None):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with the best threshold\n",
    "    '''\n",
    "    limit1, limit2 = 1, 1\n",
    "    if best_thresh1 != None:\n",
    "        limit1 = best_thresh1\n",
    "    if best_thresh2 != None:\n",
    "        limit2 = best_thresh2\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, limit1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        \n",
    "    threshold_list = np.arange(0.001, limit2, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "    return recall1, recall2, precision1, precision2, threshold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of all of the unique commits (i.e. links) between developers and the corresponding folders\n",
    "graph_df = pd.read_csv(\"../../Neo4j_output/JiT_Reliability_Output/Pig.csv\")\n",
    "\n",
    "new_columns = {}\n",
    "\n",
    "# Generate binary classification for our dataframe based on if a developer \n",
    "# introduced a bug or not with the corresponding commit\n",
    "for index in graph_df.index:\n",
    "    if graph_df.loc[index, \"Bug\"] != \"INTRODUCED_NEW_BUG\":\n",
    "        graph_df.loc[index, \"Bug\"] = 0\n",
    "    else:\n",
    "        graph_df.loc[index, \"Bug\"] = 1\n",
    "        \n",
    "    # separate each node2vec embedding into it's own unique label\n",
    "    embeddings = literal_eval(graph_df.loc[index, 'n2vEmbedding'])\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        if f\"emb_{i}\" not in new_columns:\n",
    "            new_columns[f\"emb_{i}\"] = []\n",
    "            new_columns[f\"emb_{i}\"].append(embedding)\n",
    "        else:\n",
    "            new_columns[f\"emb_{i}\"].append(embedding)\n",
    "\n",
    "# delete the n2vEmbedding label, as the list has now been separated into their own unique labels \n",
    "del graph_df['n2vEmbedding']\n",
    "temp_df = pd.DataFrame.from_dict(new_columns)\n",
    "graph_df = graph_df.join(temp_df)\n",
    "            \n",
    "graph_df['Bug'] = graph_df.Bug.astype('int')\n",
    "    \n",
    "x = graph_df[\"Name\"]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Koji Noguchi</td>\n",
       "      <td>test/org/apache/pig/test/TestMultiQueryBasic.java</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1.572914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.955528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546818</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>-0.668151</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>-0.529091</td>\n",
       "      <td>0.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Koji Noguchi</td>\n",
       "      <td>src/org/apache/pig/newplan/logical/visitor/Sca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1.572914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.955528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546818</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>-0.668151</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>-0.529091</td>\n",
       "      <td>0.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koji Noguchi</td>\n",
       "      <td>CHANGES.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1.572914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.955528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546818</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>-0.668151</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>-0.529091</td>\n",
       "      <td>0.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koji Noguchi</td>\n",
       "      <td>test/org/apache/pig/test/TestUnion.java</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1.572914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.955528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546818</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>-0.668151</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>-0.529091</td>\n",
       "      <td>0.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koji Noguchi</td>\n",
       "      <td>test/org/apache/pig/test/TestTypeCheckingValid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>1.572914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.955528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546818</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>-0.668151</td>\n",
       "      <td>0.697140</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>-0.529091</td>\n",
       "      <td>0.156157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27153</th>\n",
       "      <td>Christopher Olston</td>\n",
       "      <td>src/org/apache/pig/tools/{grunt/GruntParser.jj...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>-0.327987</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.323296</td>\n",
       "      <td>-0.580270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27154</th>\n",
       "      <td>Christopher Olston</td>\n",
       "      <td>src/org/apache/pig/tools/grunt/GruntParser.java</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>-0.327987</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.323296</td>\n",
       "      <td>-0.580270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27155</th>\n",
       "      <td>Christopher Olston</td>\n",
       "      <td>src/org/apache/pig/impl/logicalLayer/LOEval.java</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>-0.327987</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.323296</td>\n",
       "      <td>-0.580270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27156</th>\n",
       "      <td>Christopher Olston</td>\n",
       "      <td>src/org/apache/pig/impl/logicalLayer/LOCogroup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>-0.327987</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.323296</td>\n",
       "      <td>-0.580270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27157</th>\n",
       "      <td>Christopher Olston</td>\n",
       "      <td>build.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.091666</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.476298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>0.641442</td>\n",
       "      <td>-0.327987</td>\n",
       "      <td>0.735042</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.320902</td>\n",
       "      <td>0.617582</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.323296</td>\n",
       "      <td>-0.580270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27158 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name                                               File  \\\n",
       "0            Koji Noguchi  test/org/apache/pig/test/TestMultiQueryBasic.java   \n",
       "1            Koji Noguchi  src/org/apache/pig/newplan/logical/visitor/Sca...   \n",
       "2            Koji Noguchi                                        CHANGES.txt   \n",
       "3            Koji Noguchi            test/org/apache/pig/test/TestUnion.java   \n",
       "4            Koji Noguchi  test/org/apache/pig/test/TestTypeCheckingValid...   \n",
       "...                   ...                                                ...   \n",
       "27153  Christopher Olston  src/org/apache/pig/tools/{grunt/GruntParser.jj...   \n",
       "27154  Christopher Olston    src/org/apache/pig/tools/grunt/GruntParser.java   \n",
       "27155  Christopher Olston   src/org/apache/pig/impl/logicalLayer/LOEval.java   \n",
       "27156  Christopher Olston  src/org/apache/pig/impl/logicalLayer/LOCogroup...   \n",
       "27157  Christopher Olston                                          build.xml   \n",
       "\n",
       "       Bug  PageRank  Betweenness  Closeness  Harmonic  Degree  communityId  \\\n",
       "0        0  0.994971     1.572914   1.000000  0.976744  5178.0           32   \n",
       "1        0  0.994971     1.572914   1.000000  0.976744  5178.0           32   \n",
       "2        0  0.994971     1.572914   1.000000  0.976744  5178.0           32   \n",
       "3        0  0.994971     1.572914   1.000000  0.976744  5178.0           32   \n",
       "4        0  0.994971     1.572914   1.000000  0.976744  5178.0           32   \n",
       "...    ...       ...          ...        ...       ...     ...          ...   \n",
       "27153    0  0.223828     0.091666   0.893617  0.918605    70.0           32   \n",
       "27154    0  0.223828     0.091666   0.893617  0.918605    70.0           32   \n",
       "27155    0  0.223828     0.091666   0.893617  0.918605    70.0           32   \n",
       "27156    0  0.223828     0.091666   0.893617  0.918605    70.0           32   \n",
       "27157    0  0.223828     0.091666   0.893617  0.918605    70.0           32   \n",
       "\n",
       "          emb_0  ...   emb_118   emb_119   emb_120   emb_121   emb_122  \\\n",
       "0     -0.955528  ... -0.546818  0.191431  0.402488  0.169185  0.539597   \n",
       "1     -0.955528  ... -0.546818  0.191431  0.402488  0.169185  0.539597   \n",
       "2     -0.955528  ... -0.546818  0.191431  0.402488  0.169185  0.539597   \n",
       "3     -0.955528  ... -0.546818  0.191431  0.402488  0.169185  0.539597   \n",
       "4     -0.955528  ... -0.546818  0.191431  0.402488  0.169185  0.539597   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "27153 -0.476298  ... -0.447549  0.641442 -0.327987  0.735042  0.279529   \n",
       "27154 -0.476298  ... -0.447549  0.641442 -0.327987  0.735042  0.279529   \n",
       "27155 -0.476298  ... -0.447549  0.641442 -0.327987  0.735042  0.279529   \n",
       "27156 -0.476298  ... -0.447549  0.641442 -0.327987  0.735042  0.279529   \n",
       "27157 -0.476298  ... -0.447549  0.641442 -0.327987  0.735042  0.279529   \n",
       "\n",
       "        emb_123   emb_124   emb_125   emb_126   emb_127  \n",
       "0     -0.668151  0.697140  0.010506 -0.529091  0.156157  \n",
       "1     -0.668151  0.697140  0.010506 -0.529091  0.156157  \n",
       "2     -0.668151  0.697140  0.010506 -0.529091  0.156157  \n",
       "3     -0.668151  0.697140  0.010506 -0.529091  0.156157  \n",
       "4     -0.668151  0.697140  0.010506 -0.529091  0.156157  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27153  0.320902  0.617582 -0.037106 -0.323296 -0.580270  \n",
       "27154  0.320902  0.617582 -0.037106 -0.323296 -0.580270  \n",
       "27155  0.320902  0.617582 -0.037106 -0.323296 -0.580270  \n",
       "27156  0.320902  0.617582 -0.037106 -0.323296 -0.580270  \n",
       "27157  0.320902  0.617582 -0.037106 -0.323296 -0.580270  \n",
       "\n",
       "[27158 rows x 137 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the class counts for our binary classification. In this case, our results are 40,143 <b>False (0)</b> counts, and 1,947 <b>True (1)</b> counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    27158\n",
      "Name: Bug, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(graph_df['Bug'].value_counts())\n",
    "# 2D Array containing all results\n",
    "results_data = [[None for j in range(9)] for i in range(72)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "lr_model2 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "rf_model1 = RandomForestClassifier(n_estimators=120)\n",
    "rf_model2 = RandomForestClassifier(n_estimators=120)\n",
    "xgb_model1 = XGBClassifier(verbosity = 0)\n",
    "xgb_model2 = XGBClassifier(verbosity = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_test_split params\n",
    "-----------------------\n",
    "graph_df: Graph dataset\n",
    "test_size: float value between 0.0 and 1.0 representing the precentage of data to be put into the test dataset\n",
    "random_state = used to create reproducible, or deterministic results.\n",
    "'''\n",
    "train, test = train_test_split(graph_df, test_size=0.3, random_state = 5)\n",
    "train = train.reset_index()\n",
    "test = test.reset_index()\n",
    "\n",
    "# Labels used for model 1\n",
    "labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "\n",
    "# Labels used for model 2\n",
    "labels2 = set(list(graph_df.columns))\n",
    "labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "x1_train = train[labels1]\n",
    "x2_train = train[labels2]\n",
    "y_train = train[\"Bug\"]\n",
    "x1_test = test[labels1]\n",
    "x2_test = test[labels2]\n",
    "y_test = test[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19010\n",
      "Name: Bug, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12101</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>src/org/apache/pig/impl/logicalLayer/LOGenerat...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14456</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>contrib/zebra/src/java/org/apache/hadoop/zebra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5375</td>\n",
       "      <td>Jianyong Dai</td>\n",
       "      <td>src/org/apache/pig/backend/hadoop/executioneng...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.327836</td>\n",
       "      <td>3.015271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>68475.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566791</td>\n",
       "      <td>-0.614349</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>-0.153464</td>\n",
       "      <td>0.821868</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>-0.104511</td>\n",
       "      <td>-0.184231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16779</td>\n",
       "      <td>Dmitriy V. Ryaboy</td>\n",
       "      <td>contrib/piggybank/java/src/main/java/org/apach...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.251714</td>\n",
       "      <td>1.039233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>7265.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581806</td>\n",
       "      <td>-0.481348</td>\n",
       "      <td>0.767510</td>\n",
       "      <td>-0.686637</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.495615</td>\n",
       "      <td>-0.532274</td>\n",
       "      <td>-0.749127</td>\n",
       "      <td>0.171382</td>\n",
       "      <td>0.069775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25495</td>\n",
       "      <td>rding</td>\n",
       "      <td>ivy.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093489</td>\n",
       "      <td>0.311237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>4405.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>-0.278302</td>\n",
       "      <td>-0.297046</td>\n",
       "      <td>-0.369034</td>\n",
       "      <td>0.314084</td>\n",
       "      <td>-0.665316</td>\n",
       "      <td>0.732076</td>\n",
       "      <td>-0.123451</td>\n",
       "      <td>0.513728</td>\n",
       "      <td>0.116460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>3046</td>\n",
       "      <td>Jianyong Dai</td>\n",
       "      <td>test/org/apache/pig/test/TestUDFContext.java</td>\n",
       "      <td>0</td>\n",
       "      <td>2.327836</td>\n",
       "      <td>3.015271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>68475.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566791</td>\n",
       "      <td>-0.614349</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>-0.153464</td>\n",
       "      <td>0.821868</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>-0.104511</td>\n",
       "      <td>-0.184231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19006</th>\n",
       "      <td>26301</td>\n",
       "      <td>Owen O'Malley</td>\n",
       "      <td>test/org/apache/pig/test/data/InputFiles/passwd</td>\n",
       "      <td>0</td>\n",
       "      <td>1.591310</td>\n",
       "      <td>0.323663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>3649.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780537</td>\n",
       "      <td>0.340568</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>-0.841710</td>\n",
       "      <td>0.580271</td>\n",
       "      <td>-0.650050</td>\n",
       "      <td>0.298884</td>\n",
       "      <td>0.880872</td>\n",
       "      <td>-0.816803</td>\n",
       "      <td>-0.553678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19007</th>\n",
       "      <td>20463</td>\n",
       "      <td>Olga Natkovich</td>\n",
       "      <td>test/org/apache/pig/test/TestPigContext.java</td>\n",
       "      <td>0</td>\n",
       "      <td>1.862974</td>\n",
       "      <td>1.675151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>32794.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027508</td>\n",
       "      <td>-0.085361</td>\n",
       "      <td>0.398141</td>\n",
       "      <td>0.610251</td>\n",
       "      <td>-0.044058</td>\n",
       "      <td>-0.450660</td>\n",
       "      <td>0.508188</td>\n",
       "      <td>0.758275</td>\n",
       "      <td>0.312680</td>\n",
       "      <td>0.557327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19008</th>\n",
       "      <td>18638</td>\n",
       "      <td>Thejas Nair</td>\n",
       "      <td>test/org/apache/pig/test/TestPOCast.java</td>\n",
       "      <td>0</td>\n",
       "      <td>1.437429</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>9132.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.160760</td>\n",
       "      <td>-0.064096</td>\n",
       "      <td>0.561470</td>\n",
       "      <td>-0.442125</td>\n",
       "      <td>-0.515800</td>\n",
       "      <td>-0.418347</td>\n",
       "      <td>-0.764986</td>\n",
       "      <td>0.093149</td>\n",
       "      <td>0.278459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19009</th>\n",
       "      <td>2915</td>\n",
       "      <td>Jianyong Dai</td>\n",
       "      <td>src/org/apache/pig/backend/hadoop/executioneng...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.327836</td>\n",
       "      <td>3.015271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>68475.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566791</td>\n",
       "      <td>-0.614349</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>-0.153464</td>\n",
       "      <td>0.821868</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>-0.104511</td>\n",
       "      <td>-0.184231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19010 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index               Name  \\\n",
       "0      12101         Alan Gates   \n",
       "1      14456         Alan Gates   \n",
       "2       5375       Jianyong Dai   \n",
       "3      16779  Dmitriy V. Ryaboy   \n",
       "4      25495              rding   \n",
       "...      ...                ...   \n",
       "19005   3046       Jianyong Dai   \n",
       "19006  26301      Owen O'Malley   \n",
       "19007  20463     Olga Natkovich   \n",
       "19008  18638        Thejas Nair   \n",
       "19009   2915       Jianyong Dai   \n",
       "\n",
       "                                                    File  Bug  PageRank  \\\n",
       "0      src/org/apache/pig/impl/logicalLayer/LOGenerat...    0  2.200797   \n",
       "1      contrib/zebra/src/java/org/apache/hadoop/zebra...    0  2.200797   \n",
       "2      src/org/apache/pig/backend/hadoop/executioneng...    0  2.327836   \n",
       "3      contrib/piggybank/java/src/main/java/org/apach...    0  1.251714   \n",
       "4                                                ivy.xml    0  1.093489   \n",
       "...                                                  ...  ...       ...   \n",
       "19005       test/org/apache/pig/test/TestUDFContext.java    0  2.327836   \n",
       "19006    test/org/apache/pig/test/data/InputFiles/passwd    0  1.591310   \n",
       "19007       test/org/apache/pig/test/TestPigContext.java    0  1.862974   \n",
       "19008           test/org/apache/pig/test/TestPOCast.java    0  1.437429   \n",
       "19009  src/org/apache/pig/backend/hadoop/executioneng...    0  2.327836   \n",
       "\n",
       "       Betweenness  Closeness  Harmonic   Degree  communityId  ...   emb_118  \\\n",
       "0         2.823044        1.0  0.976744  33582.0           32  ...  0.250239   \n",
       "1         2.823044        1.0  0.976744  33582.0           32  ...  0.250239   \n",
       "2         3.015271        1.0  0.976744  68475.0           32  ...  0.566791   \n",
       "3         1.039233        1.0  0.976744   7265.0           32  ... -0.581806   \n",
       "4         0.311237        1.0  0.976744   4405.0           32  ...  0.000272   \n",
       "...            ...        ...       ...      ...          ...  ...       ...   \n",
       "19005     3.015271        1.0  0.976744  68475.0           32  ...  0.566791   \n",
       "19006     0.323663        1.0  0.976744   3649.0           32  ... -0.780537   \n",
       "19007     1.675151        1.0  0.976744  32794.0           32  ...  0.027508   \n",
       "19008     0.933710        1.0  0.976744   9132.0           32  ...  0.111050   \n",
       "19009     3.015271        1.0  0.976744  68475.0           32  ...  0.566791   \n",
       "\n",
       "        emb_119   emb_120   emb_121   emb_122   emb_123   emb_124   emb_125  \\\n",
       "0     -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "1     -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "2     -0.614349  0.180927  0.313573 -0.153464  0.821868  0.000452  0.508137   \n",
       "3     -0.481348  0.767510 -0.686637  0.105634  0.495615 -0.532274 -0.749127   \n",
       "4     -0.278302 -0.297046 -0.369034  0.314084 -0.665316  0.732076 -0.123451   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19005 -0.614349  0.180927  0.313573 -0.153464  0.821868  0.000452  0.508137   \n",
       "19006  0.340568  0.536000 -0.841710  0.580271 -0.650050  0.298884  0.880872   \n",
       "19007 -0.085361  0.398141  0.610251 -0.044058 -0.450660  0.508188  0.758275   \n",
       "19008  0.160760 -0.064096  0.561470 -0.442125 -0.515800 -0.418347 -0.764986   \n",
       "19009 -0.614349  0.180927  0.313573 -0.153464  0.821868  0.000452  0.508137   \n",
       "\n",
       "        emb_126   emb_127  \n",
       "0     -0.282591  0.660514  \n",
       "1     -0.282591  0.660514  \n",
       "2     -0.104511 -0.184231  \n",
       "3      0.171382  0.069775  \n",
       "4      0.513728  0.116460  \n",
       "...         ...       ...  \n",
       "19005 -0.104511 -0.184231  \n",
       "19006 -0.816803 -0.553678  \n",
       "19007  0.312680  0.557327  \n",
       "19008  0.093149  0.278459  \n",
       "19009 -0.104511 -0.184231  \n",
       "\n",
       "[19010 rows x 138 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train['Bug'].value_counts())\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the class counts for our binary classification in the training dataset. In this case, our results are 12,060 <b>False (0)</b> counts, and 567 <b>True (1)</b> counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8148\n",
      "Name: Bug, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14199</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>test/org/apache/pig/test/TestMergeJoin.java</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19070</td>\n",
       "      <td>Santhosh Muthur Srinivasan</td>\n",
       "      <td>src/org/apache/pig/impl/logicalLayer/LogicalOp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055236</td>\n",
       "      <td>0.622473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>4238.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177989</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>-0.641231</td>\n",
       "      <td>-0.675856</td>\n",
       "      <td>-0.103919</td>\n",
       "      <td>-0.146215</td>\n",
       "      <td>-0.514260</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.672333</td>\n",
       "      <td>-0.699174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25268</td>\n",
       "      <td>yanz</td>\n",
       "      <td>contrib/zebra/CHANGES.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558202</td>\n",
       "      <td>0.188699</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>465.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689147</td>\n",
       "      <td>-0.251181</td>\n",
       "      <td>0.078829</td>\n",
       "      <td>-0.592870</td>\n",
       "      <td>-0.060723</td>\n",
       "      <td>0.036221</td>\n",
       "      <td>-0.523529</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.430928</td>\n",
       "      <td>0.026098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25957</td>\n",
       "      <td>hashutosh</td>\n",
       "      <td>contrib/piggybank/java/src/main/java/org/apach...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611777</td>\n",
       "      <td>0.110111</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>392.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513057</td>\n",
       "      <td>-0.792362</td>\n",
       "      <td>-0.657239</td>\n",
       "      <td>0.349282</td>\n",
       "      <td>0.473826</td>\n",
       "      <td>0.587484</td>\n",
       "      <td>0.523576</td>\n",
       "      <td>-0.261212</td>\n",
       "      <td>0.375688</td>\n",
       "      <td>0.480017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24979</td>\n",
       "      <td>daijy</td>\n",
       "      <td>src/org/apache/pig/newplan/logical/expression/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.156590</td>\n",
       "      <td>0.335030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598363</td>\n",
       "      <td>-0.671051</td>\n",
       "      <td>-0.466709</td>\n",
       "      <td>-0.545072</td>\n",
       "      <td>-0.137708</td>\n",
       "      <td>-0.364932</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.603701</td>\n",
       "      <td>-0.313474</td>\n",
       "      <td>-0.372411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>12257</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>test/org/apache/pig/test/TestLogicalPlanBuilde...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>11101</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>src/org/apache/pig/data/DataReaderWriter.java</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>6008</td>\n",
       "      <td>Jianyong Dai</td>\n",
       "      <td>test/org/apache/pig/test/TestPigScriptParser.java</td>\n",
       "      <td>0</td>\n",
       "      <td>2.327836</td>\n",
       "      <td>3.015271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>68475.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566791</td>\n",
       "      <td>-0.614349</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.313573</td>\n",
       "      <td>-0.153464</td>\n",
       "      <td>0.821868</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>-0.104511</td>\n",
       "      <td>-0.184231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>6582</td>\n",
       "      <td>Rohini Palaniswamy</td>\n",
       "      <td>CHANGES.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>1.457491</td>\n",
       "      <td>2.010222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>20766.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432612</td>\n",
       "      <td>0.155345</td>\n",
       "      <td>-0.064648</td>\n",
       "      <td>0.094880</td>\n",
       "      <td>0.156698</td>\n",
       "      <td>-0.854661</td>\n",
       "      <td>0.557385</td>\n",
       "      <td>0.490715</td>\n",
       "      <td>0.544879</td>\n",
       "      <td>0.180652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>13080</td>\n",
       "      <td>Alan Gates</td>\n",
       "      <td>test/org/apache/pig/test/data/DotFiles/optplan...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200797</td>\n",
       "      <td>2.823044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>33582.0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>-0.410574</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>-0.197693</td>\n",
       "      <td>-0.464232</td>\n",
       "      <td>0.758703</td>\n",
       "      <td>-0.538323</td>\n",
       "      <td>-0.867511</td>\n",
       "      <td>-0.282591</td>\n",
       "      <td>0.660514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8148 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                        Name  \\\n",
       "0     14199                  Alan Gates   \n",
       "1     19070  Santhosh Muthur Srinivasan   \n",
       "2     25268                        yanz   \n",
       "3     25957                   hashutosh   \n",
       "4     24979                       daijy   \n",
       "...     ...                         ...   \n",
       "8143  12257                  Alan Gates   \n",
       "8144  11101                  Alan Gates   \n",
       "8145   6008                Jianyong Dai   \n",
       "8146   6582          Rohini Palaniswamy   \n",
       "8147  13080                  Alan Gates   \n",
       "\n",
       "                                                   File  Bug  PageRank  \\\n",
       "0           test/org/apache/pig/test/TestMergeJoin.java    0  2.200797   \n",
       "1     src/org/apache/pig/impl/logicalLayer/LogicalOp...    0  1.055236   \n",
       "2                             contrib/zebra/CHANGES.txt    0  0.558202   \n",
       "3     contrib/piggybank/java/src/main/java/org/apach...    0  0.611777   \n",
       "4     src/org/apache/pig/newplan/logical/expression/...    0  1.156590   \n",
       "...                                                 ...  ...       ...   \n",
       "8143  test/org/apache/pig/test/TestLogicalPlanBuilde...    0  2.200797   \n",
       "8144      src/org/apache/pig/data/DataReaderWriter.java    0  2.200797   \n",
       "8145  test/org/apache/pig/test/TestPigScriptParser.java    0  2.327836   \n",
       "8146                                        CHANGES.txt    0  1.457491   \n",
       "8147  test/org/apache/pig/test/data/DotFiles/optplan...    0  2.200797   \n",
       "\n",
       "      Betweenness  Closeness  Harmonic   Degree  communityId  ...   emb_118  \\\n",
       "0        2.823044   1.000000  0.976744  33582.0           32  ...  0.250239   \n",
       "1        0.622473   1.000000  0.976744   4238.0           32  ... -0.177989   \n",
       "2        0.188699   0.976744  0.965116    465.0           32  ... -0.689147   \n",
       "3        0.110111   0.976744  0.965116    392.0           32  ...  0.513057   \n",
       "4        0.335030   1.000000  0.976744   5606.0           32  ...  0.598363   \n",
       "...           ...        ...       ...      ...          ...  ...       ...   \n",
       "8143     2.823044   1.000000  0.976744  33582.0           32  ...  0.250239   \n",
       "8144     2.823044   1.000000  0.976744  33582.0           32  ...  0.250239   \n",
       "8145     3.015271   1.000000  0.976744  68475.0           32  ...  0.566791   \n",
       "8146     2.010222   1.000000  0.976744  20766.0           32  ...  0.432612   \n",
       "8147     2.823044   1.000000  0.976744  33582.0           32  ...  0.250239   \n",
       "\n",
       "       emb_119   emb_120   emb_121   emb_122   emb_123   emb_124   emb_125  \\\n",
       "0    -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "1     0.010473 -0.641231 -0.675856 -0.103919 -0.146215 -0.514260  0.753644   \n",
       "2    -0.251181  0.078829 -0.592870 -0.060723  0.036221 -0.523529  0.002722   \n",
       "3    -0.792362 -0.657239  0.349282  0.473826  0.587484  0.523576 -0.261212   \n",
       "4    -0.671051 -0.466709 -0.545072 -0.137708 -0.364932  0.008714  0.603701   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8143 -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "8144 -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "8145 -0.614349  0.180927  0.313573 -0.153464  0.821868  0.000452  0.508137   \n",
       "8146  0.155345 -0.064648  0.094880  0.156698 -0.854661  0.557385  0.490715   \n",
       "8147 -0.410574  0.430066 -0.197693 -0.464232  0.758703 -0.538323 -0.867511   \n",
       "\n",
       "       emb_126   emb_127  \n",
       "0    -0.282591  0.660514  \n",
       "1     0.672333 -0.699174  \n",
       "2     0.430928  0.026098  \n",
       "3     0.375688  0.480017  \n",
       "4    -0.313474 -0.372411  \n",
       "...        ...       ...  \n",
       "8143 -0.282591  0.660514  \n",
       "8144 -0.282591  0.660514  \n",
       "8145 -0.104511 -0.184231  \n",
       "8146  0.544879  0.180652  \n",
       "8147 -0.282591  0.660514  \n",
       "\n",
       "[8148 rows x 138 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test['Bug'].value_counts())\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70655db72bec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlr_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrf_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrf_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxgb_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    935\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m    936\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         class_weight_ = compute_class_weight(class_weight, classes=classes_,\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "lr_model1.fit(x1_train, y_train)\n",
    "lr_model2.fit(x2_train, y_train)\n",
    "rf_model1.fit(x1_train, y_train)\n",
    "rf_model2.fit(x2_train, y_train)\n",
    "xgb_model1.fit(x1_train, y_train)\n",
    "xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y_test)}\")\n",
    "results_data[0][0] = \"Original_Logistic_Regression\"\n",
    "results_data[0][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[0][2] = lr_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y_test)}\")\n",
    "results_data[1][0] = \"Original_Random_Forrest\"\n",
    "results_data[1][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[1][2] = rf_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y_test)}\")\n",
    "results_data[2][0] = \"Original_XGB_Classifier\"\n",
    "results_data[2][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[2][2] = xgb_model2.score(x2_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model scores for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[0][3] = acc1\n",
    "results_data[0][4] = acc2\n",
    "results_data[0][5] = prc_val1\n",
    "results_data[0][6] = prc_val2\n",
    "results_data[0][7] = pr_auc1\n",
    "results_data[0][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[1][3] = acc1\n",
    "results_data[1][4] = acc2\n",
    "results_data[1][5] = prc_val1\n",
    "results_data[1][6] = prc_val2\n",
    "results_data[1][7] = pr_auc1\n",
    "results_data[1][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[2][3] = acc1\n",
    "results_data[2][4] = acc2\n",
    "results_data[2][5] = prc_val1\n",
    "results_data[2][6] = prc_val2\n",
    "results_data[2][7] = pr_auc1\n",
    "results_data[2][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models\n",
    "\n",
    "TODO: Get it to work with randomforrest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y_test, x2_test, y_test, lr_prediction_probs1, lr_prediction_probs2, \"original dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y_test, x2_test, y_test, rf_prediction_probs1, rf_prediction_probs2, \"original dataset Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y_test, x2_test, y_test, xgb_prediction_probs1, xgb_prediction_probs2, \"original dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best thresholds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "\n",
    "results_data[3][0] = \"Original_Logistic_Regression_Best_Threshold\"\n",
    "results_data[3][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[3][2] = lr_model2.score(x2_test, y_test)\n",
    "results_data[3][3] = acc1\n",
    "results_data[3][4] = acc2\n",
    "results_data[3][5] = prc_val1\n",
    "results_data[3][6] = prc_val2\n",
    "results_data[3][7] = pr_auc1\n",
    "results_data[3][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[4][0] = \"Original_Random_Forrest_Best_Threshold\"\n",
    "results_data[4][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[4][2] = rf_model2.score(x2_test, y_test)\n",
    "results_data[4][3] = acc1\n",
    "results_data[4][4] = acc2\n",
    "results_data[4][5] = prc_val1\n",
    "results_data[4][6] = prc_val2\n",
    "results_data[4][7] = pr_auc1\n",
    "results_data[4][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[5][0] = \"Original_XGBoost_Classifier_Best_Threshold\"\n",
    "results_data[5][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[5][2] = xgb_model2.score(x2_test, y_test)\n",
    "results_data[5][3] = acc1\n",
    "results_data[5][4] = acc2\n",
    "results_data[5][5] = prc_val1\n",
    "results_data[5][6] = prc_val2\n",
    "results_data[5][7] = pr_auc1\n",
    "results_data[5][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df['Bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross validation results for model 1\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "cv_results = cross_validate(lr_model1, x1, y, cv=3)\n",
    "sorted(cv_results.keys())\n",
    "print(cv_results['test_score'])\n",
    "\n",
    "print(\"\\nCross validation results for model 2\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "cv_results = cross_validate(lr_model2, x2, y, cv=3)\n",
    "sorted(cv_results.keys())\n",
    "print(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Running extremely slow, working on this issue\n",
    "#Loo(lr_model1, x1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, x1, y)\n",
    "results_data[6][0] = \"Original_Logistic_Regression_rkf\"\n",
    "results_data[6][1] = model_score\n",
    "results_data[6][3] = acc\n",
    "results_data[6][5] = prc_val\n",
    "results_data[6][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[7][0] = \"Original_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[7][1] = model_score\n",
    "results_data[7][3] = acc\n",
    "results_data[7][5] = prc_val\n",
    "results_data[7][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, x1, y)\n",
    "results_data[8][0] = \"Original_Random_Forrest_rkf\"\n",
    "results_data[8][1] = model_score\n",
    "results_data[8][3] = acc\n",
    "results_data[8][5] = prc_val\n",
    "results_data[8][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, x1, y)\n",
    "results_data[9][0] = \"Original_XGB_Classifier_rkf\"\n",
    "results_data[9][1] = model_score\n",
    "results_data[9][3] = acc\n",
    "results_data[9][5] = prc_val\n",
    "results_data[9][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, x1, y)\n",
    "results_data[10][0] = \"Original_Logistic_Regression_skf\"\n",
    "results_data[10][1] = model_score\n",
    "results_data[10][3] = acc\n",
    "results_data[10][5] = prc_val\n",
    "results_data[10][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[11][0] = \"Original_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[11][1] = model_score\n",
    "results_data[11][3] = acc\n",
    "results_data[11][5] = prc_val\n",
    "results_data[11][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, x1, y)\n",
    "results_data[12][0] = \"Original_Random_Forrest_skf\"\n",
    "results_data[12][1] = model_score\n",
    "results_data[12][3] = acc\n",
    "results_data[12][5] = prc_val\n",
    "results_data[12][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, x1, y)\n",
    "results_data[13][0] = \"Original_XGB_Classifier_skf\"\n",
    "results_data[13][1] = model_score\n",
    "results_data[13][3] = acc\n",
    "results_data[13][5] = prc_val\n",
    "results_data[13][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, x1, y)\n",
    "results_data[14][0] = \"Original_Logistic_Regression_tss\"\n",
    "results_data[14][1] = model_score\n",
    "results_data[14][3] = acc\n",
    "results_data[14][5] = prc_val\n",
    "results_data[14][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[15][0] = \"Original_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[15][1] = model_score\n",
    "results_data[15][3] = acc\n",
    "results_data[15][5] = prc_val\n",
    "results_data[15][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, x1, y)\n",
    "results_data[16][0] = \"Original_Random_Forrest_tss\"\n",
    "results_data[16][1] = model_score\n",
    "results_data[16][3] = acc\n",
    "results_data[16][5] = prc_val\n",
    "results_data[16][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, x1, y)\n",
    "results_data[17][0] = \"Original_XGB_Classifier_tss\"\n",
    "results_data[17][1] = model_score\n",
    "results_data[17][3] = acc\n",
    "results_data[17][5] = prc_val\n",
    "results_data[17][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Running extremely slow, working on this issue\n",
    "#Loo(lr_model2, x2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, x2, y)\n",
    "results_data[6][2] = model_score\n",
    "results_data[6][4] = acc\n",
    "results_data[6][6] = prc_val\n",
    "results_data[6][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[7][2] = model_score\n",
    "results_data[7][4] = acc\n",
    "results_data[7][6] = prc_val\n",
    "results_data[7][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, x2, y)\n",
    "results_data[8][2] = model_score\n",
    "results_data[8][4] = acc\n",
    "results_data[8][6] = prc_val\n",
    "results_data[8][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, x2, y)\n",
    "results_data[9][2] = model_score\n",
    "results_data[9][4] = acc\n",
    "results_data[9][6] = prc_val\n",
    "results_data[9][8] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, x2, y)\n",
    "results_data[10][2] = model_score\n",
    "results_data[10][4] = acc\n",
    "results_data[10][6] = prc_val\n",
    "results_data[10][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[11][2] = model_score\n",
    "results_data[11][4] = acc\n",
    "results_data[11][6] = prc_val\n",
    "results_data[11][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, x2, y)\n",
    "results_data[12][2] = model_score\n",
    "results_data[12][4] = acc\n",
    "results_data[12][6] = prc_val\n",
    "results_data[12][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, x2, y)\n",
    "results_data[13][2] = model_score\n",
    "results_data[13][4] = acc\n",
    "results_data[13][6] = prc_val\n",
    "results_data[13][8] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, x2, y)\n",
    "results_data[14][2] = model_score\n",
    "results_data[14][4] = acc\n",
    "results_data[14][6] = prc_val\n",
    "results_data[14][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[15][2] = model_score\n",
    "results_data[15][4] = acc\n",
    "results_data[15][6] = prc_val\n",
    "results_data[15][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, x2, y)\n",
    "results_data[16][2] = model_score\n",
    "results_data[16][4] = acc\n",
    "results_data[16][6] = prc_val\n",
    "results_data[16][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, x2, y)\n",
    "results_data[17][2] = model_score\n",
    "results_data[17][4] = acc\n",
    "results_data[17][6] = prc_val\n",
    "results_data[17][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"original dataset Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"original dataset Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"original dataset XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"original dataset Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"original dataset Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"original dataset XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"original dataset Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"original dataset Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"original dataset XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_df = graph_df.loc[graph_df['Bug'] == 1].sample(n=1900, random_state=42)\n",
    "non_bug_df = graph_df.loc[graph_df['Bug'] == 0].sample(n=1900, random_state=42)\n",
    "normalized_under_df = pd.concat([bug_df, non_bug_df])\n",
    "normalized_under_df = normalized_under_df.reset_index()\n",
    "print(normalized_under_df['Bug'].value_counts())\n",
    "\n",
    "usx1 = normalized_under_df[labels1]\n",
    "usx2 = normalized_under_df[labels2]\n",
    "usy = normalized_under_df[\"Bug\"]\n",
    "usy = usy.sample(frac=1).reset_index(drop=True) # shuffle dataset\n",
    "\n",
    "train, test = train_test_split(normalized_under_df, test_size=0.3, random_state = 5)\n",
    "\n",
    "labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "labels2 = set(list(normalized_under_df.columns))\n",
    "labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "x1_train = train[labels1]\n",
    "x2_train = train[labels2]\n",
    "y_train = train[\"Bug\"]\n",
    "x1_test = test[labels1]\n",
    "x2_test = test[labels2]\n",
    "y_test = test[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1.fit(x1_train, y_train)\n",
    "lr_model2.fit(x2_train, y_train)\n",
    "rf_model1.fit(x1_train, y_train)\n",
    "rf_model2.fit(x2_train, y_train)\n",
    "xgb_model1.fit(x1_train, y_train)\n",
    "xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y_test)}\")\n",
    "results_data[18][0] = \"Undersampled_Logistic_Regression\"\n",
    "results_data[18][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[18][2] = lr_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y_test)}\")\n",
    "results_data[19][0] = \"Undersampled_Random_Forrest\"\n",
    "results_data[19][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[19][2] = rf_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y_test)}\")\n",
    "results_data[20][0] = \"Undersampled_XGB_Classifier\"\n",
    "results_data[20][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[20][2] = xgb_model2.score(x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[18][3] = acc1\n",
    "results_data[18][4] = acc2\n",
    "results_data[18][5] = prc_val1\n",
    "results_data[18][6] = prc_val2\n",
    "results_data[18][7] = pr_auc1\n",
    "results_data[18][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[19][3] = acc1\n",
    "results_data[19][4] = acc2\n",
    "results_data[19][5] = prc_val1\n",
    "results_data[19][6] = prc_val2\n",
    "results_data[19][7] = pr_auc1\n",
    "results_data[19][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[20][3] = acc1\n",
    "results_data[20][4] = acc2\n",
    "results_data[20][5] = prc_val1\n",
    "results_data[20][6] = prc_val2\n",
    "results_data[20][7] = pr_auc1\n",
    "results_data[20][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y_test, x2_test, y_test, lr_prediction_probs1, lr_prediction_probs2, \"undersampled dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y_test, x2_test, y_test, rf_prediction_probs1, rf_prediction_probs2, \"undersampled datase Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, xgb_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y_test, x2_test, y_test, xgb_prediction_probs1, xgb_prediction_probs2, \"undersampled dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[21][0] = \"Undersampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[21][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[21][2] = lr_model2.score(x2_test, y_test)\n",
    "results_data[21][3] = acc1\n",
    "results_data[21][4] = acc2\n",
    "results_data[21][5] = prc_val1\n",
    "results_data[21][6] = prc_val2\n",
    "results_data[21][7] = pr_auc1\n",
    "results_data[21][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[22][0] = \"Undersampled_Random_Forrest_Best_Threshold\"\n",
    "results_data[22][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[22][2] = rf_model2.score(x2_test, y_test)\n",
    "results_data[22][3] = acc1\n",
    "results_data[22][4] = acc2\n",
    "results_data[22][5] = prc_val1\n",
    "results_data[22][6] = prc_val2\n",
    "results_data[22][7] = pr_auc1\n",
    "results_data[22][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[23][0] = \"Undersampled_XGB_Classifier_Best_Threshold\"\n",
    "results_data[23][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[23][2] = xgb_model2.score(x2_test, y_test)\n",
    "results_data[23][3] = acc1\n",
    "results_data[23][4] = acc2\n",
    "results_data[23][5] = prc_val1\n",
    "results_data[23][6] = prc_val2\n",
    "results_data[23][7] = pr_auc1\n",
    "results_data[23][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Undersampling Rebalance for model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, usx1, usy)\n",
    "results_data[24][0] = \"Undersampled_Logistic_Regression_rkf\"\n",
    "results_data[24][1] = model_score\n",
    "results_data[24][3] = acc\n",
    "results_data[24][5] = prc_val\n",
    "results_data[24][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[25][0] = \"Undersampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[25][1] = model_score\n",
    "results_data[25][3] = acc\n",
    "results_data[25][5] = prc_val\n",
    "results_data[25][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, usx1, usy)\n",
    "results_data[26][0] = \"Undersampled_Random_Forrest_rkf\"\n",
    "results_data[26][1] = model_score\n",
    "results_data[26][3] = acc\n",
    "results_data[26][5] = prc_val\n",
    "results_data[26][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, usx1, usy)\n",
    "results_data[27][0] = \"Undersampled_XGB_Classifier_rkf\"\n",
    "results_data[27][1] = model_score\n",
    "results_data[27][3] = acc\n",
    "results_data[27][5] = prc_val\n",
    "results_data[27][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, usx1, usy)\n",
    "results_data[28][0] = \"Undersampled_Logistic_Regression_skf\"\n",
    "results_data[28][1] = model_score\n",
    "results_data[28][3] = acc\n",
    "results_data[28][5] = prc_val\n",
    "results_data[28][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[29][0] = \"Undersampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[29][1] = model_score\n",
    "results_data[29][3] = acc\n",
    "results_data[29][5] = prc_val\n",
    "results_data[29][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, usx1, usy)\n",
    "results_data[30][0] = \"Undersampled_Random_Forrest_skf\"\n",
    "results_data[30][1] = model_score\n",
    "results_data[30][3] = acc\n",
    "results_data[30][5] = prc_val\n",
    "results_data[30][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, usx1, usy)\n",
    "results_data[31][0] = \"Undersampled_XGB_Classifier_skf\"\n",
    "results_data[31][1] = model_score\n",
    "results_data[31][3] = acc\n",
    "results_data[31][5] = prc_val\n",
    "results_data[31][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, usx1, usy)\n",
    "results_data[32][0] = \"Undersampled_Logistic_Regression_tss\"\n",
    "results_data[32][1] = model_score\n",
    "results_data[32][3] = acc\n",
    "results_data[32][5] = prc_val\n",
    "results_data[32][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[33][0] = \"Undersampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[33][1] = model_score\n",
    "results_data[33][3] = acc\n",
    "results_data[33][5] = prc_val\n",
    "results_data[33][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, usx1, usy)\n",
    "results_data[34][0] = \"Undersampled_Random_Forrest_tss\"\n",
    "results_data[34][1] = model_score\n",
    "results_data[34][3] = acc\n",
    "results_data[34][5] = prc_val\n",
    "results_data[34][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, usx1, usy)\n",
    "results_data[35][0] = \"Undersampled_XGB_Classifier_tss\"\n",
    "results_data[35][1] = model_score\n",
    "results_data[35][3] = acc\n",
    "results_data[35][5] = prc_val\n",
    "results_data[35][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Undersampling Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, usx2, usy)\n",
    "results_data[24][2] = model_score\n",
    "results_data[24][4] = acc\n",
    "results_data[24][6] = prc_val\n",
    "results_data[24][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[25][2] = model_score\n",
    "results_data[25][4] = acc\n",
    "results_data[25][6] = prc_val\n",
    "results_data[25][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, usx2, usy)\n",
    "results_data[26][2] = model_score\n",
    "results_data[26][4] = acc\n",
    "results_data[26][6] = prc_val\n",
    "results_data[26][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, usx2, usy)\n",
    "results_data[27][2] = model_score\n",
    "results_data[27][4] = acc\n",
    "results_data[27][6] = prc_val\n",
    "results_data[27][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, usx2, usy)\n",
    "results_data[28][2] = model_score\n",
    "results_data[28][4] = acc\n",
    "results_data[28][6] = prc_val\n",
    "results_data[28][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[29][2] = model_score\n",
    "results_data[29][4] = acc\n",
    "results_data[29][6] = prc_val\n",
    "results_data[29][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, usx2, usy)\n",
    "results_data[30][2] = model_score\n",
    "results_data[30][4] = acc\n",
    "results_data[30][6] = prc_val\n",
    "results_data[30][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, usx2, usy)\n",
    "results_data[31][2] = model_score\n",
    "results_data[31][4] = acc\n",
    "results_data[31][6] = prc_val\n",
    "results_data[31][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, usx2, usy)\n",
    "results_data[32][2] = model_score\n",
    "results_data[32][4] = acc\n",
    "results_data[32][6] = prc_val\n",
    "results_data[32][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[33][2] = model_score\n",
    "results_data[33][4] = acc\n",
    "results_data[33][6] = prc_val\n",
    "results_data[33][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, usx2, usy)\n",
    "results_data[34][2] = model_score\n",
    "results_data[34][4] = acc\n",
    "results_data[34][6] = prc_val\n",
    "results_data[34][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, usx2, usy)\n",
    "results_data[35][2] = model_score\n",
    "results_data[35][4] = acc\n",
    "results_data[35][6] = prc_val\n",
    "results_data[35][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"Undersampled Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"Undersampled Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"Undersampled XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"Undersampled Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"Undersampled Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"Undersampled XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"Undersampled Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"Undersampled Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"Undersampled XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For oversampling we will use SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "\n",
    "print(\"x1 Before SMOTE:\")\n",
    "\n",
    "print(x1_train.shape)\n",
    "\n",
    "print(\"x2 Before SMOTE:\")\n",
    "\n",
    "print(x2_train.shape)\n",
    "\n",
    "# Fit the model to generate the data for Model 1.\n",
    "oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "# Fit the model to generate the data for Model 2.\n",
    "oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "print(\"x1 After SMOTE:\")\n",
    "\n",
    "print(oversampled_X1.shape)\n",
    "\n",
    "print(\"x2 After SMOTE:\")\n",
    "\n",
    "print(oversampled_X2.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y2.value_counts(normalize=True) * 100)\n",
    "\n",
    "osx1 = oversampled_X1\n",
    "osx2 = oversampled_X2\n",
    "osy1 = oversampled_Y1\n",
    "osy2 = oversampled_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(osx1, osy1, test_size=0.3, random_state = 5)\n",
    "#x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(osx2, osy2, test_size=0.3, random_state = 5)\n",
    "#x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "lr_model1.fit(x1_train, y1_train)\n",
    "lr_model2.fit(x2_train, y2_train)\n",
    "rf_model1.fit(x1_train, y1_train)\n",
    "rf_model2.fit(x2_train, y2_train)\n",
    "xgb_model1.fit(x1_train, y1_train)\n",
    "xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y2_test)}\")\n",
    "results_data[36][0] = \"Oversampled_Logistic_Regression\"\n",
    "results_data[36][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[36][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y2_test)}\")\n",
    "results_data[37][0] = \"Oversampled_Random_Forrest\"\n",
    "results_data[37][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[37][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y2_test)}\")\n",
    "results_data[38][0] = \"Oversampled_XGB_Classifier\"\n",
    "results_data[38][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[38][2] = xgb_model2.score(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[36][3] = acc1\n",
    "results_data[36][4] = acc2\n",
    "results_data[36][5] = prc_val1\n",
    "results_data[36][6] = prc_val2\n",
    "results_data[36][7] = pr_auc1\n",
    "results_data[36][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[37][3] = acc1\n",
    "results_data[37][4] = acc2\n",
    "results_data[37][5] = prc_val1\n",
    "results_data[37][6] = prc_val2\n",
    "results_data[37][7] = pr_auc1\n",
    "results_data[37][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[38][3] = acc1\n",
    "results_data[38][4] = acc2\n",
    "results_data[38][5] = prc_val1\n",
    "results_data[38][6] = prc_val2\n",
    "results_data[38][7] = pr_auc1\n",
    "results_data[38][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_test, x2_test, y2_test, lr_prediction_probs1, lr_prediction_probs2, \"oversampled dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_test, x2_test, y2_test, rf_prediction_probs1, rf_prediction_probs2, \"oversampled dataset Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_test, x2_test, y2_test, xgb_prediction_probs1, xgb_prediction_probs2, \"oversampled dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using best threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[39][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[39][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[39][2] = lr_model2.score(x2_test, y2_test)\n",
    "results_data[39][3] = acc1\n",
    "results_data[39][4] = acc2\n",
    "results_data[39][5] = prc_val1\n",
    "results_data[39][6] = prc_val2\n",
    "results_data[39][7] = pr_auc1\n",
    "results_data[39][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[40][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[40][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[40][2] = rf_model2.score(x2_test, y2_test)\n",
    "results_data[40][3] = acc1\n",
    "results_data[40][4] = acc2\n",
    "results_data[40][5] = prc_val1\n",
    "results_data[40][6] = prc_val2\n",
    "results_data[40][7] = pr_auc1\n",
    "results_data[40][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[41][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[41][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[41][2] = xgb_model2.score(x2_test, y2_test)\n",
    "results_data[41][3] = acc1\n",
    "results_data[41][4] = acc2\n",
    "results_data[41][5] = prc_val1\n",
    "results_data[41][6] = prc_val2\n",
    "results_data[41][7] = pr_auc1\n",
    "results_data[41][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling Rebalance for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, osx1, osy1)\n",
    "results_data[42][0] = \"Oversampled_Logistic_Regression_rkf\"\n",
    "results_data[42][1] = model_score\n",
    "results_data[42][3] = acc\n",
    "results_data[42][5] = prc_val\n",
    "results_data[42][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[43][0] = \"Oversampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[43][1] = model_score\n",
    "results_data[43][3] = acc\n",
    "results_data[43][5] = prc_val\n",
    "results_data[43][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, osx1, osy1)\n",
    "results_data[44][0] = \"Oversampled_Random_Forrest_rkf\"\n",
    "results_data[44][1] = model_score\n",
    "results_data[44][3] = acc\n",
    "results_data[44][5] = prc_val\n",
    "results_data[44][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, osx1, osy1)\n",
    "results_data[45][0] = \"Oversampled_XGB_Classifier_rkf\"\n",
    "results_data[45][1] = model_score\n",
    "results_data[45][3] = acc\n",
    "results_data[45][5] = prc_val\n",
    "results_data[45][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, osx1, osy1)\n",
    "results_data[46][0] = \"Oversampled_Logistic_Regression_skf\"\n",
    "results_data[46][1] = model_score\n",
    "results_data[46][3] = acc\n",
    "results_data[46][5] = prc_val\n",
    "results_data[46][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[47][0] = \"Oversampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[47][1] = model_score\n",
    "results_data[47][3] = acc\n",
    "results_data[47][5] = prc_val\n",
    "results_data[47][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, osx1, osy1)\n",
    "results_data[48][0] = \"Oversampled_Random_Forrest_skf\"\n",
    "results_data[48][1] = model_score\n",
    "results_data[48][3] = acc\n",
    "results_data[48][5] = prc_val\n",
    "results_data[48][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, osx1, osy1)\n",
    "results_data[49][0] = \"Oversampled_XGB_Classifier_skf\"\n",
    "results_data[49][1] = model_score\n",
    "results_data[49][3] = acc\n",
    "results_data[49][5] = prc_val\n",
    "results_data[49][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, osx1, osy1)\n",
    "results_data[50][0] = \"Oversampled_Logistic_Regression_tss\"\n",
    "results_data[50][1] = model_score\n",
    "results_data[50][3] = acc\n",
    "results_data[50][5] = prc_val\n",
    "results_data[50][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[51][0] = \"Oversampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[51][1] = model_score\n",
    "results_data[51][3] = acc\n",
    "results_data[51][5] = prc_val\n",
    "results_data[51][7] = pr_auc\n",
    "\n",
    "Tss_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, osx1, osy1)\n",
    "results_data[52][0] = \"Oversampled_Random_Forrest_tss\"\n",
    "results_data[52][1] = model_score\n",
    "results_data[52][3] = acc\n",
    "results_data[52][5] = prc_val\n",
    "results_data[52][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, osx1, osy1)\n",
    "results_data[53][0] = \"Oversampled_XGB_Classifier_tss\"\n",
    "results_data[53][1] = model_score\n",
    "results_data[53][3] = acc\n",
    "results_data[53][5] = prc_val\n",
    "results_data[53][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, osx2, osy2)\n",
    "results_data[42][2] = model_score\n",
    "results_data[42][4] = acc\n",
    "results_data[42][6] = prc_val\n",
    "results_data[42][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[43][2] = model_score\n",
    "results_data[43][4] = acc\n",
    "results_data[43][6] = prc_val\n",
    "results_data[43][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, osx2, osy2)\n",
    "results_data[44][2] = model_score\n",
    "results_data[44][4] = acc\n",
    "results_data[44][6] = prc_val\n",
    "results_data[44][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, osx2, osy2)\n",
    "results_data[45][2] = model_score\n",
    "results_data[45][4] = acc\n",
    "results_data[45][6] = prc_val\n",
    "results_data[45][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, osx2, osy2)\n",
    "results_data[46][2] = model_score\n",
    "results_data[46][4] = acc\n",
    "results_data[46][6] = prc_val\n",
    "results_data[46][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[47][2] = model_score\n",
    "results_data[47][4] = acc\n",
    "results_data[47][6] = prc_val\n",
    "results_data[47][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, osx2, osy2)\n",
    "results_data[48][2] = model_score\n",
    "results_data[48][4] = acc\n",
    "results_data[48][6] = prc_val\n",
    "results_data[48][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model1, osx1, osy1)\n",
    "results_data[49][2] = model_score\n",
    "results_data[49][4] = acc\n",
    "results_data[49][6] = prc_val\n",
    "results_data[49][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, osx2, osy2)\n",
    "results_data[50][2] = model_score\n",
    "results_data[50][4] = acc\n",
    "results_data[50][6] = prc_val\n",
    "results_data[50][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[51][2] = model_score\n",
    "results_data[51][4] = acc\n",
    "results_data[51][6] = prc_val\n",
    "results_data[51][8] = pr_auc\n",
    "\n",
    "Tss_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, osx2, osy2)\n",
    "results_data[52][2] = model_score\n",
    "results_data[52][4] = acc\n",
    "results_data[52][6] = prc_val\n",
    "results_data[52][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, osx2, osy2)\n",
    "results_data[53][2] = model_score\n",
    "results_data[53][4] = acc\n",
    "results_data[53][6] = prc_val\n",
    "results_data[53][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"Oversampled Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"Oversampled Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"Oversampled XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"Oversampled Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"Oversampled Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"Oversampled XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"Oversampled Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"Oversampled Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"Oversampled XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining Oversampling with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "print(\"x1 Before SMOTE:\")\n",
    "print(x1.shape)\n",
    "print(\"x2 Before SMOTE:\")\n",
    "print(x2.shape)\n",
    "\n",
    "# Fit the model to generate the data for Model 1.\n",
    "oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "# Fit the model to generate the data for Model 2.\n",
    "oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "print(\"x1 After SMOTE:\")\n",
    "print(oversampled_X1.shape)\n",
    "print(\"x2 After SMOTE:\")\n",
    "print(oversampled_X2.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y2.value_counts(normalize=True) * 100)\n",
    "\n",
    "osx1 = oversampled_X1\n",
    "osx2 = oversampled_X2\n",
    "osy1 = oversampled_Y1\n",
    "osy2 = oversampled_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "print(\"x1 Before RandomUnderSampler:\")\n",
    "print(osx1.shape)\n",
    "print(\"x2 Before RandomUnderSampler:\")\n",
    "print(osx2.shape)\n",
    "\n",
    "balanced_x1, balanced_y1, = rus.fit_resample(osx1, osy1)\n",
    "balanced_x2, balanced_y2, = rus.fit_resample(osx2, osy2)\n",
    "\n",
    "print(\"x1 After RandomUnderSampler:\")\n",
    "print(balanced_x1.shape)\n",
    "print(\"x2 After RandomUnderSampler:\")\n",
    "print(balanced_x1.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(balanced_y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(balanced_y2.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(balanced_x1, balanced_y1, test_size=0.3, random_state = 5)\n",
    "#x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(balanced_x2, balanced_y2, test_size=0.3, random_state = 5)\n",
    "#x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "lr_model1.fit(x1_train, y1_train)\n",
    "lr_model2.fit(x2_train, y2_train)\n",
    "rf_model1.fit(x1_train, y1_train)\n",
    "rf_model2.fit(x2_train, y2_train)\n",
    "xgb_model1.fit(x1_train, y1_train)\n",
    "xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y2_test)}\")\n",
    "results_data[54][0] = \"OSUS_Combination_Logistic_Regression\"\n",
    "results_data[54][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[54][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y2_test)}\")\n",
    "results_data[55][0] = \"OSUS_Combination_Random_Forrest\"\n",
    "results_data[55][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[55][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y2_test)}\")\n",
    "results_data[56][0] = \"OSUS_Combination_XGB_Classifier\"\n",
    "results_data[56][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[56][2] = xgb_model2.score(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[54][3] = acc1\n",
    "results_data[54][4] = acc2\n",
    "results_data[54][5] = prc_val1\n",
    "results_data[54][6] = prc_val2\n",
    "results_data[54][7] = pr_auc1\n",
    "results_data[54][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[55][3] = acc1\n",
    "results_data[55][4] = acc2\n",
    "results_data[55][5] = prc_val1\n",
    "results_data[55][6] = prc_val2\n",
    "results_data[55][7] = pr_auc1\n",
    "results_data[55][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[56][3] = acc1\n",
    "results_data[56][4] = acc2\n",
    "results_data[56][5] = prc_val1\n",
    "results_data[56][6] = prc_val2\n",
    "results_data[56][7] = pr_auc1\n",
    "results_data[56][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for oversampling and undersampling combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_test, x2_test, y2_test, lr_prediction_probs1, lr_prediction_probs2, \"USOS Combination Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_test, x2_test, y2_test, rf_prediction_probs1, rf_prediction_probs2, \"USOS Combination Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_test, x2_test, y2_test, xgb_prediction_probs1, xgb_prediction_probs2, \"USOS Combination XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[57][0] = \"OSUS_Logistic_Regression_Best_Threshold\"\n",
    "results_data[57][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[57][2] = lr_model2.score(x2_test, y2_test)\n",
    "results_data[57][3] = acc1\n",
    "results_data[57][4] = acc2\n",
    "results_data[57][5] = prc_val1\n",
    "results_data[57][6] = prc_val2\n",
    "results_data[57][7] = pr_auc1\n",
    "results_data[57][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[58][0] = \"OSUS_Random_Forrest_Best_Threshold\"\n",
    "results_data[58][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[58][2] = rf_model2.score(x2_test, y2_test)\n",
    "results_data[58][3] = acc1\n",
    "results_data[58][4] = acc2\n",
    "results_data[58][5] = prc_val1\n",
    "results_data[58][6] = prc_val2\n",
    "results_data[58][7] = pr_auc1\n",
    "results_data[58][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[59][0] = \"OSUS_XGBoost_Classifier_Best_Threshold\"\n",
    "results_data[59][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[59][2] = xgb_model2.score(x2_test, y2_test)\n",
    "results_data[59][3] = acc1\n",
    "results_data[59][4] = acc2\n",
    "results_data[59][5] = prc_val1\n",
    "results_data[59][6] = prc_val2\n",
    "results_data[59][7] = pr_auc1\n",
    "results_data[59][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling/Undersampling Combination Rebalance for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[60][0] = \"OSUS_Combination_Logistic_Regression_rkf\"\n",
    "results_data[60][1] = model_score\n",
    "results_data[60][3] = acc\n",
    "results_data[60][5] = prc_val\n",
    "results_data[60][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[61][0] = \"OSUS_Combination_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[61][1] = model_score\n",
    "results_data[61][3] = acc\n",
    "results_data[61][5] = prc_val\n",
    "results_data[61][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[62][0] = \"OSUS_Combination_Random_Forrest_rkf\"\n",
    "results_data[62][1] = model_score\n",
    "results_data[62][3] = acc\n",
    "results_data[62][5] = prc_val\n",
    "results_data[62][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[63][0] = \"OSUS_Combination_XGB_Classifier_rkf\"\n",
    "results_data[63][1] = model_score\n",
    "results_data[63][3] = acc\n",
    "results_data[63][5] = prc_val\n",
    "results_data[63][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[64][0] = \"OSUS_Combination_Logistic_Regression_skf\"\n",
    "results_data[64][1] = model_score\n",
    "results_data[64][3] = acc\n",
    "results_data[64][5] = prc_val\n",
    "results_data[64][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[65][0] = \"OSUS_Combination_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[65][1] = model_score\n",
    "results_data[65][3] = acc\n",
    "results_data[65][5] = prc_val\n",
    "results_data[65][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[66][0] = \"OSUS_Combination_Random_Forrest_skf\"\n",
    "results_data[66][1] = model_score\n",
    "results_data[66][3] = acc\n",
    "results_data[66][5] = prc_val\n",
    "results_data[66][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[67][0] = \"OSUS_Combination_XGB_Classifier_skf\"\n",
    "results_data[67][1] = model_score\n",
    "results_data[67][3] = acc\n",
    "results_data[67][5] = prc_val\n",
    "results_data[67][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[68][0] = \"OSUS_Combination_Logistic_Regression_tss\"\n",
    "results_data[68][1] = model_score\n",
    "results_data[68][3] = acc\n",
    "results_data[68][5] = prc_val\n",
    "results_data[68][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[69][0] = \"OSUS_Combination_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[69][1] = model_score\n",
    "results_data[69][3] = acc\n",
    "results_data[69][5] = prc_val\n",
    "results_data[69][7] = pr_auc\n",
    "\n",
    "Tss_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[70][0] = \"OSUS_Combination_Random_Forrest_tss\"\n",
    "results_data[70][1] = model_score\n",
    "results_data[70][3] = acc\n",
    "results_data[70][5] = prc_val\n",
    "results_data[70][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[71][0] = \"OSUS_Combination_XGB_Classifier_tss\"\n",
    "results_data[71][1] = model_score\n",
    "results_data[71][3] = acc\n",
    "results_data[71][5] = prc_val\n",
    "results_data[71][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling/Undersampling Combination Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[60][2] = model_score\n",
    "results_data[60][4] = acc\n",
    "results_data[60][6] = prc_val\n",
    "results_data[60][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[61][2] = model_score\n",
    "results_data[61][4] = acc\n",
    "results_data[61][6] = prc_val\n",
    "results_data[61][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[62][2] = model_score\n",
    "results_data[62][4] = acc\n",
    "results_data[62][6] = prc_val\n",
    "results_data[62][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[63][2] = model_score\n",
    "results_data[63][4] = acc\n",
    "results_data[63][6] = prc_val\n",
    "results_data[63][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[64][2] = model_score\n",
    "results_data[64][4] = acc\n",
    "results_data[64][6] = prc_val\n",
    "results_data[64][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[65][2] = model_score\n",
    "results_data[65][4] = acc\n",
    "results_data[65][6] = prc_val\n",
    "results_data[65][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[66][2] = model_score\n",
    "results_data[66][4] = acc\n",
    "results_data[66][6] = prc_val\n",
    "results_data[66][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[67][2] = model_score\n",
    "results_data[67][4] = acc\n",
    "results_data[67][6] = prc_val\n",
    "results_data[67][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[68][2] = model_score\n",
    "results_data[68][4] = acc\n",
    "results_data[68][6] = prc_val\n",
    "results_data[68][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[69][2] = model_score\n",
    "results_data[69][4] = acc\n",
    "results_data[69][6] = prc_val\n",
    "results_data[69][8] = pr_auc\n",
    "\n",
    "Tss_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[70][2] = model_score\n",
    "results_data[70][4] = acc\n",
    "results_data[70][6] = prc_val\n",
    "results_data[70][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[71][2] = model_score\n",
    "results_data[71][4] = acc\n",
    "results_data[71][6] = prc_val\n",
    "results_data[71][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"OSUS Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"OSUS Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"OSUS XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"OSUS Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"OSUS Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"OSUS XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"OSUS Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"OSUS Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"OSUS XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_data, columns = ['Test', 'Model1 score', 'Model2 score', 'Model1 accuracy', 'Model2 accuracy', 'Model1 avg. PR score', 'Model2 avg. PR score', 'Model1 PRC-AUC Score', 'Model2 PRC-AUC Score'])\n",
    "model1_results_df = results_df[['Test', 'Model1 score', 'Model1 accuracy', 'Model1 avg. PR score', 'Model1 PRC-AUC Score']]\n",
    "model2_results_df = results_df[['Test', 'Model2 score', 'Model2 accuracy', 'Model2 avg. PR score', 'Model2 PRC-AUC Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_results_df[~model1_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model1 PRC-AUC Score', 'Model1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results_df[~model2_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model2 PRC-AUC Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = [lr_skf_us_fig, rf_skf_us_fig, xgb_skf_us_fig]\n",
    "\n",
    "for i, figure in enumerate(figures):\n",
    "    figure.savefig(f\"../../img/Pig/graphs/Precision vs. Recall Results/Figure_{i}\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_A = mpimg.imread('../../img/Pig/graphs/Precision vs. Recall Results/Figure_0.png')\n",
    "img_B = mpimg.imread('../../img/Pig/graphs/Precision vs. Recall Results/Figure_1.png')\n",
    "img_C = mpimg.imread('../../img/Pig/graphs/Precision vs. Recall Results/Figure_2.png')\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,3,figsize=(20,20))\n",
    "ax[0].imshow(img_A);\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(img_B);\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(img_C);\n",
    "ax[2].axis('off')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"../../img/Pig/graphs/Precision vs. Recall Results/Figure_final.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
