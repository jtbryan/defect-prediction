{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis of Vagrant Developers\n",
    "<a href=\"#TODO's\">TODO</a><br>\n",
    "<a href=\"#Imports\">Imports</a><br>\n",
    "<a href=\"#Functions\">Functions</a><br>\n",
    "<a href=\"#Analysis\">Analysis</a><br>\n",
    "<a href=\"#Graph-Based-Analysis-using-Logistic-Regression,-Random-Forest-Classifer,-and-XGBoost-classifier\"><b>Analysis</b> - Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier</a><br>\n",
    "<a href=\"#Cross-Validation\"><b>Analysis</b> - Cross Validation</a><br>\n",
    "<a href=\"#Rebalancing-data\"><b>Analysis</b> - Data Rebalancing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO's\n",
    "\n",
    "<ul>\n",
    "<li>Implement a new dataframe to store the results from each section. (refer to last cell)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import json\n",
    "import csv\n",
    "import numpy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve, plot_precision_recall_curve, auc, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, LeaveOneOut, KFold, StratifiedKFold, RepeatedKFold, TimeSeriesSplit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import statsmodels.api as sm\n",
    "from ast import literal_eval\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(model, x, y):\n",
    "    '''\n",
    "    Plots the predictions made using a linear regression model \n",
    "    given the set of dependent variable(s) and the independent variable\n",
    "        model: Linear Regression Model\n",
    "        x: Dependent Variable(s)\n",
    "        y: Independent Variable\n",
    "    returns: Independent Variable Predictions\n",
    "    '''\n",
    "    y_pred = model.predict(x)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_pred, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# source: https://stackoverflow.com/questions/26319259/how-to-get-a-regression-summary-in-python-scikit-like-r-does\n",
    "def regression_results(y_true, y_pred):\n",
    "    '''\n",
    "    Analyzes the results from the linear regression model prediction using different metrics, such r^2\n",
    "    '''\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def Loo(model, x, y):\n",
    "    '''\n",
    "    Uses the LeaveOneOut cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    loo = LeaveOneOut() \n",
    "    highestscore = (0, \"\")\n",
    "    y_true, y_pred = list(), list()\n",
    "    \n",
    "    # Split the data\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        predictions = model.predict_proba(x_test)\n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        score = model.score(x_test, y_test) # NOTE: Removed the following due to errors: prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if score > highestscore[0]:\n",
    "            highestscore = (model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\")\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[1])\n",
    "    print(\"\\nModel Score: {}\\n\".format(highestscore[0]))\n",
    "    #acc = accuracy_score(y_true, y_pred)\n",
    "    #print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    \n",
    "def Loo_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the LeaveOneOut cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = LeaveOneOut()\n",
    "    # to see list of scoring methods, go to: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Rkf(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the RepeatedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    kf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42) \n",
    "    #kf.get_n_splits(x)\n",
    "    #print(kf)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        \n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"Average Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "\n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "    \n",
    "def Rkf_short(model, x, y):    \n",
    "    '''\n",
    "    Uses the shortened version of the RepeatedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))\n",
    "    \n",
    "def Skf(model, x, y, threshold = None):\n",
    "    '''\n",
    "    Uses the StratifiedKFold cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    recall = None\n",
    "    yhat = None\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "        \n",
    "        # fit the model on the new data\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "            \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "    \n",
    "def Skf_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the StratifiedKFold cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores)))    \n",
    "\n",
    "def Tss(model, x, y, threshold=None):\n",
    "    '''\n",
    "    Uses the TimeSeriesSplit cross-validation method provided by SkLearn\n",
    "    '''\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    highestscore = (0, 0, \"\")\n",
    "    predictions = None\n",
    "    precision = None\n",
    "    rcall = None\n",
    "    yhat = None\n",
    "    \n",
    "    for train_index, test_index in tscv.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # if there is only one value (i.e. only 1's or only 0's)\n",
    "        if(len(set(y_train.values.tolist())) <= 1):\n",
    "            continue\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        #evaluate model\n",
    "        if threshold is not None:\n",
    "            predictions = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            yhat = (model.predict_proba(x_test)[:,1] >= threshold).astype(int)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "        else:\n",
    "            predictions = model.predict_proba(x_test)\n",
    "            # uses default threshold\n",
    "            yhat = model.predict(x_test)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, predictions[:, 1])\n",
    "        \n",
    "        fscore = (2 * (np.array(precision, dtype=float) * np.array(recall, dtype=float)) / (np.array(precision, dtype=float) + np.array(recall, dtype=float)))\n",
    "        fscore[np.isnan(fscore)] = 0 \n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        yhat = model.predict(x_test) \n",
    "        \n",
    "        # Get the auc up to the best threshold point\n",
    "        pr_auc = auc(recall[ix:], precision[ix:])\n",
    "\n",
    "        # determine PRC_AUC score\n",
    "        prc_val = average_precision_score(y_test, yhat)#predictions[:,1])\n",
    "        if prc_val > highestscore[0]:\n",
    "            highestscore = (prc_val, model.score(x_test, y_test), f\"TRAIN: {train_index} | TEST: {test_index}\", y_test, yhat, pr_auc, predictions)\n",
    "\n",
    "        #y_true.append(y_test[0])\n",
    "        #y_pred.append(yhat[0])\n",
    "            \n",
    "    print(highestscore[2])\n",
    "    print(\"\\nModel Score: {}\".format(highestscore[1]))\n",
    "    print(\"\\nAverage Precision-Recall Score: {}\".format(highestscore[0]))\n",
    "    print(\"PRC-AUC Score: {}\".format(highestscore[5]))\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(highestscore[3], highestscore[4]))\n",
    "    acc = accuracy_score(highestscore[3], highestscore[4])\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    \n",
    "    # Return model score, average precision score, y_test, PRC-AUC, and Predictions\n",
    "    return highestscore[1], acc, highestscore[0], highestscore[3], highestscore[5], highestscore[6]\n",
    "\n",
    "def Tss_short(model, x, y):\n",
    "    '''\n",
    "    Uses the shortened version of the TimeSeriesSplit cross-validation method provided by SkLearn by using cross_val_score\n",
    "    '''\n",
    "    cv = TimeSeriesSplit(n_splits=10)\n",
    "    scores = cross_val_score(model, x, y, scoring='average_precision', cv=cv)\n",
    "    print(\"Mean Average-Precision Recall Score: {}\".format(mean(scores))) \n",
    "    \n",
    "def Compare_Model_Scores(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    \n",
    "    print(\"Predictions for model 1: \")\n",
    "    print(prediction_probs1)\n",
    "    print(\"\\nPredictions for model 2: \")\n",
    "    print(prediction_probs2)\n",
    "    '''\n",
    "    \n",
    "    #recall1, recall2, precision1, precision2, thresholds_list = get_precision_recall(test_x1, test_x2, y_test, model1, model2)\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:, 1]) \n",
    "    #retrieve probability of being 1(in second column of probs_y)\n",
    "    \n",
    "    pr_auc1 = auc(recall1, precision1)\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    \n",
    "    pr_auc2 = auc(recall2, precision2)\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2\n",
    "    \n",
    "def Compare_Model_Scores_Best_Threshold(test_x1, test_x2, y_test, predictions1, predictions2, prediction_probs1, prediction_probs2, model1, model2):\n",
    "    '''\n",
    "    This method provides different metrics about the predictions associated with an independent test variable.\n",
    "    These metrics include: PRC-AUC scores, ROC-AUC scores, and the classification report provided by sklearn\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    # ovr: One-vs-rest\n",
    "    # ovo: One-vs-one\n",
    "    print(\"\\nScores for model 1\")\n",
    "    print(\"------------------\")\n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(y_test, prediction_probs1[:,1])\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    \n",
    "    pr_auc1 = auc(recall1[ix1:], precision1[ix1:])\n",
    "    roc_val1 = roc_auc_score(y_test, prediction_probs1[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val1))\n",
    "    prc_val1 = average_precision_score(y_test, prediction_probs1[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val1))\n",
    "    print(f\"PRC-AUC for model 1: {pr_auc1}\")\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc1 = accuracy_score(y_test, predictions1)\n",
    "    print('Accuracy: %.3f' % acc1)\n",
    "\n",
    "    '''\n",
    "    Classification Report breakdown from https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn:\n",
    "    The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "    The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "    The f1-score is the harmonic mean between precision & recall\n",
    "\n",
    "    The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "    '''\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions1))\n",
    "\n",
    "    print(\"\\nScores for model 2\")\n",
    "    print(\"------------------\")\n",
    "    # Temporarily removed to retrieve precision & recall by hand\n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(y_test, prediction_probs2[:, 1])\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore2[np.isnan(fscore2)] = 0  \n",
    "    ix2 = np.argmax(fscore2)\n",
    "    \n",
    "    pr_auc2 = auc(recall2[ix2:], precision2[ix2:])\n",
    "    roc_val2 = roc_auc_score(y_test, prediction_probs2[:, 1], multi_class='ovr')\n",
    "    print('Roc_Auc Score: {}'.format(roc_val2))\n",
    "    prc_val2 = average_precision_score(y_test, prediction_probs2[:, 1])\n",
    "    print(\"Average Precision-Recall Score: {}\".format(prc_val2))\n",
    "    print(f\"PRC-AUC for model 2: {pr_auc2}\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, predictions2))\n",
    "    \n",
    "    # Measure the accuracy of the results by comparing the test data with the predictions using the best threshold\n",
    "    acc2 = accuracy_score(y_test, predictions2)\n",
    "    print('Accuracy: %.3f' % acc2)\n",
    "    \n",
    "    return acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2\n",
    "\n",
    "def plot_thresholds(model1, model2, test_x1, test_y1, test_x2, test_y2, prediction_probs1, prediction_probs2, title):\n",
    "    '''Predict test_y values and probabilities based on fitted logistic for both models''' \n",
    "\n",
    "    # recall1, recall2, precision1, precision2, threshold_list = get_precision_recall(test_x1, test_x2, test_y1, model1, model2)\n",
    "    \n",
    "    precision1, recall1, thresholds1 = precision_recall_curve(test_y1, prediction_probs1[:, 1]) \n",
    "    precision2, recall2, thresholds2 = precision_recall_curve(test_y2, prediction_probs2[:, 1])\n",
    "    \n",
    "    # convert to f1 score\n",
    "    # from: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "    fscore1 = (2 * (np.array(precision1, dtype=float) * np.array(recall1, dtype=float)) / (np.array(precision1, dtype=float) + np.array(recall1, dtype=float)))\n",
    "    fscore2 = (2 * (np.array(precision2, dtype=float) * np.array(recall2, dtype=float)) / (np.array(precision2, dtype=float) + np.array(recall2, dtype=float)))\n",
    "    fscore1[np.isnan(fscore1)] = 0 \n",
    "    fscore2[np.isnan(fscore2)] = 0 \n",
    "    \n",
    "    # locate the index of the largest f score\n",
    "    ix1 = np.argmax(fscore1)\n",
    "    ix2 = np.argmax(fscore2)\n",
    "    #print(f\"F score 1: {fscore1} with ix: {ix1}\")\n",
    "    #print(f\"F score 2: {fscore2} with ix: {ix2}\")\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 1' % (thresholds1[ix1], fscore1[ix1]))\n",
    "    print('Best Threshold=%f, F1-Score=%.3f for model 2' % (thresholds2[ix2], fscore2[ix2]))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.title(f\"PRC for {title}\")\n",
    "    # use marker = \".\" to see each threshhold value\n",
    "    plt.plot(recall1[:-1], precision1[:-1], \"b\", label=f\"Model 1\\n-----------\\n • PRC-AUC score: {auc(recall1[ix1:], precision1[ix1:]):.2f}\\n • Best Threshold: {round(thresholds1[ix1], 2):.2f}\\n • Best F1-Score: {round(fscore1[ix1], 2):.2f}\\n\")\n",
    "    plt.plot(recall2[:-1], precision2[:-1], \"r--\", label=f\"Model 2\\n-----------\\n • PRC-AUC score: {auc(recall2[ix2:], precision2[ix2:]):.2f}\\n • Best Threshold: {round(thresholds2[ix2], 2):.2f}\\n • Best F1-Score: {round(fscore2[ix2], 2):.2f}\")\n",
    "    plt.scatter([recall1[ix1], recall2[ix2]], [precision1[ix1], precision2[ix2]], marker='o', color='black', label='Best threshold')\n",
    "    #plt.annotate('Model 1 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds1[ix1], fscore1[ix1]), (0.38, 0.35), fontsize=8)\n",
    "    #plt.annotate('Model 2 Best Threshold=%.2f, Best F1-Score=%.2f' % (thresholds2[ix2], fscore2[ix2]), (0.38, 0.3), fontsize=8)\n",
    "    \n",
    "    x1 = np.array(recall1[ix1:], dtype=float)\n",
    "    x2 = np.array(recall2[ix2:], dtype=float)\n",
    "    y1 = np.array(precision1[ix1:], dtype=float)\n",
    "    y2 = np.array(precision2[ix2:], dtype=float)\n",
    "    y1_opp = np.array(precision1[ix2:], dtype=float)\n",
    "    \n",
    "    #plt.fill_between(x1, y1, color='b', alpha=0.5)\n",
    "    # where=y1_opp<=y2\n",
    "    #plt.fill_between(x2, y2, color='r', alpha=0.3)\n",
    "    \n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    plt.ylim([0,1])\n",
    "    plt.xlim([0,1])\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return thresholds1[ix1], thresholds2[ix2], fig\n",
    "    \n",
    "def simple_threshold_plot(classifier, x_test, y_test):\n",
    "    predictions = classifier.predict(x_test)\n",
    "    prc_val = average_precision_score(y_test, predictions)\n",
    "    disp = plot_precision_recall_curve(classifier, x_test, y_test)\n",
    "    disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(prc_val))\n",
    "    \n",
    "def get_precision_recall(test_x1, test_x2, test_y, model1, model2):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with each type of threshold\n",
    "    '''\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, 1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "        \n",
    "    return recall1, recall2, precision1, precision2, threshold_list\n",
    "\n",
    "def get_precision_recall_best_thresh(test_x1, test_x2, test_y, model1, model2, best_thresh1=None, best_thresh2=None):\n",
    "    '''\n",
    "    Get the the preicison and recall values for every data point with the best threshold\n",
    "    '''\n",
    "    limit1, limit2 = 1, 1\n",
    "    if best_thresh1 != None:\n",
    "        limit1 = best_thresh1\n",
    "    if best_thresh2 != None:\n",
    "        limit2 = best_thresh2\n",
    "    \n",
    "    recall1, recall2, precision1, precision2 = list(), list(), list(), list()\n",
    "    \n",
    "    # Could also create thresholds using: thresholds = arange(0, 1, 0.001)\n",
    "    # threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\n",
    "    threshold_list = np.arange(0.001, limit1, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y1=model1.predict(test_x1) \n",
    "        probs_y1=(model1.predict_proba(test_x1)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision1.append(precision_score(test_y, probs_y1, average='binary'))\n",
    "        recall1.append(recall_score(test_y, probs_y1, average='binary'))\n",
    "        \n",
    "    threshold_list = np.arange(0.001, limit2, 0.001)\n",
    "    for threshold in threshold_list:\n",
    "        #pred_y2=model2.predict(test_x2) \n",
    "        probs_y2=(model2.predict_proba(test_x2)[:,1] >= threshold).astype(int)\n",
    "        # probs_y is a 2-D array of probability of being labeled as 0 (first column of array) \n",
    "        # vs 1 (2nd column in array)\n",
    "        precision2.append(precision_score(test_y, probs_y2, average='binary'))\n",
    "        recall2.append(recall_score(test_y, probs_y2, average='binary'))\n",
    "    return recall1, recall2, precision1, precision2, threshold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph-Based Analysis using Logistic Regression, Random Forest Classifer, and XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of all of the unique commits (i.e. links) between developers and the corresponding folders\n",
    "graph_df = pd.read_csv(\"../../Neo4j_output/JiT_Reliability_Output/Velocity.csv\")\n",
    "\n",
    "new_columns = {}\n",
    "\n",
    "# Generate binary classification for our dataframe based on if a developer \n",
    "# introduced a bug or not with the corresponding commit\n",
    "for index in graph_df.index:\n",
    "    if graph_df.loc[index, \"Bug\"] != \"INTRODUCED_NEW_BUG\":\n",
    "        graph_df.loc[index, \"Bug\"] = 0\n",
    "    else:\n",
    "        graph_df.loc[index, \"Bug\"] = 1\n",
    "        \n",
    "    # separate each node2vec embedding into it's own unique label\n",
    "    embeddings = literal_eval(graph_df.loc[index, 'n2vEmbedding'])\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        if f\"emb_{i}\" not in new_columns:\n",
    "            new_columns[f\"emb_{i}\"] = []\n",
    "            new_columns[f\"emb_{i}\"].append(embedding)\n",
    "        else:\n",
    "            new_columns[f\"emb_{i}\"].append(embedding)\n",
    "\n",
    "# delete the n2vEmbedding label, as the list has now been separated into their own unique labels \n",
    "del graph_df['n2vEmbedding']\n",
    "temp_df = pd.DataFrame.from_dict(new_columns)\n",
    "graph_df = graph_df.join(temp_df)\n",
    "            \n",
    "graph_df['Bug'] = graph_df.Bug.astype('int')\n",
    "    \n",
    "x = graph_df[\"Name\"]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>src/java/org/apache/velocity/runtime/parser/no...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.99854</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.247516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>build/download.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.99854</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.247516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>build/build.properties</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.99854</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.247516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>build/build.properties</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.99854</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.247516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>build/build.properties</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.99854</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.247516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20802</th>\n",
       "      <td>Bob McWhirter</td>\n",
       "      <td>examples/anakia/build/build.sh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>-0.172403</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>-0.709946</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>-0.629452</td>\n",
       "      <td>0.488355</td>\n",
       "      <td>-0.119194</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.137582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20803</th>\n",
       "      <td>Bob McWhirter</td>\n",
       "      <td>src/java/org/apache/velocity/anakia/XPathTool....</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>-0.172403</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>-0.709946</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>-0.629452</td>\n",
       "      <td>0.488355</td>\n",
       "      <td>-0.119194</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.137582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20804</th>\n",
       "      <td>Bob McWhirter</td>\n",
       "      <td>src/java/org/apache/velocity/anakia/XPathTool....</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>-0.172403</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>-0.709946</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>-0.629452</td>\n",
       "      <td>0.488355</td>\n",
       "      <td>-0.119194</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.137582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20805</th>\n",
       "      <td>Bob McWhirter</td>\n",
       "      <td>examples/anakia/xdocs/stylesheets/site.vsl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>-0.172403</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>-0.709946</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>-0.629452</td>\n",
       "      <td>0.488355</td>\n",
       "      <td>-0.119194</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.137582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>Bob McWhirter</td>\n",
       "      <td>build/lib/werken.xpath.jar</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.296443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>-0.172403</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>-0.709946</td>\n",
       "      <td>0.253641</td>\n",
       "      <td>-0.629452</td>\n",
       "      <td>0.488355</td>\n",
       "      <td>-0.119194</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.137582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20807 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                               File  Bug  \\\n",
       "0      Claude Brisson  src/java/org/apache/velocity/runtime/parser/no...    0   \n",
       "1      Claude Brisson                                 build/download.xml    0   \n",
       "2      Claude Brisson                             build/build.properties    0   \n",
       "3      Claude Brisson                             build/build.properties    0   \n",
       "4      Claude Brisson                             build/build.properties    0   \n",
       "...               ...                                                ...  ...   \n",
       "20802   Bob McWhirter                     examples/anakia/build/build.sh    0   \n",
       "20803   Bob McWhirter  src/java/org/apache/velocity/anakia/XPathTool....    0   \n",
       "20804   Bob McWhirter  src/java/org/apache/velocity/anakia/XPathTool....    0   \n",
       "20805   Bob McWhirter         examples/anakia/xdocs/stylesheets/site.vsl    0   \n",
       "20806   Bob McWhirter                         build/lib/werken.xpath.jar    0   \n",
       "\n",
       "       PageRank  Betweenness  Closeness  Harmonic  Degree  communityId  \\\n",
       "0      1.184341    109.99854   0.947368  0.875000  5084.0            9   \n",
       "1      1.184341    109.99854   0.947368  0.875000  5084.0            9   \n",
       "2      1.184341    109.99854   0.947368  0.875000  5084.0            9   \n",
       "3      1.184341    109.99854   0.947368  0.875000  5084.0            9   \n",
       "4      1.184341    109.99854   0.947368  0.875000  5084.0            9   \n",
       "...         ...          ...        ...       ...     ...          ...   \n",
       "20802  0.197017      0.00000   0.600000  0.633333    77.0           17   \n",
       "20803  0.197017      0.00000   0.600000  0.633333    77.0           17   \n",
       "20804  0.197017      0.00000   0.600000  0.633333    77.0           17   \n",
       "20805  0.197017      0.00000   0.600000  0.633333    77.0           17   \n",
       "20806  0.197017      0.00000   0.600000  0.633333    77.0           17   \n",
       "\n",
       "          emb_0  ...   emb_118   emb_119   emb_120   emb_121   emb_122  \\\n",
       "0     -0.247516  ...  0.725507  0.626239  0.243156  0.691346 -0.423329   \n",
       "1     -0.247516  ...  0.725507  0.626239  0.243156  0.691346 -0.423329   \n",
       "2     -0.247516  ...  0.725507  0.626239  0.243156  0.691346 -0.423329   \n",
       "3     -0.247516  ...  0.725507  0.626239  0.243156  0.691346 -0.423329   \n",
       "4     -0.247516  ...  0.725507  0.626239  0.243156  0.691346 -0.423329   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "20802 -0.296443  ...  0.703920 -0.172403  0.221329 -0.709946  0.253641   \n",
       "20803 -0.296443  ...  0.703920 -0.172403  0.221329 -0.709946  0.253641   \n",
       "20804 -0.296443  ...  0.703920 -0.172403  0.221329 -0.709946  0.253641   \n",
       "20805 -0.296443  ...  0.703920 -0.172403  0.221329 -0.709946  0.253641   \n",
       "20806 -0.296443  ...  0.703920 -0.172403  0.221329 -0.709946  0.253641   \n",
       "\n",
       "        emb_123   emb_124   emb_125   emb_126   emb_127  \n",
       "0     -0.698127 -0.416638 -0.230406  0.426186  0.102370  \n",
       "1     -0.698127 -0.416638 -0.230406  0.426186  0.102370  \n",
       "2     -0.698127 -0.416638 -0.230406  0.426186  0.102370  \n",
       "3     -0.698127 -0.416638 -0.230406  0.426186  0.102370  \n",
       "4     -0.698127 -0.416638 -0.230406  0.426186  0.102370  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "20802 -0.629452  0.488355 -0.119194  0.538052  0.137582  \n",
       "20803 -0.629452  0.488355 -0.119194  0.538052  0.137582  \n",
       "20804 -0.629452  0.488355 -0.119194  0.538052  0.137582  \n",
       "20805 -0.629452  0.488355 -0.119194  0.538052  0.137582  \n",
       "20806 -0.629452  0.488355 -0.119194  0.538052  0.137582  \n",
       "\n",
       "[20807 rows x 137 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the class counts for our binary classification. In this case, our results are 40,143 <b>False (0)</b> counts, and 1,947 <b>True (1)</b> counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20807\n",
      "Name: Bug, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(graph_df['Bug'].value_counts())\n",
    "# 2D Array containing all results\n",
    "results_data = [[None for j in range(9)] for i in range(72)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "lr_model2 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "rf_model1 = RandomForestClassifier(n_estimators=120)\n",
    "rf_model2 = RandomForestClassifier(n_estimators=120)\n",
    "xgb_model1 = XGBClassifier(verbosity = 0)\n",
    "xgb_model2 = XGBClassifier(verbosity = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_test_split params\n",
    "-----------------------\n",
    "graph_df: Graph dataset\n",
    "test_size: float value between 0.0 and 1.0 representing the precentage of data to be put into the test dataset\n",
    "random_state = used to create reproducible, or deterministic results.\n",
    "'''\n",
    "train, test = train_test_split(graph_df, test_size=0.3, random_state = 5)\n",
    "train = train.reset_index()\n",
    "test = test.reset_index()\n",
    "\n",
    "# Labels used for model 1\n",
    "labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "\n",
    "# Labels used for model 2\n",
    "labels2 = set(list(graph_df.columns))\n",
    "labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "x1_train = train[labels1]\n",
    "x2_train = train[labels2]\n",
    "y_train = train[\"Bug\"]\n",
    "x1_test = test[labels1]\n",
    "x2_test = test[labels2]\n",
    "y_test = test[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    14564\n",
      "Name: Bug, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9397</td>\n",
       "      <td>Antonio Petrelli</td>\n",
       "      <td>src/test/org/apache/velocity/test/PropertyMeth...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>7.057669</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.825</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.864049</td>\n",
       "      <td>0.515813</td>\n",
       "      <td>-0.927484</td>\n",
       "      <td>-0.873930</td>\n",
       "      <td>-0.656481</td>\n",
       "      <td>0.463783</td>\n",
       "      <td>0.363294</td>\n",
       "      <td>-0.325170</td>\n",
       "      <td>0.634005</td>\n",
       "      <td>-0.770786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18964</td>\n",
       "      <td>Jon Scott Stevens</td>\n",
       "      <td>docs/ymtd/ymtd-error-handling.html</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305663</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193705</td>\n",
       "      <td>-0.815001</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.927922</td>\n",
       "      <td>-0.485899</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>-0.667325</td>\n",
       "      <td>-0.802270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16306</td>\n",
       "      <td>Geir Magnusson Jr</td>\n",
       "      <td>docs/developer-guide.html</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736420</td>\n",
       "      <td>2.666855</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>15235.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.955519</td>\n",
       "      <td>0.220302</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>-0.792885</td>\n",
       "      <td>0.541425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373</td>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>velocity-engine-core/src/test/java/org/apache/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.998540</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4999</td>\n",
       "      <td>Henning Schmiedehausen</td>\n",
       "      <td>whiteboard/geir/velocity.properties</td>\n",
       "      <td>0</td>\n",
       "      <td>1.745637</td>\n",
       "      <td>3.886492</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.775</td>\n",
       "      <td>8351.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378187</td>\n",
       "      <td>-0.364097</td>\n",
       "      <td>0.458338</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>0.250242</td>\n",
       "      <td>0.163307</td>\n",
       "      <td>-0.225199</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>1.103847</td>\n",
       "      <td>-0.059876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>5520</td>\n",
       "      <td>Henning Schmiedehausen</td>\n",
       "      <td>xdocs/vtl-reference-guide.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>1.745637</td>\n",
       "      <td>3.886492</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.775</td>\n",
       "      <td>8351.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378187</td>\n",
       "      <td>-0.364097</td>\n",
       "      <td>0.458338</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>0.250242</td>\n",
       "      <td>0.163307</td>\n",
       "      <td>-0.225199</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>1.103847</td>\n",
       "      <td>-0.059876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14560</th>\n",
       "      <td>3046</td>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>velocity-engine-core/src/main/java/org/apache/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.998540</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14561</th>\n",
       "      <td>20463</td>\n",
       "      <td>Jason van Zyl</td>\n",
       "      <td>TODO-1.0.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360128</td>\n",
       "      <td>1.159654</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>5383.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.466211</td>\n",
       "      <td>-0.494635</td>\n",
       "      <td>0.871449</td>\n",
       "      <td>-0.238051</td>\n",
       "      <td>-0.081807</td>\n",
       "      <td>-0.288823</td>\n",
       "      <td>-0.084420</td>\n",
       "      <td>-1.064453</td>\n",
       "      <td>0.917812</td>\n",
       "      <td>-0.051695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14562</th>\n",
       "      <td>18638</td>\n",
       "      <td>Jon Scott Stevens</td>\n",
       "      <td>src/java/org/apache/velocity/runtime/directive...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305663</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193705</td>\n",
       "      <td>-0.815001</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.927922</td>\n",
       "      <td>-0.485899</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>-0.667325</td>\n",
       "      <td>-0.802270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>2915</td>\n",
       "      <td>Claude Brisson</td>\n",
       "      <td>velocity-engine-core/src/test/java/org/apache/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.184341</td>\n",
       "      <td>109.998540</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5084.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725507</td>\n",
       "      <td>0.626239</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.423329</td>\n",
       "      <td>-0.698127</td>\n",
       "      <td>-0.416638</td>\n",
       "      <td>-0.230406</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.102370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14564 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                    Name  \\\n",
       "0       9397        Antonio Petrelli   \n",
       "1      18964       Jon Scott Stevens   \n",
       "2      16306       Geir Magnusson Jr   \n",
       "3       1373          Claude Brisson   \n",
       "4       4999  Henning Schmiedehausen   \n",
       "...      ...                     ...   \n",
       "14559   5520  Henning Schmiedehausen   \n",
       "14560   3046          Claude Brisson   \n",
       "14561  20463           Jason van Zyl   \n",
       "14562  18638       Jon Scott Stevens   \n",
       "14563   2915          Claude Brisson   \n",
       "\n",
       "                                                    File  Bug  PageRank  \\\n",
       "0      src/test/org/apache/velocity/test/PropertyMeth...    0  2.023938   \n",
       "1                     docs/ymtd/ymtd-error-handling.html    0  1.305663   \n",
       "2                              docs/developer-guide.html    0  1.736420   \n",
       "3      velocity-engine-core/src/test/java/org/apache/...    0  1.184341   \n",
       "4                    whiteboard/geir/velocity.properties    0  1.745637   \n",
       "...                                                  ...  ...       ...   \n",
       "14559                      xdocs/vtl-reference-guide.xml    0  1.745637   \n",
       "14560  velocity-engine-core/src/main/java/org/apache/...    0  1.184341   \n",
       "14561                                       TODO-1.0.txt    0  1.360128   \n",
       "14562  src/java/org/apache/velocity/runtime/directive...    0  1.305663   \n",
       "14563  velocity-engine-core/src/test/java/org/apache/...    0  1.184341   \n",
       "\n",
       "       Betweenness  Closeness  Harmonic   Degree  communityId  ...   emb_118  \\\n",
       "0         7.057669   0.857143     0.825   3036.0           17  ... -0.864049   \n",
       "1         1.366062   0.750000     0.750   4654.0           17  ... -0.193705   \n",
       "2         2.666855   0.750000     0.750  15235.0           17  ...  0.238687   \n",
       "3       109.998540   0.947368     0.875   5084.0            9  ...  0.725507   \n",
       "4         3.886492   0.782609     0.775   8351.0           17  ...  0.378187   \n",
       "...            ...        ...       ...      ...          ...  ...       ...   \n",
       "14559     3.886492   0.782609     0.775   8351.0           17  ...  0.378187   \n",
       "14560   109.998540   0.947368     0.875   5084.0            9  ...  0.725507   \n",
       "14561     1.159654   0.750000     0.750   5383.0           17  ... -0.466211   \n",
       "14562     1.366062   0.750000     0.750   4654.0           17  ... -0.193705   \n",
       "14563   109.998540   0.947368     0.875   5084.0            9  ...  0.725507   \n",
       "\n",
       "        emb_119   emb_120   emb_121   emb_122   emb_123   emb_124   emb_125  \\\n",
       "0      0.515813 -0.927484 -0.873930 -0.656481  0.463783  0.363294 -0.325170   \n",
       "1     -0.815001  0.341188 -0.196324 -0.927922 -0.485899 -0.185160  0.357114   \n",
       "2      0.219475 -0.103638 -0.247022 -0.955519  0.220302  0.125604  0.210404   \n",
       "3      0.626239  0.243156  0.691346 -0.423329 -0.698127 -0.416638 -0.230406   \n",
       "4     -0.364097  0.458338 -0.156045  0.250242  0.163307 -0.225199  0.179227   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14559 -0.364097  0.458338 -0.156045  0.250242  0.163307 -0.225199  0.179227   \n",
       "14560  0.626239  0.243156  0.691346 -0.423329 -0.698127 -0.416638 -0.230406   \n",
       "14561 -0.494635  0.871449 -0.238051 -0.081807 -0.288823 -0.084420 -1.064453   \n",
       "14562 -0.815001  0.341188 -0.196324 -0.927922 -0.485899 -0.185160  0.357114   \n",
       "14563  0.626239  0.243156  0.691346 -0.423329 -0.698127 -0.416638 -0.230406   \n",
       "\n",
       "        emb_126   emb_127  \n",
       "0      0.634005 -0.770786  \n",
       "1     -0.667325 -0.802270  \n",
       "2     -0.792885  0.541425  \n",
       "3      0.426186  0.102370  \n",
       "4      1.103847 -0.059876  \n",
       "...         ...       ...  \n",
       "14559  1.103847 -0.059876  \n",
       "14560  0.426186  0.102370  \n",
       "14561  0.917812 -0.051695  \n",
       "14562 -0.667325 -0.802270  \n",
       "14563  0.426186  0.102370  \n",
       "\n",
       "[14564 rows x 138 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train['Bug'].value_counts())\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the class counts for our binary classification in the training dataset. In this case, our results are 12,060 <b>False (0)</b> counts, and 567 <b>True (1)</b> counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6243\n",
      "Name: Bug, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>File</th>\n",
       "      <th>Bug</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Harmonic</th>\n",
       "      <th>Degree</th>\n",
       "      <th>communityId</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10680</td>\n",
       "      <td>Antonio Petrelli</td>\n",
       "      <td>{velocity-engine =&gt; velocity-engine-core}/src/...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>7.057669</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.825</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.864049</td>\n",
       "      <td>0.515813</td>\n",
       "      <td>-0.927484</td>\n",
       "      <td>-0.873930</td>\n",
       "      <td>-0.656481</td>\n",
       "      <td>0.463783</td>\n",
       "      <td>0.363294</td>\n",
       "      <td>-0.325170</td>\n",
       "      <td>0.634005</td>\n",
       "      <td>-0.770786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14690</td>\n",
       "      <td>Geir Magnusson Jr</td>\n",
       "      <td>src/java/org/apache/velocity/runtime/parser/Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736420</td>\n",
       "      <td>2.666855</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>15235.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.955519</td>\n",
       "      <td>0.220302</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>-0.792885</td>\n",
       "      <td>0.541425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19068</td>\n",
       "      <td>Jon Scott Stevens</td>\n",
       "      <td>src/java/org/apache/velocity/runtime/parser/no...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305663</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193705</td>\n",
       "      <td>-0.815001</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.927922</td>\n",
       "      <td>-0.485899</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>-0.667325</td>\n",
       "      <td>-0.802270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12772</td>\n",
       "      <td>William Glass-Husain</td>\n",
       "      <td>src/java/org/apache/velocity/exception/ParseEr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.915983</td>\n",
       "      <td>4.716703</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.775</td>\n",
       "      <td>5939.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425968</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.676466</td>\n",
       "      <td>0.845613</td>\n",
       "      <td>-0.097672</td>\n",
       "      <td>-0.542028</td>\n",
       "      <td>0.772965</td>\n",
       "      <td>-0.033726</td>\n",
       "      <td>0.058582</td>\n",
       "      <td>0.385896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16548</td>\n",
       "      <td>Geir Magnusson Jr</td>\n",
       "      <td>docs/ymtd/ymtd-taglibs.html</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736420</td>\n",
       "      <td>2.666855</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>15235.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.955519</td>\n",
       "      <td>0.220302</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>-0.792885</td>\n",
       "      <td>0.541425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238</th>\n",
       "      <td>4707</td>\n",
       "      <td>Henning Schmiedehausen</td>\n",
       "      <td>examples/xmlapp_example/appendVELCP.bat</td>\n",
       "      <td>0</td>\n",
       "      <td>1.745637</td>\n",
       "      <td>3.886492</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.775</td>\n",
       "      <td>8351.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378187</td>\n",
       "      <td>-0.364097</td>\n",
       "      <td>0.458338</td>\n",
       "      <td>-0.156045</td>\n",
       "      <td>0.250242</td>\n",
       "      <td>0.163307</td>\n",
       "      <td>-0.225199</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>1.103847</td>\n",
       "      <td>-0.059876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>8118</td>\n",
       "      <td>Nathan Bubna</td>\n",
       "      <td>test/texen/templates/ServiceImplementation.vm</td>\n",
       "      <td>0</td>\n",
       "      <td>2.495680</td>\n",
       "      <td>29.956681</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>8927.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205965</td>\n",
       "      <td>0.125033</td>\n",
       "      <td>0.666150</td>\n",
       "      <td>0.642181</td>\n",
       "      <td>0.627789</td>\n",
       "      <td>-0.211606</td>\n",
       "      <td>0.335257</td>\n",
       "      <td>-0.157020</td>\n",
       "      <td>-0.591673</td>\n",
       "      <td>0.688562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>17157</td>\n",
       "      <td>Geir Magnusson Jr</td>\n",
       "      <td>src/java/org/apache/velocity/runtime/parser/no...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736420</td>\n",
       "      <td>2.666855</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>15235.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238687</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.955519</td>\n",
       "      <td>0.220302</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>-0.792885</td>\n",
       "      <td>0.541425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>18285</td>\n",
       "      <td>Jon Scott Stevens</td>\n",
       "      <td>docs/developer-guide.html</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305663</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193705</td>\n",
       "      <td>-0.815001</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.927922</td>\n",
       "      <td>-0.485899</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>-0.667325</td>\n",
       "      <td>-0.802270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>18544</td>\n",
       "      <td>Jon Scott Stevens</td>\n",
       "      <td>docs/migration.html</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305663</td>\n",
       "      <td>1.366062</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>4654.0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193705</td>\n",
       "      <td>-0.815001</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.196324</td>\n",
       "      <td>-0.927922</td>\n",
       "      <td>-0.485899</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>-0.667325</td>\n",
       "      <td>-0.802270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6243 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                    Name  \\\n",
       "0     10680        Antonio Petrelli   \n",
       "1     14690       Geir Magnusson Jr   \n",
       "2     19068       Jon Scott Stevens   \n",
       "3     12772    William Glass-Husain   \n",
       "4     16548       Geir Magnusson Jr   \n",
       "...     ...                     ...   \n",
       "6238   4707  Henning Schmiedehausen   \n",
       "6239   8118            Nathan Bubna   \n",
       "6240  17157       Geir Magnusson Jr   \n",
       "6241  18285       Jon Scott Stevens   \n",
       "6242  18544       Jon Scott Stevens   \n",
       "\n",
       "                                                   File  Bug  PageRank  \\\n",
       "0     {velocity-engine => velocity-engine-core}/src/...    0  2.023938   \n",
       "1     src/java/org/apache/velocity/runtime/parser/Pa...    0  1.736420   \n",
       "2     src/java/org/apache/velocity/runtime/parser/no...    0  1.305663   \n",
       "3     src/java/org/apache/velocity/exception/ParseEr...    0  1.915983   \n",
       "4                           docs/ymtd/ymtd-taglibs.html    0  1.736420   \n",
       "...                                                 ...  ...       ...   \n",
       "6238            examples/xmlapp_example/appendVELCP.bat    0  1.745637   \n",
       "6239      test/texen/templates/ServiceImplementation.vm    0  2.495680   \n",
       "6240  src/java/org/apache/velocity/runtime/parser/no...    0  1.736420   \n",
       "6241                          docs/developer-guide.html    0  1.305663   \n",
       "6242                                docs/migration.html    0  1.305663   \n",
       "\n",
       "      Betweenness  Closeness  Harmonic   Degree  communityId  ...   emb_118  \\\n",
       "0        7.057669   0.857143     0.825   3036.0           17  ... -0.864049   \n",
       "1        2.666855   0.750000     0.750  15235.0           17  ...  0.238687   \n",
       "2        1.366062   0.750000     0.750   4654.0           17  ... -0.193705   \n",
       "3        4.716703   0.782609     0.775   5939.0           17  ... -0.425968   \n",
       "4        2.666855   0.750000     0.750  15235.0           17  ...  0.238687   \n",
       "...           ...        ...       ...      ...          ...  ...       ...   \n",
       "6238     3.886492   0.782609     0.775   8351.0           17  ...  0.378187   \n",
       "6239    29.956681   0.900000     0.850   8927.0           17  ...  0.205965   \n",
       "6240     2.666855   0.750000     0.750  15235.0           17  ...  0.238687   \n",
       "6241     1.366062   0.750000     0.750   4654.0           17  ... -0.193705   \n",
       "6242     1.366062   0.750000     0.750   4654.0           17  ... -0.193705   \n",
       "\n",
       "       emb_119   emb_120   emb_121   emb_122   emb_123   emb_124   emb_125  \\\n",
       "0     0.515813 -0.927484 -0.873930 -0.656481  0.463783  0.363294 -0.325170   \n",
       "1     0.219475 -0.103638 -0.247022 -0.955519  0.220302  0.125604  0.210404   \n",
       "2    -0.815001  0.341188 -0.196324 -0.927922 -0.485899 -0.185160  0.357114   \n",
       "3     0.068658  0.676466  0.845613 -0.097672 -0.542028  0.772965 -0.033726   \n",
       "4     0.219475 -0.103638 -0.247022 -0.955519  0.220302  0.125604  0.210404   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6238 -0.364097  0.458338 -0.156045  0.250242  0.163307 -0.225199  0.179227   \n",
       "6239  0.125033  0.666150  0.642181  0.627789 -0.211606  0.335257 -0.157020   \n",
       "6240  0.219475 -0.103638 -0.247022 -0.955519  0.220302  0.125604  0.210404   \n",
       "6241 -0.815001  0.341188 -0.196324 -0.927922 -0.485899 -0.185160  0.357114   \n",
       "6242 -0.815001  0.341188 -0.196324 -0.927922 -0.485899 -0.185160  0.357114   \n",
       "\n",
       "       emb_126   emb_127  \n",
       "0     0.634005 -0.770786  \n",
       "1    -0.792885  0.541425  \n",
       "2    -0.667325 -0.802270  \n",
       "3     0.058582  0.385896  \n",
       "4    -0.792885  0.541425  \n",
       "...        ...       ...  \n",
       "6238  1.103847 -0.059876  \n",
       "6239 -0.591673  0.688562  \n",
       "6240 -0.792885  0.541425  \n",
       "6241 -0.667325 -0.802270  \n",
       "6242 -0.667325 -0.802270  \n",
       "\n",
       "[6243 rows x 138 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test['Bug'].value_counts())\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70655db72bec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlr_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrf_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrf_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxgb_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    935\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m    936\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         class_weight_ = compute_class_weight(class_weight, classes=classes_,\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "lr_model1.fit(x1_train, y_train)\n",
    "lr_model2.fit(x2_train, y_train)\n",
    "rf_model1.fit(x1_train, y_train)\n",
    "rf_model2.fit(x2_train, y_train)\n",
    "xgb_model1.fit(x1_train, y_train)\n",
    "xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y_test)}\")\n",
    "results_data[0][0] = \"Original_Logistic_Regression\"\n",
    "results_data[0][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[0][2] = lr_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y_test)}\")\n",
    "results_data[1][0] = \"Original_Random_Forrest\"\n",
    "results_data[1][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[1][2] = rf_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y_test)}\")\n",
    "results_data[2][0] = \"Original_XGB_Classifier\"\n",
    "results_data[2][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[2][2] = xgb_model2.score(x2_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model scores for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[0][3] = acc1\n",
    "results_data[0][4] = acc2\n",
    "results_data[0][5] = prc_val1\n",
    "results_data[0][6] = prc_val2\n",
    "results_data[0][7] = pr_auc1\n",
    "results_data[0][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[1][3] = acc1\n",
    "results_data[1][4] = acc2\n",
    "results_data[1][5] = prc_val1\n",
    "results_data[1][6] = prc_val2\n",
    "results_data[1][7] = pr_auc1\n",
    "results_data[1][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[2][3] = acc1\n",
    "results_data[2][4] = acc2\n",
    "results_data[2][5] = prc_val1\n",
    "results_data[2][6] = prc_val2\n",
    "results_data[2][7] = pr_auc1\n",
    "results_data[2][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models\n",
    "\n",
    "TODO: Get it to work with randomforrest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y_test, x2_test, y_test, lr_prediction_probs1, lr_prediction_probs2, \"original dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y_test, x2_test, y_test, rf_prediction_probs1, rf_prediction_probs2, \"original dataset Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y_test, x2_test, y_test, xgb_prediction_probs1, xgb_prediction_probs2, \"original dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best thresholds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "\n",
    "results_data[3][0] = \"Original_Logistic_Regression_Best_Threshold\"\n",
    "results_data[3][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[3][2] = lr_model2.score(x2_test, y_test)\n",
    "results_data[3][3] = acc1\n",
    "results_data[3][4] = acc2\n",
    "results_data[3][5] = prc_val1\n",
    "results_data[3][6] = prc_val2\n",
    "results_data[3][7] = pr_auc1\n",
    "results_data[3][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[4][0] = \"Original_Random_Forrest_Best_Threshold\"\n",
    "results_data[4][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[4][2] = rf_model2.score(x2_test, y_test)\n",
    "results_data[4][3] = acc1\n",
    "results_data[4][4] = acc2\n",
    "results_data[4][5] = prc_val1\n",
    "results_data[4][6] = prc_val2\n",
    "results_data[4][7] = pr_auc1\n",
    "results_data[4][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[5][0] = \"Original_XGBoost_Classifier_Best_Threshold\"\n",
    "results_data[5][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[5][2] = xgb_model2.score(x2_test, y_test)\n",
    "results_data[5][3] = acc1\n",
    "results_data[5][4] = acc2\n",
    "results_data[5][5] = prc_val1\n",
    "results_data[5][6] = prc_val2\n",
    "results_data[5][7] = pr_auc1\n",
    "results_data[5][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df['Bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross validation results for model 1\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "cv_results = cross_validate(lr_model1, x1, y, cv=3)\n",
    "sorted(cv_results.keys())\n",
    "print(cv_results['test_score'])\n",
    "\n",
    "print(\"\\nCross validation results for model 2\")\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "cv_results = cross_validate(lr_model2, x2, y, cv=3)\n",
    "sorted(cv_results.keys())\n",
    "print(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Running extremely slow, working on this issue\n",
    "#Loo(lr_model1, x1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, x1, y)\n",
    "results_data[6][0] = \"Original_Logistic_Regression_rkf\"\n",
    "results_data[6][1] = model_score\n",
    "results_data[6][3] = acc\n",
    "results_data[6][5] = prc_val\n",
    "results_data[6][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[7][0] = \"Original_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[7][1] = model_score\n",
    "results_data[7][3] = acc\n",
    "results_data[7][5] = prc_val\n",
    "results_data[7][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, x1, y)\n",
    "results_data[8][0] = \"Original_Random_Forrest_rkf\"\n",
    "results_data[8][1] = model_score\n",
    "results_data[8][3] = acc\n",
    "results_data[8][5] = prc_val\n",
    "results_data[8][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, x1, y)\n",
    "results_data[9][0] = \"Original_XGB_Classifier_rkf\"\n",
    "results_data[9][1] = model_score\n",
    "results_data[9][3] = acc\n",
    "results_data[9][5] = prc_val\n",
    "results_data[9][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, x1, y)\n",
    "results_data[10][0] = \"Original_Logistic_Regression_skf\"\n",
    "results_data[10][1] = model_score\n",
    "results_data[10][3] = acc\n",
    "results_data[10][5] = prc_val\n",
    "results_data[10][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[11][0] = \"Original_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[11][1] = model_score\n",
    "results_data[11][3] = acc\n",
    "results_data[11][5] = prc_val\n",
    "results_data[11][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, x1, y)\n",
    "results_data[12][0] = \"Original_Random_Forrest_skf\"\n",
    "results_data[12][1] = model_score\n",
    "results_data[12][3] = acc\n",
    "results_data[12][5] = prc_val\n",
    "results_data[12][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, x1, y)\n",
    "results_data[13][0] = \"Original_XGB_Classifier_skf\"\n",
    "results_data[13][1] = model_score\n",
    "results_data[13][3] = acc\n",
    "results_data[13][5] = prc_val\n",
    "results_data[13][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, x1, y)\n",
    "results_data[14][0] = \"Original_Logistic_Regression_tss\"\n",
    "results_data[14][1] = model_score\n",
    "results_data[14][3] = acc\n",
    "results_data[14][5] = prc_val\n",
    "results_data[14][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, x1, y, lr_best_threshold1)\n",
    "results_data[15][0] = \"Original_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[15][1] = model_score\n",
    "results_data[15][3] = acc\n",
    "results_data[15][5] = prc_val\n",
    "results_data[15][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, x1, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, x1, y)\n",
    "results_data[16][0] = \"Original_Random_Forrest_tss\"\n",
    "results_data[16][1] = model_score\n",
    "results_data[16][3] = acc\n",
    "results_data[16][5] = prc_val\n",
    "results_data[16][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, x1, y)\n",
    "results_data[17][0] = \"Original_XGB_Classifier_tss\"\n",
    "results_data[17][1] = model_score\n",
    "results_data[17][3] = acc\n",
    "results_data[17][5] = prc_val\n",
    "results_data[17][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Running extremely slow, working on this issue\n",
    "#Loo(lr_model2, x2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, x2, y)\n",
    "results_data[6][2] = model_score\n",
    "results_data[6][4] = acc\n",
    "results_data[6][6] = prc_val\n",
    "results_data[6][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[7][2] = model_score\n",
    "results_data[7][4] = acc\n",
    "results_data[7][6] = prc_val\n",
    "results_data[7][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, x2, y)\n",
    "results_data[8][2] = model_score\n",
    "results_data[8][4] = acc\n",
    "results_data[8][6] = prc_val\n",
    "results_data[8][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, x2, y)\n",
    "results_data[9][2] = model_score\n",
    "results_data[9][4] = acc\n",
    "results_data[9][6] = prc_val\n",
    "results_data[9][8] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, x2, y)\n",
    "results_data[10][2] = model_score\n",
    "results_data[10][4] = acc\n",
    "results_data[10][6] = prc_val\n",
    "results_data[10][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[11][2] = model_score\n",
    "results_data[11][4] = acc\n",
    "results_data[11][6] = prc_val\n",
    "results_data[11][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, x2, y)\n",
    "results_data[12][2] = model_score\n",
    "results_data[12][4] = acc\n",
    "results_data[12][6] = prc_val\n",
    "results_data[12][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, x2, y)\n",
    "results_data[13][2] = model_score\n",
    "results_data[13][4] = acc\n",
    "results_data[13][6] = prc_val\n",
    "results_data[13][8] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, x2, y)\n",
    "results_data[14][2] = model_score\n",
    "results_data[14][4] = acc\n",
    "results_data[14][6] = prc_val\n",
    "results_data[14][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, x2, y, lr_best_threshold2)\n",
    "results_data[15][2] = model_score\n",
    "results_data[15][4] = acc\n",
    "results_data[15][6] = prc_val\n",
    "results_data[15][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, x2, y)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, x2, y)\n",
    "results_data[16][2] = model_score\n",
    "results_data[16][4] = acc\n",
    "results_data[16][6] = prc_val\n",
    "results_data[16][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, x2, y)\n",
    "results_data[17][2] = model_score\n",
    "results_data[17][4] = acc\n",
    "results_data[17][6] = prc_val\n",
    "results_data[17][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"original dataset Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"original dataset Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"original dataset XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"original dataset Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"original dataset Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"original dataset XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_og_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"original dataset Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_og_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"original dataset Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_og_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"original dataset XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_df = graph_df.loc[graph_df['Bug'] == 1].sample(n=1900, random_state=42)\n",
    "non_bug_df = graph_df.loc[graph_df['Bug'] == 0].sample(n=1900, random_state=42)\n",
    "normalized_under_df = pd.concat([bug_df, non_bug_df])\n",
    "normalized_under_df = normalized_under_df.reset_index()\n",
    "print(normalized_under_df['Bug'].value_counts())\n",
    "\n",
    "usx1 = normalized_under_df[labels1]\n",
    "usx2 = normalized_under_df[labels2]\n",
    "usy = normalized_under_df[\"Bug\"]\n",
    "usy = usy.sample(frac=1).reset_index(drop=True) # shuffle dataset\n",
    "\n",
    "train, test = train_test_split(normalized_under_df, test_size=0.3, random_state = 5)\n",
    "\n",
    "labels1 = ['PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree']\n",
    "labels2 = set(list(normalized_under_df.columns))\n",
    "labels2.difference_update(['index', 'Bug', 'Name', 'File', 'PageRank', 'Betweenness', 'Closeness', 'Harmonic', 'Degree'])\n",
    "\n",
    "x1_train = train[labels1]\n",
    "x2_train = train[labels2]\n",
    "y_train = train[\"Bug\"]\n",
    "x1_test = test[labels1]\n",
    "x2_test = test[labels2]\n",
    "y_test = test[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1.fit(x1_train, y_train)\n",
    "lr_model2.fit(x2_train, y_train)\n",
    "rf_model1.fit(x1_train, y_train)\n",
    "rf_model2.fit(x2_train, y_train)\n",
    "xgb_model1.fit(x1_train, y_train)\n",
    "xgb_model2.fit(x2_train, y_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y_test)}\")\n",
    "results_data[18][0] = \"Undersampled_Logistic_Regression\"\n",
    "results_data[18][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[18][2] = lr_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y_test)}\")\n",
    "results_data[19][0] = \"Undersampled_Random_Forrest\"\n",
    "results_data[19][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[19][2] = rf_model2.score(x2_test, y_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y_test)}\")\n",
    "results_data[20][0] = \"Undersampled_XGB_Classifier\"\n",
    "results_data[20][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[20][2] = xgb_model2.score(x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[18][3] = acc1\n",
    "results_data[18][4] = acc2\n",
    "results_data[18][5] = prc_val1\n",
    "results_data[18][6] = prc_val2\n",
    "results_data[18][7] = pr_auc1\n",
    "results_data[18][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[19][3] = acc1\n",
    "results_data[19][4] = acc2\n",
    "results_data[19][5] = prc_val1\n",
    "results_data[19][6] = prc_val2\n",
    "results_data[19][7] = pr_auc1\n",
    "results_data[19][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[20][3] = acc1\n",
    "results_data[20][4] = acc2\n",
    "results_data[20][5] = prc_val1\n",
    "results_data[20][6] = prc_val2\n",
    "results_data[20][7] = pr_auc1\n",
    "results_data[20][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y_test, x2_test, y_test, lr_prediction_probs1, lr_prediction_probs2, \"undersampled dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y_test, x2_test, y_test, rf_prediction_probs1, rf_prediction_probs2, \"undersampled datase Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, xgb_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y_test, x2_test, y_test, xgb_prediction_probs1, xgb_prediction_probs2, \"undersampled dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[21][0] = \"Undersampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[21][1] = lr_model1.score(x1_test, y_test)\n",
    "results_data[21][2] = lr_model2.score(x2_test, y_test)\n",
    "results_data[21][3] = acc1\n",
    "results_data[21][4] = acc2\n",
    "results_data[21][5] = prc_val1\n",
    "results_data[21][6] = prc_val2\n",
    "results_data[21][7] = pr_auc1\n",
    "results_data[21][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[22][0] = \"Undersampled_Random_Forrest_Best_Threshold\"\n",
    "results_data[22][1] = rf_model1.score(x1_test, y_test)\n",
    "results_data[22][2] = rf_model2.score(x2_test, y_test)\n",
    "results_data[22][3] = acc1\n",
    "results_data[22][4] = acc2\n",
    "results_data[22][5] = prc_val1\n",
    "results_data[22][6] = prc_val2\n",
    "results_data[22][7] = pr_auc1\n",
    "results_data[22][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[23][0] = \"Undersampled_XGB_Classifier_Best_Threshold\"\n",
    "results_data[23][1] = xgb_model1.score(x1_test, y_test)\n",
    "results_data[23][2] = xgb_model2.score(x2_test, y_test)\n",
    "results_data[23][3] = acc1\n",
    "results_data[23][4] = acc2\n",
    "results_data[23][5] = prc_val1\n",
    "results_data[23][6] = prc_val2\n",
    "results_data[23][7] = pr_auc1\n",
    "results_data[23][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Undersampling Rebalance for model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, usx1, usy)\n",
    "results_data[24][0] = \"Undersampled_Logistic_Regression_rkf\"\n",
    "results_data[24][1] = model_score\n",
    "results_data[24][3] = acc\n",
    "results_data[24][5] = prc_val\n",
    "results_data[24][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[25][0] = \"Undersampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[25][1] = model_score\n",
    "results_data[25][3] = acc\n",
    "results_data[25][5] = prc_val\n",
    "results_data[25][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, usx1, usy)\n",
    "results_data[26][0] = \"Undersampled_Random_Forrest_rkf\"\n",
    "results_data[26][1] = model_score\n",
    "results_data[26][3] = acc\n",
    "results_data[26][5] = prc_val\n",
    "results_data[26][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, usx1, usy)\n",
    "results_data[27][0] = \"Undersampled_XGB_Classifier_rkf\"\n",
    "results_data[27][1] = model_score\n",
    "results_data[27][3] = acc\n",
    "results_data[27][5] = prc_val\n",
    "results_data[27][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, usx1, usy)\n",
    "results_data[28][0] = \"Undersampled_Logistic_Regression_skf\"\n",
    "results_data[28][1] = model_score\n",
    "results_data[28][3] = acc\n",
    "results_data[28][5] = prc_val\n",
    "results_data[28][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[29][0] = \"Undersampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[29][1] = model_score\n",
    "results_data[29][3] = acc\n",
    "results_data[29][5] = prc_val\n",
    "results_data[29][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, usx1, usy)\n",
    "results_data[30][0] = \"Undersampled_Random_Forrest_skf\"\n",
    "results_data[30][1] = model_score\n",
    "results_data[30][3] = acc\n",
    "results_data[30][5] = prc_val\n",
    "results_data[30][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, usx1, usy)\n",
    "results_data[31][0] = \"Undersampled_XGB_Classifier_skf\"\n",
    "results_data[31][1] = model_score\n",
    "results_data[31][3] = acc\n",
    "results_data[31][5] = prc_val\n",
    "results_data[31][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, usx1, usy)\n",
    "results_data[32][0] = \"Undersampled_Logistic_Regression_tss\"\n",
    "results_data[32][1] = model_score\n",
    "results_data[32][3] = acc\n",
    "results_data[32][5] = prc_val\n",
    "results_data[32][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, usx1, usy, lr_best_threshold1)\n",
    "results_data[33][0] = \"Undersampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[33][1] = model_score\n",
    "results_data[33][3] = acc\n",
    "results_data[33][5] = prc_val\n",
    "results_data[33][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, usx1, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, usx1, usy)\n",
    "results_data[34][0] = \"Undersampled_Random_Forrest_tss\"\n",
    "results_data[34][1] = model_score\n",
    "results_data[34][3] = acc\n",
    "results_data[34][5] = prc_val\n",
    "results_data[34][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, usx1, usy)\n",
    "results_data[35][0] = \"Undersampled_XGB_Classifier_tss\"\n",
    "results_data[35][1] = model_score\n",
    "results_data[35][3] = acc\n",
    "results_data[35][5] = prc_val\n",
    "results_data[35][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Undersampling Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, usx2, usy)\n",
    "results_data[24][2] = model_score\n",
    "results_data[24][4] = acc\n",
    "results_data[24][6] = prc_val\n",
    "results_data[24][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[25][2] = model_score\n",
    "results_data[25][4] = acc\n",
    "results_data[25][6] = prc_val\n",
    "results_data[25][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, usx2, usy)\n",
    "results_data[26][2] = model_score\n",
    "results_data[26][4] = acc\n",
    "results_data[26][6] = prc_val\n",
    "results_data[26][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, usx2, usy)\n",
    "results_data[27][2] = model_score\n",
    "results_data[27][4] = acc\n",
    "results_data[27][6] = prc_val\n",
    "results_data[27][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, usx2, usy)\n",
    "results_data[28][2] = model_score\n",
    "results_data[28][4] = acc\n",
    "results_data[28][6] = prc_val\n",
    "results_data[28][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[29][2] = model_score\n",
    "results_data[29][4] = acc\n",
    "results_data[29][6] = prc_val\n",
    "results_data[29][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, usx2, usy)\n",
    "results_data[30][2] = model_score\n",
    "results_data[30][4] = acc\n",
    "results_data[30][6] = prc_val\n",
    "results_data[30][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, usx2, usy)\n",
    "results_data[31][2] = model_score\n",
    "results_data[31][4] = acc\n",
    "results_data[31][6] = prc_val\n",
    "results_data[31][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, usx2, usy)\n",
    "results_data[32][2] = model_score\n",
    "results_data[32][4] = acc\n",
    "results_data[32][6] = prc_val\n",
    "results_data[32][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, usx2, usy, lr_best_threshold2)\n",
    "results_data[33][2] = model_score\n",
    "results_data[33][4] = acc\n",
    "results_data[33][6] = prc_val\n",
    "results_data[33][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, usx2, usy)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, usx2, usy)\n",
    "results_data[34][2] = model_score\n",
    "results_data[34][4] = acc\n",
    "results_data[34][6] = prc_val\n",
    "results_data[34][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, usx2, usy)\n",
    "results_data[35][2] = model_score\n",
    "results_data[35][4] = acc\n",
    "results_data[35][6] = prc_val\n",
    "results_data[35][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"Undersampled Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"Undersampled Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"Undersampled XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"Undersampled Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"Undersampled Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"Undersampled XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_us_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"Undersampled Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_us_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"Undersampled Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_us_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"Undersampled XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For oversampling we will use SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "\n",
    "print(\"x1 Before SMOTE:\")\n",
    "\n",
    "print(x1_train.shape)\n",
    "\n",
    "print(\"x2 Before SMOTE:\")\n",
    "\n",
    "print(x2_train.shape)\n",
    "\n",
    "# Fit the model to generate the data for Model 1.\n",
    "oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "# Fit the model to generate the data for Model 2.\n",
    "oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "print(\"x1 After SMOTE:\")\n",
    "\n",
    "print(oversampled_X1.shape)\n",
    "\n",
    "print(\"x2 After SMOTE:\")\n",
    "\n",
    "print(oversampled_X2.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y2.value_counts(normalize=True) * 100)\n",
    "\n",
    "osx1 = oversampled_X1\n",
    "osx2 = oversampled_X2\n",
    "osy1 = oversampled_Y1\n",
    "osy2 = oversampled_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(osx1, osy1, test_size=0.3, random_state = 5)\n",
    "#x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(osx2, osy2, test_size=0.3, random_state = 5)\n",
    "#x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "lr_model1.fit(x1_train, y1_train)\n",
    "lr_model2.fit(x2_train, y2_train)\n",
    "rf_model1.fit(x1_train, y1_train)\n",
    "rf_model2.fit(x2_train, y2_train)\n",
    "xgb_model1.fit(x1_train, y1_train)\n",
    "xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y2_test)}\")\n",
    "results_data[36][0] = \"Oversampled_Logistic_Regression\"\n",
    "results_data[36][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[36][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y2_test)}\")\n",
    "results_data[37][0] = \"Oversampled_Random_Forrest\"\n",
    "results_data[37][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[37][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y2_test)}\")\n",
    "results_data[38][0] = \"Oversampled_XGB_Classifier\"\n",
    "results_data[38][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[38][2] = xgb_model2.score(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[36][3] = acc1\n",
    "results_data[36][4] = acc2\n",
    "results_data[36][5] = prc_val1\n",
    "results_data[36][6] = prc_val2\n",
    "results_data[36][7] = pr_auc1\n",
    "results_data[36][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[37][3] = acc1\n",
    "results_data[37][4] = acc2\n",
    "results_data[37][5] = prc_val1\n",
    "results_data[37][6] = prc_val2\n",
    "results_data[37][7] = pr_auc1\n",
    "results_data[37][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[38][3] = acc1\n",
    "results_data[38][4] = acc2\n",
    "results_data[38][5] = prc_val1\n",
    "results_data[38][6] = prc_val2\n",
    "results_data[38][7] = pr_auc1\n",
    "results_data[38][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_test, x2_test, y2_test, lr_prediction_probs1, lr_prediction_probs2, \"oversampled dataset Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_test, x2_test, y2_test, rf_prediction_probs1, rf_prediction_probs2, \"oversampled dataset Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_test, x2_test, y2_test, xgb_prediction_probs1, xgb_prediction_probs2, \"oversampled dataset XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using best threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[39][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[39][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[39][2] = lr_model2.score(x2_test, y2_test)\n",
    "results_data[39][3] = acc1\n",
    "results_data[39][4] = acc2\n",
    "results_data[39][5] = prc_val1\n",
    "results_data[39][6] = prc_val2\n",
    "results_data[39][7] = pr_auc1\n",
    "results_data[39][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[40][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[40][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[40][2] = rf_model2.score(x2_test, y2_test)\n",
    "results_data[40][3] = acc1\n",
    "results_data[40][4] = acc2\n",
    "results_data[40][5] = prc_val1\n",
    "results_data[40][6] = prc_val2\n",
    "results_data[40][7] = pr_auc1\n",
    "results_data[40][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[41][0] = \"Oversampled_Logistic_Regression_Best_Threshold\"\n",
    "results_data[41][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[41][2] = xgb_model2.score(x2_test, y2_test)\n",
    "results_data[41][3] = acc1\n",
    "results_data[41][4] = acc2\n",
    "results_data[41][5] = prc_val1\n",
    "results_data[41][6] = prc_val2\n",
    "results_data[41][7] = pr_auc1\n",
    "results_data[41][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling Rebalance for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, osx1, osy1)\n",
    "results_data[42][0] = \"Oversampled_Logistic_Regression_rkf\"\n",
    "results_data[42][1] = model_score\n",
    "results_data[42][3] = acc\n",
    "results_data[42][5] = prc_val\n",
    "results_data[42][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[43][0] = \"Oversampled_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[43][1] = model_score\n",
    "results_data[43][3] = acc\n",
    "results_data[43][5] = prc_val\n",
    "results_data[43][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, osx1, osy1)\n",
    "results_data[44][0] = \"Oversampled_Random_Forrest_rkf\"\n",
    "results_data[44][1] = model_score\n",
    "results_data[44][3] = acc\n",
    "results_data[44][5] = prc_val\n",
    "results_data[44][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, osx1, osy1)\n",
    "results_data[45][0] = \"Oversampled_XGB_Classifier_rkf\"\n",
    "results_data[45][1] = model_score\n",
    "results_data[45][3] = acc\n",
    "results_data[45][5] = prc_val\n",
    "results_data[45][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, osx1, osy1)\n",
    "results_data[46][0] = \"Oversampled_Logistic_Regression_skf\"\n",
    "results_data[46][1] = model_score\n",
    "results_data[46][3] = acc\n",
    "results_data[46][5] = prc_val\n",
    "results_data[46][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[47][0] = \"Oversampled_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[47][1] = model_score\n",
    "results_data[47][3] = acc\n",
    "results_data[47][5] = prc_val\n",
    "results_data[47][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, osx1, osy1)\n",
    "results_data[48][0] = \"Oversampled_Random_Forrest_skf\"\n",
    "results_data[48][1] = model_score\n",
    "results_data[48][3] = acc\n",
    "results_data[48][5] = prc_val\n",
    "results_data[48][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, osx1, osy1)\n",
    "results_data[49][0] = \"Oversampled_XGB_Classifier_skf\"\n",
    "results_data[49][1] = model_score\n",
    "results_data[49][3] = acc\n",
    "results_data[49][5] = prc_val\n",
    "results_data[49][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, osx1, osy1)\n",
    "results_data[50][0] = \"Oversampled_Logistic_Regression_tss\"\n",
    "results_data[50][1] = model_score\n",
    "results_data[50][3] = acc\n",
    "results_data[50][5] = prc_val\n",
    "results_data[50][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, osx1, osy1, lr_best_threshold1)\n",
    "results_data[51][0] = \"Oversampled_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[51][1] = model_score\n",
    "results_data[51][3] = acc\n",
    "results_data[51][5] = prc_val\n",
    "results_data[51][7] = pr_auc\n",
    "\n",
    "Tss_short(lr_model1, osx1, osy1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Tss(rf_model1, osx1, osy1)\n",
    "results_data[52][0] = \"Oversampled_Random_Forrest_tss\"\n",
    "results_data[52][1] = model_score\n",
    "results_data[52][3] = acc\n",
    "results_data[52][5] = prc_val\n",
    "results_data[52][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, osx1, osy1)\n",
    "results_data[53][0] = \"Oversampled_XGB_Classifier_tss\"\n",
    "results_data[53][1] = model_score\n",
    "results_data[53][3] = acc\n",
    "results_data[53][5] = prc_val\n",
    "results_data[53][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, osx2, osy2)\n",
    "results_data[42][2] = model_score\n",
    "results_data[42][4] = acc\n",
    "results_data[42][6] = prc_val\n",
    "results_data[42][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[43][2] = model_score\n",
    "results_data[43][4] = acc\n",
    "results_data[43][6] = prc_val\n",
    "results_data[43][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, osx2, osy2)\n",
    "results_data[44][2] = model_score\n",
    "results_data[44][4] = acc\n",
    "results_data[44][6] = prc_val\n",
    "results_data[44][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, osx2, osy2)\n",
    "results_data[45][2] = model_score\n",
    "results_data[45][4] = acc\n",
    "results_data[45][6] = prc_val\n",
    "results_data[45][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, osx2, osy2)\n",
    "results_data[46][2] = model_score\n",
    "results_data[46][4] = acc\n",
    "results_data[46][6] = prc_val\n",
    "results_data[46][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[47][2] = model_score\n",
    "results_data[47][4] = acc\n",
    "results_data[47][6] = prc_val\n",
    "results_data[47][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, osx2, osy2)\n",
    "results_data[48][2] = model_score\n",
    "results_data[48][4] = acc\n",
    "results_data[48][6] = prc_val\n",
    "results_data[48][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model1, osx1, osy1)\n",
    "results_data[49][2] = model_score\n",
    "results_data[49][4] = acc\n",
    "results_data[49][6] = prc_val\n",
    "results_data[49][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, osx2, osy2)\n",
    "results_data[50][2] = model_score\n",
    "results_data[50][4] = acc\n",
    "results_data[50][6] = prc_val\n",
    "results_data[50][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, osx2, osy2, lr_best_threshold2)\n",
    "results_data[51][2] = model_score\n",
    "results_data[51][4] = acc\n",
    "results_data[51][6] = prc_val\n",
    "results_data[51][8] = pr_auc\n",
    "\n",
    "Tss_short(lr_model2, osx2, osy2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Tss(rf_model2, osx2, osy2)\n",
    "results_data[52][2] = model_score\n",
    "results_data[52][4] = acc\n",
    "results_data[52][6] = prc_val\n",
    "results_data[52][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, osx2, osy2)\n",
    "results_data[53][2] = model_score\n",
    "results_data[53][4] = acc\n",
    "results_data[53][6] = prc_val\n",
    "results_data[53][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"Oversampled Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"Oversampled Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"Oversampled XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"Oversampled Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"Oversampled Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"Oversampled XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_os_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"Oversampled Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_os_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"Oversampled Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_os_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"Oversampled XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining Oversampling with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = graph_df[labels1]\n",
    "x2 = graph_df[labels2]\n",
    "y = graph_df[\"Bug\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "print(\"x1 Before SMOTE:\")\n",
    "print(x1.shape)\n",
    "print(\"x2 Before SMOTE:\")\n",
    "print(x2.shape)\n",
    "\n",
    "# Fit the model to generate the data for Model 1.\n",
    "oversampled_X1, oversampled_Y1 = sm.fit_resample(x1, y)\n",
    "\n",
    "# Fit the model to generate the data for Model 2.\n",
    "oversampled_X2, oversampled_Y2 = sm.fit_resample(x2, y)\n",
    "\n",
    "print(\"x1 After SMOTE:\")\n",
    "print(oversampled_X1.shape)\n",
    "print(\"x2 After SMOTE:\")\n",
    "print(oversampled_X2.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(oversampled_Y2.value_counts(normalize=True) * 100)\n",
    "\n",
    "osx1 = oversampled_X1\n",
    "osx2 = oversampled_X2\n",
    "osy1 = oversampled_Y1\n",
    "osy2 = oversampled_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "print(\"x1 Before RandomUnderSampler:\")\n",
    "print(osx1.shape)\n",
    "print(\"x2 Before RandomUnderSampler:\")\n",
    "print(osx2.shape)\n",
    "\n",
    "balanced_x1, balanced_y1, = rus.fit_resample(osx1, osy1)\n",
    "balanced_x2, balanced_y2, = rus.fit_resample(osx2, osy2)\n",
    "\n",
    "print(\"x1 After RandomUnderSampler:\")\n",
    "print(balanced_x1.shape)\n",
    "print(\"x2 After RandomUnderSampler:\")\n",
    "print(balanced_x1.shape)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(balanced_y1.value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "print(balanced_y2.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(balanced_x1, balanced_y1, test_size=0.3, random_state = 5)\n",
    "#x1_train, y1_train = sm.fit_resample(x1_train, y1_train)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(balanced_x2, balanced_y2, test_size=0.3, random_state = 5)\n",
    "#x2_train, y2_train = sm.fit_resample(x2_train, y2_train)\n",
    "lr_model1.fit(x1_train, y1_train)\n",
    "lr_model2.fit(x2_train, y2_train)\n",
    "rf_model1.fit(x1_train, y1_train)\n",
    "rf_model2.fit(x2_train, y2_train)\n",
    "xgb_model1.fit(x1_train, y1_train)\n",
    "xgb_model2.fit(x2_train, y2_train)\n",
    "\n",
    "lr_predictions1 = lr_model1.predict(x1_test)\n",
    "lr_predictions2 = lr_model2.predict(x2_test)\n",
    "lr_prediction_probs1 = lr_model1.predict_proba(x1_test)\n",
    "lr_prediction_probs2 = lr_model2.predict_proba(x2_test)\n",
    "\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "rf_predictions2 = rf_model2.predict(x2_test)\n",
    "rf_prediction_probs1 = rf_model1.predict_proba(x1_test)\n",
    "rf_prediction_probs2 = rf_model2.predict_proba(x2_test)\n",
    "\n",
    "xgb_predictions1 = xgb_model1.predict(x1_test)\n",
    "xgb_predictions2 = xgb_model2.predict(x2_test)\n",
    "xgb_prediction_probs1 = xgb_model1.predict_proba(x1_test)\n",
    "xgb_prediction_probs2 = xgb_model2.predict_proba(x2_test)\n",
    "\n",
    "# Score returns the mean accuracy on the given test data and labels for the provided model.\n",
    "print(f\"Logistic regression training score for model 1: {lr_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Logistic regression training score for model 2: {lr_model2.score(x2_test, y2_test)}\")\n",
    "results_data[54][0] = \"OSUS_Combination_Logistic_Regression\"\n",
    "results_data[54][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[54][2] = lr_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"Random Forrest Classification training score for model 1: {rf_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"Random Forrest Classification training score for model 2: {rf_model2.score(x2_test, y2_test)}\")\n",
    "results_data[55][0] = \"OSUS_Combination_Random_Forrest\"\n",
    "results_data[55][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[55][2] = rf_model2.score(x2_test, y2_test)\n",
    "\n",
    "print(f\"XGB Classifier training score for model 1: {xgb_model1.score(x1_test, y1_test)}\")\n",
    "print(f\"XGB Classifier training score for model 2: {xgb_model2.score(x2_test, y2_test)}\")\n",
    "results_data[56][0] = \"OSUS_Combination_XGB_Classifier\"\n",
    "results_data[56][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[56][2] = xgb_model2.score(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, lr_predictions1, lr_predictions2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[54][3] = acc1\n",
    "results_data[54][4] = acc2\n",
    "results_data[54][5] = prc_val1\n",
    "results_data[54][6] = prc_val2\n",
    "results_data[54][7] = pr_auc1\n",
    "results_data[54][8] = pr_auc2\n",
    "\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, rf_predictions1, rf_predictions2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[55][3] = acc1\n",
    "results_data[55][4] = acc2\n",
    "results_data[55][5] = prc_val1\n",
    "results_data[55][6] = prc_val2\n",
    "results_data[55][7] = pr_auc1\n",
    "results_data[55][8] = pr_auc2\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores(x1_test, x2_test, y1_test, xgb_predictions1, xgb_predictions2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[56][3] = acc1\n",
    "results_data[56][4] = acc2\n",
    "results_data[56][5] = prc_val1\n",
    "results_data[56][6] = prc_val2\n",
    "results_data[56][7] = pr_auc1\n",
    "results_data[56][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare Precision-Recall thresholds between models for oversampling and undersampling combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_threshold1, lr_best_threshold2, lr_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_test, x2_test, y2_test, lr_prediction_probs1, lr_prediction_probs2, \"USOS Combination Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_threshold1, rf_best_threshold2, rf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_test, x2_test, y2_test, rf_prediction_probs1, rf_prediction_probs2, \"USOS Combination Random Forrest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_threshold1, xgb_best_threshold2, xgb_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_test, x2_test, y2_test, xgb_prediction_probs1, xgb_prediction_probs2, \"USOS Combination XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model1, x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_threshold_plot(lr_model2, x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction_bestthresh1 = (lr_model1.predict_proba(x1_test)[:,1] >= lr_best_threshold1).astype(int)\n",
    "lr_prediction_bestthresh2 = (lr_model2.predict_proba(x2_test)[:,1] >= lr_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, lr_prediction_bestthresh1, lr_prediction_bestthresh2, lr_prediction_probs1, lr_prediction_probs2, lr_model1, lr_model2)\n",
    "results_data[57][0] = \"OSUS_Logistic_Regression_Best_Threshold\"\n",
    "results_data[57][1] = lr_model1.score(x1_test, y1_test)\n",
    "results_data[57][2] = lr_model2.score(x2_test, y2_test)\n",
    "results_data[57][3] = acc1\n",
    "results_data[57][4] = acc2\n",
    "results_data[57][5] = prc_val1\n",
    "results_data[57][6] = prc_val2\n",
    "results_data[57][7] = pr_auc1\n",
    "results_data[57][8] = pr_auc2\n",
    "\n",
    "rf_prediction_bestthresh1 = (rf_model1.predict_proba(x1_test)[:,1] >= rf_best_threshold1).astype(int)\n",
    "rf_prediction_bestthresh2 = (rf_model2.predict_proba(x2_test)[:,1] >= rf_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, rf_prediction_bestthresh1, rf_prediction_bestthresh2, rf_prediction_probs1, rf_prediction_probs2, rf_model1, rf_model2)\n",
    "results_data[58][0] = \"OSUS_Random_Forrest_Best_Threshold\"\n",
    "results_data[58][1] = rf_model1.score(x1_test, y1_test)\n",
    "results_data[58][2] = rf_model2.score(x2_test, y2_test)\n",
    "results_data[58][3] = acc1\n",
    "results_data[58][4] = acc2\n",
    "results_data[58][5] = prc_val1\n",
    "results_data[58][6] = prc_val2\n",
    "results_data[58][7] = pr_auc1\n",
    "results_data[58][8] = pr_auc2\n",
    "\n",
    "xgb_prediction_bestthresh1 = (xgb_model1.predict_proba(x1_test)[:,1] >= xgb_best_threshold1).astype(int)\n",
    "xgb_prediction_bestthresh2 = (xgb_model2.predict_proba(x2_test)[:,1] >= xgb_best_threshold2).astype(int)\n",
    "acc1, acc2, prc_val1, prc_val2, pr_auc1, pr_auc2 = Compare_Model_Scores_Best_Threshold(x1_test, x2_test, y1_test, xgb_prediction_bestthresh1, xgb_prediction_bestthresh2, xgb_prediction_probs1, xgb_prediction_probs2, xgb_model1, xgb_model2)\n",
    "results_data[59][0] = \"OSUS_XGBoost_Classifier_Best_Threshold\"\n",
    "results_data[59][1] = xgb_model1.score(x1_test, y1_test)\n",
    "results_data[59][2] = xgb_model2.score(x2_test, y2_test)\n",
    "results_data[59][3] = acc1\n",
    "results_data[59][4] = acc2\n",
    "results_data[59][5] = prc_val1\n",
    "results_data[59][6] = prc_val2\n",
    "results_data[59][7] = pr_auc1\n",
    "results_data[59][8] = pr_auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling/Undersampling Combination Rebalance for model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf, pr_auc, lr_rkf_prediction_probs1 = Rkf(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[60][0] = \"OSUS_Combination_Logistic_Regression_rkf\"\n",
    "results_data[60][1] = model_score\n",
    "results_data[60][3] = acc\n",
    "results_data[60][5] = prc_val\n",
    "results_data[60][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs1 = Rkf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[61][0] = \"OSUS_Combination_Logistic_Regression_rkf_Best_Threshold\"\n",
    "results_data[61][1] = model_score\n",
    "results_data[61][3] = acc\n",
    "results_data[61][5] = prc_val\n",
    "results_data[61][7] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_rkf, pr_auc, rf_rkf_prediction_probs1 = Rkf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[62][0] = \"OSUS_Combination_Random_Forrest_rkf\"\n",
    "results_data[62][1] = model_score\n",
    "results_data[62][3] = acc\n",
    "results_data[62][5] = prc_val\n",
    "results_data[62][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs1 = Rkf(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[63][0] = \"OSUS_Combination_XGB_Classifier_rkf\"\n",
    "results_data[63][1] = model_score\n",
    "results_data[63][3] = acc\n",
    "results_data[63][5] = prc_val\n",
    "results_data[63][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf, pr_auc, lr_skf_prediction_probs1 = Skf(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[64][0] = \"OSUS_Combination_Logistic_Regression_skf\"\n",
    "results_data[64][1] = model_score\n",
    "results_data[64][3] = acc\n",
    "results_data[64][5] = prc_val\n",
    "results_data[64][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs1 = Skf(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[65][0] = \"OSUS_Combination_Logistic_Regression_skf_Best_Threshold\"\n",
    "results_data[65][1] = model_score\n",
    "results_data[65][3] = acc\n",
    "results_data[65][5] = prc_val\n",
    "results_data[65][7] = pr_auc\n",
    "\n",
    "Skf_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_skf, pr_auc, rf_skf_prediction_probs1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[66][0] = \"OSUS_Combination_Random_Forrest_skf\"\n",
    "results_data[66][1] = model_score\n",
    "results_data[66][3] = acc\n",
    "results_data[66][5] = prc_val\n",
    "results_data[66][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_skf, pr_auc, xgb_skf_prediction_probs1 = Skf(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[67][0] = \"OSUS_Combination_XGB_Classifier_skf\"\n",
    "results_data[67][1] = model_score\n",
    "results_data[67][3] = acc\n",
    "results_data[67][5] = prc_val\n",
    "results_data[67][7] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss, pr_auc, lr_tss_prediction_probs1 = Tss(lr_model1, balanced_x1, balanced_y1)\n",
    "results_data[68][0] = \"OSUS_Combination_Logistic_Regression_tss\"\n",
    "results_data[68][1] = model_score\n",
    "results_data[68][3] = acc\n",
    "results_data[68][5] = prc_val\n",
    "results_data[68][7] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y1_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs1 = Tss(lr_model1, balanced_x1, balanced_y1, lr_best_threshold1)\n",
    "results_data[69][0] = \"OSUS_Combination_Logistic_Regression_tss_Best_Threshold\"\n",
    "results_data[69][1] = model_score\n",
    "results_data[69][3] = acc\n",
    "results_data[69][5] = prc_val\n",
    "results_data[69][7] = pr_auc\n",
    "\n",
    "Tss_short(lr_model1, balanced_x1, balanced_y1)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_rf_test_tss, pr_auc, rf_tss_prediction_probs1 = Skf(rf_model1, balanced_x1, balanced_y1)\n",
    "results_data[70][0] = \"OSUS_Combination_Random_Forrest_tss\"\n",
    "results_data[70][1] = model_score\n",
    "results_data[70][3] = acc\n",
    "results_data[70][5] = prc_val\n",
    "results_data[70][7] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y1_xgb_test_tss, pr_auc, xgb_tss_prediction_probs1 = Tss(xgb_model1, balanced_x1, balanced_y1)\n",
    "results_data[71][0] = \"OSUS_Combination_XGB_Classifier_tss\"\n",
    "results_data[71][1] = model_score\n",
    "results_data[71][3] = acc\n",
    "results_data[71][5] = prc_val\n",
    "results_data[71][7] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation After Oversampling/Undersampling Combination Rebalance for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf, pr_auc, lr_rkf_prediction_probs2 = Rkf(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[60][2] = model_score\n",
    "results_data[60][4] = acc\n",
    "results_data[60][6] = prc_val\n",
    "results_data[60][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_rkf_best, pr_auc, lr_rkf_best_prediction_probs2 = Rkf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[61][2] = model_score\n",
    "results_data[61][4] = acc\n",
    "results_data[61][6] = prc_val\n",
    "results_data[61][8] = pr_auc\n",
    "\n",
    "Rkf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_rkf, pr_auc, rf_rkf_prediction_probs2 = Rkf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[62][2] = model_score\n",
    "results_data[62][4] = acc\n",
    "results_data[62][6] = prc_val\n",
    "results_data[62][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_rkf, pr_auc, xgb_rkf_prediction_probs2 = Rkf(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[63][2] = model_score\n",
    "results_data[63][4] = acc\n",
    "results_data[63][6] = prc_val\n",
    "results_data[63][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf, pr_auc, lr_skf_prediction_probs2 = Skf(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[64][2] = model_score\n",
    "results_data[64][4] = acc\n",
    "results_data[64][6] = prc_val\n",
    "results_data[64][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_skf_best, pr_auc, lr_skf_best_prediction_probs2 = Skf(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[65][2] = model_score\n",
    "results_data[65][4] = acc\n",
    "results_data[65][6] = prc_val\n",
    "results_data[65][8] = pr_auc\n",
    "\n",
    "Skf_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_skf, pr_auc, rf_skf_prediction_probs2 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[66][2] = model_score\n",
    "results_data[66][4] = acc\n",
    "results_data[66][6] = prc_val\n",
    "results_data[66][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_skf, pr_auc, xgb_skf_prediction_probs2 = Skf(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[67][2] = model_score\n",
    "results_data[67][4] = acc\n",
    "results_data[67][6] = prc_val\n",
    "results_data[67][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------------\\n|Scores for Logistic Regression|\\n--------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss, pr_auc, lr_tss_prediction_probs2 = Tss(lr_model2, balanced_x2, balanced_y2)\n",
    "results_data[68][2] = model_score\n",
    "results_data[68][4] = acc\n",
    "results_data[68][6] = prc_val\n",
    "results_data[68][8] = pr_auc\n",
    "print(\"---------------------\")\n",
    "print(\"With best threshold\")\n",
    "model_score, acc, prc_val, y2_lr_test_tss_best, pr_auc, lr_tss_best_prediction_probs2 = Tss(lr_model2, balanced_x2, balanced_y2, lr_best_threshold2)\n",
    "results_data[69][2] = model_score\n",
    "results_data[69][4] = acc\n",
    "results_data[69][6] = prc_val\n",
    "results_data[69][8] = pr_auc\n",
    "\n",
    "Tss_short(lr_model2, balanced_x2, balanced_y2)\n",
    "print(\"--------------------------------------\\n|Scores for Random Forrest Classifier|\\n--------------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_rf_test_tss, pr_auc, rf_tss_prediction_probs2 = Skf(rf_model2, balanced_x2, balanced_y2)\n",
    "results_data[70][2] = model_score\n",
    "results_data[70][4] = acc\n",
    "results_data[70][6] = prc_val\n",
    "results_data[70][8] = pr_auc\n",
    "\n",
    "print(\"-------------------------------\\n|Scores for XGBoost Classifier|\\n-------------------------------\")\n",
    "print(\"With normal threshold\")\n",
    "model_score, acc, prc_val, y2_xgb_test_tss, pr_auc, xgb_tss_prediction_probs2 = Tss(xgb_model2, balanced_x2, balanced_y2)\n",
    "results_data[71][2] = model_score\n",
    "results_data[71][4] = acc\n",
    "results_data[71][6] = prc_val\n",
    "results_data[71][8] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rkf_best_threshold1, lr_rkf_best_threshold2, lr_rkf_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_rkf, x2_test, y2_lr_test_rkf, lr_rkf_prediction_probs1, lr_rkf_prediction_probs2, \"OSUS Logistic Regression Rkf\")\n",
    "rf_rkf_best_threshold1, rf_rkf_best_threshold2, rf_rkf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_rkf, x2_test, y2_rf_test_rkf, rf_rkf_prediction_probs1, rf_rkf_prediction_probs2, \"OSUS Random Forrest Rkf\")\n",
    "xgb_rkf_best_threshold1, xgb_rkf_best_threshold2, xgb_rkf_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_rkf, x2_test, y2_xgb_test_rkf, xgb_rkf_prediction_probs1, xgb_rkf_prediction_probs2, \"OSUS XGBoost Rkf\")\n",
    "\n",
    "lr_skf_best_threshold1, lr_skf_best_threshold2, lr_skf_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_skf, x2_test, y2_lr_test_skf, lr_skf_prediction_probs1, lr_skf_prediction_probs2, \"OSUS Logistic Regression Skf\")\n",
    "rf_skf_best_threshold1, rf_skf_best_threshold2, rf_skf_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_skf, x2_test, y2_rf_test_skf, rf_skf_prediction_probs1, rf_skf_prediction_probs2, \"OSUS Random Forrest Skf\")\n",
    "xgb_skf_best_threshold1, xgb_skf_best_threshold2, xgb_skf_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_skf, x2_test, y2_xgb_test_skf, xgb_skf_prediction_probs1, xgb_skf_prediction_probs2, \"OSUS XGBoost Skf\")\n",
    "\n",
    "lr_tss_best_threshold1, lr_tss_best_threshold2, lr_tss_osus_fig = plot_thresholds(lr_model1, lr_model2, x1_test, y1_lr_test_tss, x2_test, y2_lr_test_tss, lr_tss_prediction_probs1, lr_tss_prediction_probs2, \"OSUS Logistic Regression Tss\")\n",
    "rf_tss_best_threshold1, rf_tss_best_threshold2, rf_tss_osus_fig = plot_thresholds(rf_model1, rf_model2, x1_test, y1_rf_test_tss, x2_test, y2_rf_test_tss, rf_tss_prediction_probs1, rf_tss_prediction_probs2, \"OSUS Random Forrest Tss\")\n",
    "xgb_tss_best_threshold1, xgb_tss_best_threshold2, xgb_tss_osus_fig = plot_thresholds(xgb_model1, xgb_model2, x1_test, y1_xgb_test_tss, x2_test, y2_xgb_test_tss, xgb_tss_prediction_probs1, xgb_tss_prediction_probs2, \"OSUS XGBoost Tss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_data, columns = ['Test', 'Model1 score', 'Model2 score', 'Model1 accuracy', 'Model2 accuracy', 'Model1 avg. PR score', 'Model2 avg. PR score', 'Model1 PRC-AUC Score', 'Model2 PRC-AUC Score'])\n",
    "model1_results_df = results_df[['Test', 'Model1 score', 'Model1 accuracy', 'Model1 avg. PR score', 'Model1 PRC-AUC Score']]\n",
    "model2_results_df = results_df[['Test', 'Model2 score', 'Model2 accuracy', 'Model2 avg. PR score', 'Model2 PRC-AUC Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_results_df[~model1_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model1 PRC-AUC Score', 'Model1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results_df[~model2_results_df.Test.str.contains(\"tss\", na=False)].sort_values(by=['Model2 PRC-AUC Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = [lr_skf_og_fig, rf_skf_os_fig, xgb_skf_os_fig]\n",
    "\n",
    "for i, figure in enumerate(figures):\n",
    "    figure.savefig(f\"../../img/Velocity/graphs/Precision vs. Recall Results/Figure_{i}\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_A = mpimg.imread('../../img/Velocity/graphs/Precision vs. Recall Results/Figure_0.png')\n",
    "img_B = mpimg.imread('../../img/Velocity/graphs/Precision vs. Recall Results/Figure_1.png')\n",
    "img_C = mpimg.imread('../../img/Velocity/graphs/Precision vs. Recall Results/Figure_2.png')\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,3,figsize=(20,20))\n",
    "ax[0].imshow(img_A);\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(img_B);\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(img_C);\n",
    "ax[2].axis('off')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"../../img/Velocity/graphs/Precision vs. Recall Results/Figure_final.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
